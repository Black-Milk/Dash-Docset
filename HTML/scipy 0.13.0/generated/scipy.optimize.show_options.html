
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>scipy.optimize.show_options &mdash; SciPy v0.13.0 Reference Guide</title>
    
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-extend.css">
    <link rel="stylesheet" type="text/css" href="../_static/css/jquery-ui.css">
    <link rel="stylesheet" href="../_static/scipy.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.13.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false
      };
    </script>
    <script type="text/javascript" src="../_static/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-ui.min.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="SciPy v0.13.0 Reference Guide" href="../index.html" />
    <link rel="up" title="Optimization and root finding (scipy.optimize)" href="../optimize.html" />
    <link rel="next" title="Signal processing (scipy.signal)" href="../signal.html" />
    <link rel="prev" title="scipy.optimize.check_grad" href="scipy.optimize.check_grad.html" /> 
  </head>
  <body>

  <div class="container">
    <div class="header">
    </div>
  </div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
	
        <li class="active"><a href="../index.html">SciPy v0.13.0 Reference Guide</a></li>
	
          <li class="active"><a href="../optimize.html" accesskey="U">Optimization and root finding (<tt class="docutils literal"><span class="pre">scipy.optimize</span></tt>)</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
      <li class="active">
        <a href="../py-modindex.html" title="Python Module Index"
           >modules</a>
      </li>
      <li class="active">
        <a href="../signal.html" title="Signal processing (scipy.signal)"
           accesskey="N">next</a>
      </li>
      <li class="active">
        <a href="scipy.optimize.check_grad.html" title="scipy.optimize.check_grad"
           accesskey="P">previous</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/scipyshiny_small.png" alt="Logo"/>
            </a></p>
  <h4>Previous topic</h4>
  <p class="topless"><a href="scipy.optimize.check_grad.html"
                        title="previous chapter">scipy.optimize.check_grad</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../signal.html"
                        title="next chapter">Signal processing (<tt class="docutils literal"><span class="pre">scipy.signal</span></tt>)</a></p>


        </div>
      </div>
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <div class="section" id="scipy-optimize-show-options">
<h1>scipy.optimize.show_options<a class="headerlink" href="#scipy-optimize-show-options" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="scipy.optimize.show_options">
<tt class="descclassname">scipy.optimize.</tt><tt class="descname">show_options</tt><big>(</big><em>solver</em>, <em>method=None</em><big>)</big><a class="reference external" href="http://github.com/scipy/scipy/blob/v0.13.0/scipy/optimize/optimize.py#L2571"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#scipy.optimize.show_options" title="Permalink to this definition">¶</a></dt>
<dd><p>Show documentation for additional options of optimization solvers.</p>
<p>These are method-specific options that can be supplied through the
<tt class="docutils literal"><span class="pre">options</span></tt> dict.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>solver</strong> : str</p>
<blockquote>
<div><p>Type of optimization solver. One of {<a class="reference internal" href="scipy.optimize.minimize.html#scipy.optimize.minimize" title="scipy.optimize.minimize"><tt class="xref py py-obj docutils literal"><span class="pre">minimize</span></tt></a>, <a class="reference internal" href="scipy.optimize.root.html#scipy.optimize.root" title="scipy.optimize.root"><tt class="xref py py-obj docutils literal"><span class="pre">root</span></tt></a>}.</p>
</div></blockquote>
<p><strong>method</strong> : str, optional</p>
<blockquote class="last">
<div><p>If not given, shows all methods of the specified solver. Otherwise,
show only the options for the specified method. Valid values
corresponds to methods&#8217; names of respective solver (e.g. &#8216;BFGS&#8217; for
&#8216;minimize&#8217;).</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>** minimize options</p>
<ul>
<li><dl class="first docutils">
<dt>BFGS options:</dt>
<dd><dl class="first last docutils">
<dt>gtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Gradient norm must be less than <em class="xref py py-obj">gtol</em> before successful
termination.</p>
</dd>
<dt>norm <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Order of norm (Inf is max, -Inf is min).</p>
</dd>
<dt>eps <span class="classifier-delimiter">:</span> <span class="classifier">float or ndarray</span></dt>
<dd><p class="first last">If <em class="xref py py-obj">jac</em> is approximated, use this value for the step size.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Nelder-Mead options:</dt>
<dd><dl class="first last docutils">
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative error in solution <em class="xref py py-obj">xopt</em> acceptable for convergence.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative error in <tt class="docutils literal"><span class="pre">fun(xopt)</span></tt> acceptable for convergence.</p>
</dd>
<dt>maxfev <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of function evaluations to make.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Newton-CG options:</dt>
<dd><dl class="first last docutils">
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Average relative error in solution <em class="xref py py-obj">xopt</em> acceptable for
convergence.</p>
</dd>
<dt>eps <span class="classifier-delimiter">:</span> <span class="classifier">float or ndarray</span></dt>
<dd><p class="first last">If <em class="xref py py-obj">jac</em> is approximated, use this value for the step size.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CG options:</dt>
<dd><dl class="first last docutils">
<dt>gtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Gradient norm must be less than <em class="xref py py-obj">gtol</em> before successful
termination.</p>
</dd>
<dt>norm <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Order of norm (Inf is max, -Inf is min).</p>
</dd>
<dt>eps <span class="classifier-delimiter">:</span> <span class="classifier">float or ndarray</span></dt>
<dd><p class="first last">If <em class="xref py py-obj">jac</em> is approximated, use this value for the step size.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Powell options:</dt>
<dd><dl class="first last docutils">
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative error in solution <em class="xref py py-obj">xopt</em> acceptable for convergence.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative error in <tt class="docutils literal"><span class="pre">fun(xopt)</span></tt> acceptable for convergence.</p>
</dd>
<dt>maxfev <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of function evaluations to make.</p>
</dd>
<dt>direc <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Initial set of direction vectors for the Powell method.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Anneal options:</dt>
<dd><dl class="first last docutils">
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative error in <tt class="docutils literal"><span class="pre">fun(x)</span></tt> acceptable for convergence.</p>
</dd>
<dt>schedule <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Annealing schedule to use. One of: &#8216;fast&#8217;, &#8216;cauchy&#8217; or
&#8216;boltzmann&#8217;.</p>
</dd>
<dt>T0 <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Initial Temperature (estimated as 1.2 times the largest
cost-function deviation over random points in the range).</p>
</dd>
<dt>Tf <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Final goal temperature.</p>
</dd>
<dt>maxfev <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of function evaluations to make.</p>
</dd>
<dt>maxaccept <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum changes to accept.</p>
</dd>
<dt>boltzmann <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Boltzmann constant in acceptance test (increase for less
stringent test at each temperature).</p>
</dd>
<dt>learn_rate <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Scale constant for adjusting guesses.</p>
</dd>
<dt>quench, m, n <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Parameters to alter fast_sa schedule.</p>
</dd>
<dt>lower, upper <span class="classifier-delimiter">:</span> <span class="classifier">float or ndarray</span></dt>
<dd><p class="first last">Lower and upper bounds on <em class="xref py py-obj">x</em>.</p>
</dd>
<dt>dwell <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The number of times to search the space at each temperature.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>L-BFGS-B options:</dt>
<dd><dl class="first last docutils">
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The iteration stops when <tt class="docutils literal"><span class="pre">(f^k</span> <span class="pre">-</span>
<span class="pre">f^{k+1})/max{|f^k|,|f^{k+1}|,1}</span> <span class="pre">&lt;=</span> <span class="pre">ftol</span></tt>.</p>
</dd>
<dt>gtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The iteration will stop when <tt class="docutils literal"><span class="pre">max{|proj</span> <span class="pre">g_i</span> <span class="pre">|</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">1,</span> <span class="pre">...,</span> <span class="pre">n}</span>
<span class="pre">&lt;=</span> <span class="pre">gtol</span></tt> where <tt class="docutils literal"><span class="pre">pg_i</span></tt> is the i-th component of the
projected gradient.</p>
</dd>
<dt>maxcor <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The maximum number of variable metric corrections used to
define the limited memory matrix. (The limited memory BFGS
method does not store the full hessian but uses this many terms
in an approximation to it.)</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of function evaluations.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>TNC options:</dt>
<dd><dl class="first last docutils">
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Precision goal for the value of f in the stoping criterion.
If ftol &lt; 0.0, ftol is set to 0.0 defaults to -1.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Precision goal for the value of x in the stopping
criterion (after applying x scaling factors).  If xtol &lt;
0.0, xtol is set to sqrt(machine_precision).  Defaults to
-1.</p>
</dd>
<dt>gtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Precision goal for the value of the projected gradient in
the stopping criterion (after applying x scaling factors).
If gtol &lt; 0.0, gtol is set to 1e-2 * sqrt(accuracy).
Setting it to 0.0 is not recommended.  Defaults to -1.</p>
</dd>
<dt>scale <span class="classifier-delimiter">:</span> <span class="classifier">list of floats</span></dt>
<dd><p class="first last">Scaling factors to apply to each variable.  If None, the
factors are up-low for interval bounded variables and
1+|x] fo the others.  Defaults to None</p>
</dd>
<dt>offset <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Value to substract from each variable.  If None, the
offsets are (up+low)/2 for interval bounded variables
and x for the others.</p>
</dd>
<dt>maxCGit <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of hessian*vector evaluations per main
iteration.  If maxCGit == 0, the direction chosen is
-gradient if maxCGit &lt; 0, maxCGit is set to
max(1,min(50,n/2)).  Defaults to -1.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of function evaluation.  if None, <em class="xref py py-obj">maxiter</em> is
set to max(100, 10*len(x0)).  Defaults to None.</p>
</dd>
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Severity of the line search. if &lt; 0 or &gt; 1, set to 0.25.
Defaults to -1.</p>
</dd>
<dt>stepmx <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Maximum step for the line search.  May be increased during
call.  If too small, it will be set to 10.0.  Defaults to 0.</p>
</dd>
<dt>accuracy <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative precision for finite difference calculations.  If
&lt;= machine_precision, set to sqrt(machine_precision).
Defaults to 0.</p>
</dd>
<dt>minfev <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Minimum function value estimate.  Defaults to 0.</p>
</dd>
<dt>rescale <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Scaling factor (in log10) used to trigger f value
rescaling.  If 0, rescale at each iteration.  If a large
value, never rescale.  If &lt; 0, rescale is set to 1.3.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>COBYLA options:</dt>
<dd><dl class="first last docutils">
<dt>tol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Final accuracy in the optimization (not precisely guaranteed).
This is a lower bound on the size of the trust region.</p>
</dd>
<dt>rhobeg <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Reasonable initial changes to the variables.</p>
</dd>
<dt>maxfev <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of function evaluations.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>SLSQP options:</dt>
<dd><dl class="first last docutils">
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Precision goal for the value of f in the stopping criterion.</p>
</dd>
<dt>eps <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Step size used for numerical approximation of the jacobian.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of iterations.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>dogleg options:</dt>
<dd><dl class="first last docutils">
<dt>initial_trust_radius <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Initial trust-region radius.</p>
</dd>
<dt>max_trust_radius <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Maximum value of the trust-region radius. No steps that are longer
than this value will be proposed.</p>
</dd>
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Trust region related acceptance stringency for proposed steps.</p>
</dd>
<dt>gtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Gradient norm must be less than <em class="xref py py-obj">gtol</em> before successful
termination.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>trust-ncg options:</dt>
<dd><p class="first last">see dogleg options.</p>
</dd>
</dl>
</li>
</ul>
<p>** root options</p>
<ul>
<li><dl class="first docutils">
<dt>hybrd options:</dt>
<dd><dl class="first last docutils">
<dt>col_deriv <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd><p class="first last">Specify whether the Jacobian function computes derivatives down
the columns (faster, because there is no transpose operation).</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The calculation will terminate if the relative error between
two consecutive iterates is at most <em class="xref py py-obj">xtol</em>.</p>
</dd>
<dt>maxfev <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The maximum number of calls to the function. If zero, then
<tt class="docutils literal"><span class="pre">100*(N+1)</span></tt> is the maximum where N is the number of elements
in <em class="xref py py-obj">x0</em>.</p>
</dd>
<dt>band <span class="classifier-delimiter">:</span> <span class="classifier">sequence</span></dt>
<dd><p class="first last">If set to a two-sequence containing the number of sub- and
super-diagonals within the band of the Jacobi matrix, the
Jacobi matrix is considered banded (only for <tt class="docutils literal"><span class="pre">fprime=None</span></tt>).</p>
</dd>
<dt>epsfcn <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">A suitable step length for the forward-difference approximation
of the Jacobian (for <tt class="docutils literal"><span class="pre">fprime=None</span></tt>). If <em class="xref py py-obj">epsfcn</em> is less than
the machine precision, it is assumed that the relative errors
in the functions are of the order of the machine precision.</p>
</dd>
<dt>factor <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">A parameter determining the initial step bound (<tt class="docutils literal"><span class="pre">factor</span> <span class="pre">*</span> <span class="pre">||</span>
<span class="pre">diag</span> <span class="pre">*</span> <span class="pre">x||</span></tt>).  Should be in the interval <tt class="docutils literal"><span class="pre">(0.1,</span> <span class="pre">100)</span></tt>.</p>
</dd>
<dt>diag <span class="classifier-delimiter">:</span> <span class="classifier">sequence</span></dt>
<dd><p class="first last">N positive entries that serve as a scale factors for the
variables.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>LM options:</dt>
<dd><dl class="first last docutils">
<dt>col_deriv <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd><p class="first last">non-zero to specify that the Jacobian function computes derivatives
down the columns (faster, because there is no transpose operation).</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative error desired in the sum of squares.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Relative error desired in the approximate solution.</p>
</dd>
<dt>gtol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Orthogonality desired between the function vector and the columns
of the Jacobian.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The maximum number of calls to the function. If zero, then
100*(N+1) is the maximum where N is the number of elements in x0.</p>
</dd>
<dt>epsfcn <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">A suitable step length for the forward-difference approximation of
the Jacobian (for Dfun=None). If epsfcn is less than the machine
precision, it is assumed that the relative errors in the functions
are of the order of the machine precision.</p>
</dd>
<dt>factor <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">A parameter determining the initial step bound
(<tt class="docutils literal"><span class="pre">factor</span> <span class="pre">*</span> <span class="pre">||</span> <span class="pre">diag</span> <span class="pre">*</span> <span class="pre">x||</span></tt>). Should be in interval <tt class="docutils literal"><span class="pre">(0.1,</span> <span class="pre">100)</span></tt>.</p>
</dd>
<dt>diag <span class="classifier-delimiter">:</span> <span class="classifier">sequence</span></dt>
<dd><p class="first last">N positive entries that serve as a scale factors for the variables.</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Broyden1 options:</dt>
<dd><dl class="first last docutils">
<dt>nit <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of iterations to make. If omitted (default), make as many
as required to meet tolerances.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Print status to stdout on every iteration.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of iterations to make. If more are needed to
meet convergence, <em class="xref py py-obj">NoConvergence</em> is raised.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative tolerance for the residual. If omitted, not used.</p>
</dd>
<dt>fatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute tolerance (in max-norm) for the residual.
If omitted, default is 6e-6.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative minimum step size. If omitted, not used.</p>
</dd>
<dt>xatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute minimum step size, as determined from the Jacobian
approximation. If the step size is smaller than this, optimization
is terminated as successful. If omitted, not used.</p>
</dd>
<dt>tol_norm <span class="classifier-delimiter">:</span> <span class="classifier">function(vector) -&gt; scalar, optional</span></dt>
<dd><p class="first last">Norm to use in convergence check. Default is the maximum norm.</p>
</dd>
<dt>line_search <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;armijo&#8217; (default), &#8216;wolfe&#8217;}, optional</span></dt>
<dd><p class="first last">Which type of a line search to use to determine the step size in
the direction given by the Jacobian approximation. Defaults to
&#8216;armijo&#8217;.</p>
</dd>
<dt>jac_options <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd><dl class="first last docutils">
<dt>Options for the respective Jacobian approximation.</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Initial guess for the Jacobian is (-1/alpha).</p>
</dd>
<dt>reduction_method <span class="classifier-delimiter">:</span> <span class="classifier">str or tuple, optional</span></dt>
<dd><p class="first">Method used in ensuring that the rank of the Broyden
matrix stays low. Can either be a string giving the
name of the method, or a tuple of the form <tt class="docutils literal"><span class="pre">(method,</span>
<span class="pre">param1,</span> <span class="pre">param2,</span> <span class="pre">...)</span></tt> that gives the name of the
method and values for additional parameters.</p>
<dl class="last docutils">
<dt>Methods available:</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">restart</span></tt>: drop all matrix columns. Has no</dt>
<dd><p class="first last">extra parameters.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">simple</span></tt>: drop oldest matrix column. Has no</dt>
<dd><p class="first last">extra parameters.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">svd</span></tt>: keep only the most significant SVD</dt>
<dd><p class="first last">components.</p>
</dd>
<dt>Extra parameters:</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt><a href="#id1"><span class="problematic" id="id2">``</span></a>to_retain`: number of SVD components to</dt>
<dd><p class="first last">retain when rank reduction is done.
Default is <tt class="docutils literal"><span class="pre">max_rank</span> <span class="pre">-</span> <span class="pre">2</span></tt>.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
<dt>max_rank <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum rank for the Broyden matrix.
Default is infinity (ie., no rank reduction).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Broyden2 options:</dt>
<dd><dl class="first last docutils">
<dt>nit <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of iterations to make. If omitted (default), make as many
as required to meet tolerances.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Print status to stdout on every iteration.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of iterations to make. If more are needed to
meet convergence, <em class="xref py py-obj">NoConvergence</em> is raised.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative tolerance for the residual. If omitted, not used.</p>
</dd>
<dt>fatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute tolerance (in max-norm) for the residual.
If omitted, default is 6e-6.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative minimum step size. If omitted, not used.</p>
</dd>
<dt>xatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute minimum step size, as determined from the Jacobian
approximation. If the step size is smaller than this, optimization
is terminated as successful. If omitted, not used.</p>
</dd>
<dt>tol_norm <span class="classifier-delimiter">:</span> <span class="classifier">function(vector) -&gt; scalar, optional</span></dt>
<dd><p class="first last">Norm to use in convergence check. Default is the maximum norm.</p>
</dd>
<dt>line_search <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;armijo&#8217; (default), &#8216;wolfe&#8217;}, optional</span></dt>
<dd><p class="first last">Which type of a line search to use to determine the step size in
the direction given by the Jacobian approximation. Defaults to
&#8216;armijo&#8217;.</p>
</dd>
<dt>jac_options <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd><dl class="first last docutils">
<dt>Options for the respective Jacobian approximation.</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Initial guess for the Jacobian is (-1/alpha).</p>
</dd>
<dt>reduction_method <span class="classifier-delimiter">:</span> <span class="classifier">str or tuple, optional</span></dt>
<dd><p class="first">Method used in ensuring that the rank of the Broyden
matrix stays low. Can either be a string giving the
name of the method, or a tuple of the form <tt class="docutils literal"><span class="pre">(method,</span>
<span class="pre">param1,</span> <span class="pre">param2,</span> <span class="pre">...)</span></tt> that gives the name of the
method and values for additional parameters.</p>
<dl class="last docutils">
<dt>Methods available:</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">restart</span></tt>: drop all matrix columns. Has no</dt>
<dd><p class="first last">extra parameters.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">simple</span></tt>: drop oldest matrix column. Has no</dt>
<dd><p class="first last">extra parameters.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">svd</span></tt>: keep only the most significant SVD</dt>
<dd><p class="first last">components.</p>
</dd>
<dt>Extra parameters:</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt><a href="#id3"><span class="problematic" id="id4">``</span></a>to_retain`: number of SVD components to</dt>
<dd><p class="first last">retain when rank reduction is done.
Default is <tt class="docutils literal"><span class="pre">max_rank</span> <span class="pre">-</span> <span class="pre">2</span></tt>.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
<dt>max_rank <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum rank for the Broyden matrix.
Default is infinity (ie., no rank reduction).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Anderson options:</dt>
<dd><dl class="first last docutils">
<dt>nit <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of iterations to make. If omitted (default), make as many
as required to meet tolerances.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Print status to stdout on every iteration.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of iterations to make. If more are needed to
meet convergence, <em class="xref py py-obj">NoConvergence</em> is raised.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative tolerance for the residual. If omitted, not used.</p>
</dd>
<dt>fatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute tolerance (in max-norm) for the residual.
If omitted, default is 6e-6.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative minimum step size. If omitted, not used.</p>
</dd>
<dt>xatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute minimum step size, as determined from the Jacobian
approximation. If the step size is smaller than this, optimization
is terminated as successful. If omitted, not used.</p>
</dd>
<dt>tol_norm <span class="classifier-delimiter">:</span> <span class="classifier">function(vector) -&gt; scalar, optional</span></dt>
<dd><p class="first last">Norm to use in convergence check. Default is the maximum norm.</p>
</dd>
<dt>line_search <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;armijo&#8217; (default), &#8216;wolfe&#8217;}, optional</span></dt>
<dd><p class="first last">Which type of a line search to use to determine the step size in
the direction given by the Jacobian approximation. Defaults to
&#8216;armijo&#8217;.</p>
</dd>
<dt>jac_options <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd><dl class="first last docutils">
<dt>Options for the respective Jacobian approximation.</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Initial guess for the Jacobian is (-1/alpha).</p>
</dd>
<dt>M <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Number of previous vectors to retain. Defaults to 5.</p>
</dd>
<dt>w0 <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Regularization parameter for numerical stability.
Compared to unity, good values of the order of 0.01.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>LinearMixing options:</dt>
<dd><dl class="first last docutils">
<dt>nit <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of iterations to make. If omitted (default), make as many
as required to meet tolerances.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Print status to stdout on every iteration.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of iterations to make. If more are needed to
meet convergence, <em class="xref py py-obj">NoConvergence</em> is raised.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative tolerance for the residual. If omitted, not used.</p>
</dd>
<dt>fatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute tolerance (in max-norm) for the residual.
If omitted, default is 6e-6.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative minimum step size. If omitted, not used.</p>
</dd>
<dt>xatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute minimum step size, as determined from the Jacobian
approximation. If the step size is smaller than this, optimization
is terminated as successful. If omitted, not used.</p>
</dd>
<dt>tol_norm <span class="classifier-delimiter">:</span> <span class="classifier">function(vector) -&gt; scalar, optional</span></dt>
<dd><p class="first last">Norm to use in convergence check. Default is the maximum norm.</p>
</dd>
<dt>line_search <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;armijo&#8217; (default), &#8216;wolfe&#8217;}, optional</span></dt>
<dd><p class="first last">Which type of a line search to use to determine the step size in
the direction given by the Jacobian approximation. Defaults to
&#8216;armijo&#8217;.</p>
</dd>
<dt>jac_options <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd><dl class="first last docutils">
<dt>Options for the respective Jacobian approximation.</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">initial guess for the jacobian is (-1/alpha).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>DiagBroyden options:</dt>
<dd><dl class="first last docutils">
<dt>nit <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of iterations to make. If omitted (default), make as many
as required to meet tolerances.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Print status to stdout on every iteration.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of iterations to make. If more are needed to
meet convergence, <em class="xref py py-obj">NoConvergence</em> is raised.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative tolerance for the residual. If omitted, not used.</p>
</dd>
<dt>fatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute tolerance (in max-norm) for the residual.
If omitted, default is 6e-6.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative minimum step size. If omitted, not used.</p>
</dd>
<dt>xatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute minimum step size, as determined from the Jacobian
approximation. If the step size is smaller than this, optimization
is terminated as successful. If omitted, not used.</p>
</dd>
<dt>tol_norm <span class="classifier-delimiter">:</span> <span class="classifier">function(vector) -&gt; scalar, optional</span></dt>
<dd><p class="first last">Norm to use in convergence check. Default is the maximum norm.</p>
</dd>
<dt>line_search <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;armijo&#8217; (default), &#8216;wolfe&#8217;}, optional</span></dt>
<dd><p class="first last">Which type of a line search to use to determine the step size in
the direction given by the Jacobian approximation. Defaults to
&#8216;armijo&#8217;.</p>
</dd>
<dt>jac_options <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd><dl class="first last docutils">
<dt>Options for the respective Jacobian approximation.</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">initial guess for the jacobian is (-1/alpha).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>ExcitingMixing options:</dt>
<dd><dl class="first last docutils">
<dt>nit <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of iterations to make. If omitted (default), make as many
as required to meet tolerances.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Print status to stdout on every iteration.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of iterations to make. If more are needed to
meet convergence, <em class="xref py py-obj">NoConvergence</em> is raised.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative tolerance for the residual. If omitted, not used.</p>
</dd>
<dt>fatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute tolerance (in max-norm) for the residual.
If omitted, default is 6e-6.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative minimum step size. If omitted, not used.</p>
</dd>
<dt>xatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute minimum step size, as determined from the Jacobian
approximation. If the step size is smaller than this, optimization
is terminated as successful. If omitted, not used.</p>
</dd>
<dt>tol_norm <span class="classifier-delimiter">:</span> <span class="classifier">function(vector) -&gt; scalar, optional</span></dt>
<dd><p class="first last">Norm to use in convergence check. Default is the maximum norm.</p>
</dd>
<dt>line_search <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;armijo&#8217; (default), &#8216;wolfe&#8217;}, optional</span></dt>
<dd><p class="first last">Which type of a line search to use to determine the step size in
the direction given by the Jacobian approximation. Defaults to
&#8216;armijo&#8217;.</p>
</dd>
<dt>jac_options <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd><dl class="first last docutils">
<dt>Options for the respective Jacobian approximation.</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Initial Jacobian approximation is (-1/alpha).</p>
</dd>
<dt>alphamax <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">The entries of the diagonal Jacobian are kept in the range
<tt class="docutils literal"><span class="pre">[alpha,</span> <span class="pre">alphamax]</span></tt>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Krylov options:</dt>
<dd><dl class="first last docutils">
<dt>nit <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of iterations to make. If omitted (default), make as many
as required to meet tolerances.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Print status to stdout on every iteration.</p>
</dd>
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of iterations to make. If more are needed to
meet convergence, <em class="xref py py-obj">NoConvergence</em> is raised.</p>
</dd>
<dt>ftol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative tolerance for the residual. If omitted, not used.</p>
</dd>
<dt>fatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute tolerance (in max-norm) for the residual.
If omitted, default is 6e-6.</p>
</dd>
<dt>xtol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative minimum step size. If omitted, not used.</p>
</dd>
<dt>xatol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Absolute minimum step size, as determined from the Jacobian
approximation. If the step size is smaller than this, optimization
is terminated as successful. If omitted, not used.</p>
</dd>
<dt>tol_norm <span class="classifier-delimiter">:</span> <span class="classifier">function(vector) -&gt; scalar, optional</span></dt>
<dd><p class="first last">Norm to use in convergence check. Default is the maximum norm.</p>
</dd>
<dt>line_search <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;armijo&#8217; (default), &#8216;wolfe&#8217;}, optional</span></dt>
<dd><p class="first last">Which type of a line search to use to determine the step size in
the direction given by the Jacobian approximation. Defaults to
&#8216;armijo&#8217;.</p>
</dd>
<dt>jac_options <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd><dl class="first last docutils">
<dt>Options for the respective Jacobian approximation.</dt>
<dd><dl class="first last docutils">
<dt>rdiff <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Relative step size to use in numerical differentiation.</p>
</dd>
<dt>method <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;lgmres&#8217;, &#8216;gmres&#8217;, &#8216;bicgstab&#8217;, &#8216;cgs&#8217;, &#8216;minres&#8217;} or</span></dt>
<dd><p class="first">function
Krylov method to use to approximate the Jacobian.
Can be a string, or a function implementing the same
interface as the iterative solvers in
<a class="reference internal" href="../sparse.linalg.html#module-scipy.sparse.linalg" title="scipy.sparse.linalg"><tt class="xref py py-obj docutils literal"><span class="pre">scipy.sparse.linalg</span></tt></a>.</p>
<p class="last">The default is <a class="reference internal" href="scipy.sparse.linalg.lgmres.html#scipy.sparse.linalg.lgmres" title="scipy.sparse.linalg.lgmres"><tt class="xref py py-obj docutils literal"><span class="pre">scipy.sparse.linalg.lgmres</span></tt></a>.</p>
</dd>
<dt>inner_M <span class="classifier-delimiter">:</span> <span class="classifier">LinearOperator or InverseJacobian</span></dt>
<dd><p class="first">Preconditioner for the inner Krylov iteration.
Note that you can use also inverse Jacobians as (adaptive)
preconditioners. For example,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">jac</span> <span class="o">=</span> <span class="n">BroydenFirst</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kjac</span> <span class="o">=</span> <span class="n">KrylovJacobian</span><span class="p">(</span><span class="n">inner_M</span><span class="o">=</span><span class="n">jac</span><span class="o">.</span><span class="n">inverse</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<p class="last">If the preconditioner has a method named &#8216;update&#8217;, it will
be called as <tt class="docutils literal"><span class="pre">update(x,</span> <span class="pre">f)</span></tt> after each nonlinear step,
with <tt class="docutils literal"><span class="pre">x</span></tt> giving the current point, and <tt class="docutils literal"><span class="pre">f</span></tt> the current
function value.</p>
</dd>
<dt>inner_tol, inner_maxiter, ...</dt>
<dd><p class="first last">Parameters to pass on to the &#8220;inner&#8221; Krylov solver.
See <a class="reference internal" href="scipy.sparse.linalg.gmres.html#scipy.sparse.linalg.gmres" title="scipy.sparse.linalg.gmres"><tt class="xref py py-obj docutils literal"><span class="pre">scipy.sparse.linalg.gmres</span></tt></a> for details.</p>
</dd>
<dt>outer_k <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first">Size of the subspace kept across LGMRES nonlinear
iterations.</p>
<p class="last">See <a class="reference internal" href="scipy.sparse.linalg.lgmres.html#scipy.sparse.linalg.lgmres" title="scipy.sparse.linalg.lgmres"><tt class="xref py py-obj docutils literal"><span class="pre">scipy.sparse.linalg.lgmres</span></tt></a> for details.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
</ul>
</dd></dl>

</div>


          </div>
        </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2008-2009, The Scipy community.
      </li>
      <li>
      Last updated on Oct 21, 2013.
      </li>
      <li>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
      </li>
    </ul>
    </div>
    </div>
    </div>

<script type="text/javascript">
        $('.dropdown-toggle').dropdown()
</script>

<script>
$(document).ready(function()
{
  //Handles menu drop down
  $('.dropdown-menu').find('form').click(function (e) {
        e.stopPropagation();
        });
  });
</script>

<script type="text/javascript">
        //handles accordion arrow-up and down in pages
        $('.accordion-group').collapse();
        $('.accordion-group').on('show hide', function(e)
                { 
                        $(e.target).siblings('.accordion-heading').find('.accordion-toggle i').toggleClass('icon-arrow-down icon-arrow-up', 200); 
                });
</script>

  </body>
</html>