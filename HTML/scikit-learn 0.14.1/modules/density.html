
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>2.9. Density Estimation &mdash; scikit-learn 0.14.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.14.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="top" title="scikit-learn 0.14.1 documentation" href="../index.html" />
    <link rel="up" title="2. Unsupervised learning" href="../unsupervised_learning.html" />
    <link rel="next" title="2.10. Neural network models (unsupervised)" href="neural_networks.html" />
    <link rel="prev" title="2.8. Hidden Markov Models" href="hmm.html" />
  
   
       <script type="text/javascript" src="../_static/sidebar.js"></script>
   
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/density.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
    var bodywrapper = $('.bodywrapper');
    var sidebarbutton = $('#sidebarbutton');
    sidebarbutton.css({'height': '900px'});
  </script>

  </head>
  <body>

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../index.html">
            <img src="../_static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar">
            <ul>
                <li><a href="../../stable/index.html">Home</a></li>
                <li><a href="../../stable/install.html">Installation</a></li>
                <li class="btn-li"><div class="btn-group">
		      <a href="../documentation.html">Documentation</a>
		      <a class="btn dropdown-toggle" data-toggle="dropdown">
			     <span class="caret"></span>
		      </a>
		      <ul class="dropdown-menu">
			<li class="link-title">Scikit-learn 0.14 (stable)</li>
			<li><a href="../tutorial/index.html">Tutorials</a></li>
			<li><a href="../user_guide.html">User guide</a></li>
			<li><a href="classes.html">API</a></li>
			<li class="divider"></li>
		        <li><a href="http://scikit-learn.org/dev/documentation.html">Development</a></li>
		        <li><a href="http://scikit-learn.org/0.13/">Scikit-learn 0.13</a></li>
		        <li><a href="http://scikit-learn.org/0.12/">Scikit-learn 0.12</a></li>
		        <li><a href="http://scikit-learn.org/0.11/">Scikit-learn 0.11</a></li>
		        <li><a href="../documentation.html">More versions...</a></li>
		      </ul>
		    </div>
		</li>
            <li><a href="../auto_examples/index.html">Examples</a></li>
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="hmm.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        2.8. Hidden Mark...
        </span>
            <span class="hiddenrellink">
            2.8. Hidden Markov Models
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="neural_networks.html"
        accesskey="N">Next
        <br/>
        <span class="smallrellink">
        2.10. Neural net...
        </span>
            <span class="hiddenrellink">
            2.10. Neural network models (unsupervised)
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="../np-modindex.html"
        >Modules
        <br/>
        <span class="smallrellink">
        Python Module In...
        </span>
            <span class="hiddenrellink">
            Python Module Index
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="../py-modindex.html"
        >Modules
        <br/>
        <span class="smallrellink">
        Python Module In...
        </span>
            <span class="hiddenrellink">
            Python Module Index
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="../unsupervised_learning.html">
        Up
        <br/>
        <span class="smallrellink">
        2. Unsupervised ...
        </span>
            <span class="hiddenrellink">
            2. Unsupervised learning
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version">This documentation is for scikit-learn <strong>version 0.14.1</strong> &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    <p class="citing">If you use the software, please consider <a href="../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <ul>
<li><a class="reference internal" href="#">2.9. Density Estimation</a><ul>
<li><a class="reference internal" href="#density-estimation-histograms">2.9.1. Density Estimation: Histograms</a></li>
<li><a class="reference internal" href="#kernel-density-estimation">2.9.2. Kernel Density Estimation</a></li>
</ul>
</li>
</ul>

    </div>
</div>



      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="density-estimation">
<span id="id1"></span><h1>2.9. Density Estimation<a class="headerlink" href="#density-estimation" title="Permalink to this headline">¶</a></h1>
<p>Density estimation walks the line between unsupervised learning, feature
engineering, and data modeling.  Some of the most popular and useful
density estimation techniques are mixture models such as
Gaussian Mixtures (<a class="reference internal" href="generated/sklearn.mixture.GMM.html#sklearn.mixture.GMM" title="sklearn.mixture.GMM"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.mixture.GMM</span></tt></a>), and neighbor-based
approaches such as the kernel density estimate
(<a class="reference internal" href="generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity" title="sklearn.neighbors.KernelDensity"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.neighbors.KernelDensity</span></tt></a>).
Gaussian Mixtures are discussed more fully in the context of
<a class="reference internal" href="clustering.html#clustering"><em>clustering</em></a>, because the technique is also useful as
an unsupervised clustering scheme.</p>
<p>Density estimation is a very simple concept, and most people are already
familiar with one common density estimation technique: the histogram.</p>
<div class="section" id="density-estimation-histograms">
<h2>2.9.1. Density Estimation: Histograms<a class="headerlink" href="#density-estimation-histograms" title="Permalink to this headline">¶</a></h2>
<p>A histogram is a simple visualization of data where bins are defined, and the
number of data points within each bin is tallied.  An example of a histogram
can be seen in the upper-left panel of the following figure:</p>
<p class="centered">
<strong><a class="reference external image-reference" href="../auto_examples/neighbors/plot_kde_1d.html"><img alt="hist_to_kde" src="../_images/plot_kde_1d_11.png" style="width: 640.0px; height: 480.0px;" /></a>
</strong></p><p>A major problem with histograms, however, is that the choice of binning can
have a disproportionate effect on the resulting visualization.  Consider the
upper-right panel of the above figure.  It shows a histogram over the same
data, with the bins shifted right.  The results of the two visualizations look
entirely different, and might lead to different interpretations of the data.</p>
<p>Intuitively, one can also think of a histogram as a stack of blocks, one block
per point.  By stacking the blocks in the appropriate grid space, we recover
the histogram.  But what if, instead of stacking the blocks on a regular grid,
we center each block on the point it represents, and sum the total height at
each location?  This idea leads to the lower-left visualization.  It is perhaps
not as clean as a histogram, but the fact that the data drive the block
locations mean that it is a much better representation of the underlying
data.</p>
<p>This visualization is an example of a <em>kernel density estimation</em>, in this case
with a top-hat kernel (i.e. a square block at each point).  We can recover a
smoother distribution by using a smoother kernel.  The bottom-right plot shows
a Gaussian kernel density estimate, in which each point contributes a Gaussian
curve to the total.  The result is a smooth density estimate which is derived
from the data, and functions as a powerful non-parametric model of the
distribution of points.</p>
</div>
<div class="section" id="kernel-density-estimation">
<span id="kernel-density"></span><h2>2.9.2. Kernel Density Estimation<a class="headerlink" href="#kernel-density-estimation" title="Permalink to this headline">¶</a></h2>
<p>Kernel density estimation in scikit-learn is implemented in the
<a class="reference internal" href="generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity" title="sklearn.neighbors.KernelDensity"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.neighbors.KernelDensity</span></tt></a> estimator, which uses the
Ball Tree or KD Tree for efficient queries (see <a class="reference internal" href="neighbors.html#neighbors"><em>Nearest Neighbors</em></a> for
a discussion of these).  Though the above example
uses a 1D data set for simplicity, kernel density estimation can be
performed in any number of dimensions, though in practice the curse of
dimensionality causes its performance to degrade in high dimensions.</p>
<p>In the following figure, 100 points are drawn from a bimodal distribution,
and the kernel density estimates are shown for three choices of kernels:</p>
<p class="centered">
<strong><a class="reference external image-reference" href="../auto_examples/neighbors/plot_kde_1d.html"><img alt="kde_1d_distribution" src="../_images/plot_kde_1d_31.png" style="width: 640.0px; height: 480.0px;" /></a>
</strong></p><p>It&#8217;s clear how the kernel shape affects the smoothness of the resulting
distribution.  The scikit-learn kernel density estimator can be used as
follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors.kde</span> <span class="kn">import</span> <span class="n">KernelDensity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kde</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;gaussian&#39;</span><span class="p">,</span> <span class="n">bandwidth</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([-0.41075698, -0.41075698, -0.41076071, -0.41075698, -0.41075698,</span>
<span class="go">       -0.41076071])</span>
</pre></div>
</div>
<p>Here we have used <tt class="docutils literal"><span class="pre">kernel='gaussian'</span></tt>, as seen above.
Mathematically, a kernel is a positive function <img class="math" src="../_images/math/08b2238649d4005da6c6591a962c50452243ab30.png" alt="K(x;h)"/>
which is controlled by the bandwidth parameter <img class="math" src="../_images/math/cbb80ad77aa7a5e227d5a46bc44d235284106cfc.png" alt="h"/>.
Given this kernel form, the density estimate at a point <img class="math" src="../_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/> within
a group of points <img class="math" src="../_images/math/08fe58960982174a36d8a65ef1af0d3acf7ace5a.png" alt="x_i; i=1\cdots N"/> is given by:</p>
<div class="math">
<p><img src="../_images/math/57b73b19a75bba7654c1c5076915da8feca8bdb0.png" alt="\rho_K(y) = \sum_{i=1}^{N} K((y - x_i) / h)"/></p>
</div><p>The bandwidth here acts as a smoothing parameter, controlling the tradeoff
between bias and variance in the result.  A large bandwidth leads to a very
smooth (i.e. high-bias) density distribution.  A small bandwidth leads
to an unsmooth (i.e. high-variance) density distribution.</p>
<p><a class="reference internal" href="generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity" title="sklearn.neighbors.KernelDensity"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.neighbors.KernelDensity</span></tt></a> implements several common kernel
forms, which are shown in the following figure:</p>
<p class="centered">
<strong><a class="reference external image-reference" href="../auto_examples/neighbors/plot_kde_1d.html"><img alt="kde_kernels" src="../_images/plot_kde_1d_21.png" style="width: 640.0px; height: 480.0px;" /></a>
</strong></p><p>The form of these kernels is as follows:</p>
<ul>
<li><p class="first">Gaussian kernel (<tt class="docutils literal"><span class="pre">kernel</span> <span class="pre">=</span> <span class="pre">'gaussian'</span></tt>)</p>
<p><img class="math" src="../_images/math/6f487de9cdc05af1d24272b8f36db9f03d5abb06.png" alt="K(x; h) \propto \exp(- \frac{x^2}{2h^2} )"/></p>
</li>
<li><p class="first">Tophat kernel (<tt class="docutils literal"><span class="pre">kernel</span> <span class="pre">=</span> <span class="pre">'tophat'</span></tt>)</p>
<p><img class="math" src="../_images/math/9e63a29c9ced920f6aae821ab3e29e01675f2f12.png" alt="K(x; h) \propto 1"/> if <img class="math" src="../_images/math/caea9921eb427449d088d91b6755d96e7cf1b214.png" alt="x &lt; h"/></p>
</li>
<li><p class="first">Epanechnikov kernel (<tt class="docutils literal"><span class="pre">kernel</span> <span class="pre">=</span> <span class="pre">'epanechnikov'</span></tt>)</p>
<p><img class="math" src="../_images/math/ea8752ded7c5816c51d31d20e7d93f52fbf41f49.png" alt="K(x; h) \propto 1 - \frac{x^2}{h^2}"/></p>
</li>
<li><p class="first">Exponential kernel (<tt class="docutils literal"><span class="pre">kernel</span> <span class="pre">=</span> <span class="pre">'exponential'</span></tt>)</p>
<p><img class="math" src="../_images/math/db5929be150f149215fd88053de8d36c6608bef6.png" alt="K(x; h) \propto \exp(-x/h)"/></p>
</li>
<li><p class="first">Linear kernel (<tt class="docutils literal"><span class="pre">kernel</span> <span class="pre">=</span> <span class="pre">'linear'</span></tt>)</p>
<p><img class="math" src="../_images/math/d432478525db6c0e8aeb2a6fa0a8ca3bf0afe7b5.png" alt="K(x; h) \propto 1 - x/h"/> if <img class="math" src="../_images/math/caea9921eb427449d088d91b6755d96e7cf1b214.png" alt="x &lt; h"/></p>
</li>
<li><p class="first">Cosine kernel (<tt class="docutils literal"><span class="pre">kernel</span> <span class="pre">=</span> <span class="pre">'cosine'</span></tt>)</p>
<p><img class="math" src="../_images/math/b808030270971971d42ec8e62398634b513667c3.png" alt="K(x; h) \propto \cos(\frac{\pi x}{2h})"/> if <img class="math" src="../_images/math/caea9921eb427449d088d91b6755d96e7cf1b214.png" alt="x &lt; h"/></p>
</li>
</ul>
<p>The kernel density estimator can be used with any of the valid distance
metrics (see <a class="reference internal" href="generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.neighbors.DistanceMetric</span></tt></a> for a list of available metrics), though
the results are properly normalized only for the Euclidean metric.  One
particularly useful metric is the
<a class="reference external" href="http://en.wikipedia.org/wiki/Haversine_formula">Haversine distance</a>
which measures the angular distance between points on a sphere.  Here
is an example of using a kernel density estimate for a visualization
of geospatial data, in this case the distribution of observations of two
different species on the South American continent:</p>
<p class="centered">
<strong><a class="reference external image-reference" href="../auto_examples/neighbors/plot_species_kde.html"><img alt="species_kde" src="../_images/plot_species_kde_11.png" style="width: 640.0px; height: 480.0px;" /></a>
</strong></p><p>One other useful application of kernel density estimation is to learn a
non-parametric generative model of a dataset in order to efficiently
draw new samples from this generative model.
Here is an example of using this process to
create a new set of hand-written digits, using a Gaussian kernel learned
on a PCA projection of the data:</p>
<p class="centered">
<strong><a class="reference external image-reference" href="../auto_examples/neighbors/plot_digits_kde_sampling.html"><img alt="digits_kde" src="../_images/plot_digits_kde_sampling_11.png" style="width: 640.0px; height: 480.0px;" /></a>
</strong></p><p>The &#8220;new&#8221; data consists of linear combinations of the input data, with weights
probabilistically drawn given the KDE model.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/neighbors/plot_kde_1d.html#example-neighbors-plot-kde-1d-py"><em>Simple 1D Kernel Density Estimation</em></a>: computation of simple kernel
density estimates in one dimension.</li>
<li><a class="reference internal" href="../auto_examples/neighbors/plot_digits_kde_sampling.html#example-neighbors-plot-digits-kde-sampling-py"><em>Kernel Density Estimation</em></a>: an example of using
Kernel Density estimation to learn a generative model of the hand-written
digits data, and drawing new samples from this model.</li>
<li><a class="reference internal" href="../auto_examples/neighbors/plot_species_kde.html#example-neighbors-plot-species-kde-py"><em>Kernel Density Estimate of Species Distributions</em></a>: an example of Kernel Density
estimation using the Haversine distance metric to visualize geospatial data</li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010 - 2014, scikit-learn developers (BSD License).
      <a href="../_sources/modules/density.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="hmm.html">Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="neural_networks.html">Next
      </a>
    </div>
    <div class="buttonPrevious">
      <a href="../np-modindex.html">Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="../py-modindex.html">Next
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>