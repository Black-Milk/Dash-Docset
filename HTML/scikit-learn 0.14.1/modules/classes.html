
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>Reference &mdash; scikit-learn 0.14.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.14.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="top" title="scikit-learn 0.14.1 documentation" href="../index.html" />
    <link rel="next" title="sklearn.base.BaseEstimator" href="generated/sklearn.base.BaseEstimator.html" />
    <link rel="prev" title="The 20 newsgroups text dataset" href="../datasets/twenty_newsgroups.html" />
  
   
       <script type="text/javascript" src="../_static/sidebar.js"></script>
   
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/classes.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
    var bodywrapper = $('.bodywrapper');
    var sidebarbutton = $('#sidebarbutton');
    sidebarbutton.css({'height': '900px'});
  </script>

  </head>
  <body>

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../index.html">
            <img src="../_static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar">
            <ul>
                <li><a href="../../stable/index.html">Home</a></li>
                <li><a href="../../stable/install.html">Installation</a></li>
                <li class="btn-li"><div class="btn-group">
		      <a href="../documentation.html">Documentation</a>
		      <a class="btn dropdown-toggle" data-toggle="dropdown">
			     <span class="caret"></span>
		      </a>
		      <ul class="dropdown-menu">
			<li class="link-title">Scikit-learn 0.14 (stable)</li>
			<li><a href="../tutorial/index.html">Tutorials</a></li>
			<li><a href="../user_guide.html">User guide</a></li>
			<li><a href="#">API</a></li>
			<li class="divider"></li>
		        <li><a href="http://scikit-learn.org/dev/documentation.html">Development</a></li>
		        <li><a href="http://scikit-learn.org/0.13/">Scikit-learn 0.13</a></li>
		        <li><a href="http://scikit-learn.org/0.12/">Scikit-learn 0.12</a></li>
		        <li><a href="http://scikit-learn.org/0.11/">Scikit-learn 0.11</a></li>
		        <li><a href="../documentation.html">More versions...</a></li>
		      </ul>
		    </div>
		</li>
            <li><a href="../auto_examples/index.html">Examples</a></li>
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel rellarge">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="../datasets/twenty_newsgroups.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        The 20 newsgroup...
        </span>
            <span class="hiddenrellink">
            The 20 newsgroups text dataset
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="generated/sklearn.base.BaseEstimator.html"
        accesskey="N">Next
        <br/>
        <span class="smallrellink">
        sklearn.base.Bas...
        </span>
            <span class="hiddenrellink">
            sklearn.base.BaseEstimator
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="../np-modindex.html"
        >Modules
        <br/>
        <span class="smallrellink">
        Python Module In...
        </span>
            <span class="hiddenrellink">
            Python Module Index
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="../py-modindex.html"
        >Modules
        <br/>
        <span class="smallrellink">
        Python Module In...
        </span>
            <span class="hiddenrellink">
            Python Module Index
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
    </div>
    
      <p class="doc-version">This documentation is for scikit-learn <strong>version 0.14.1</strong> &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    <p class="citing">If you use the software, please consider <a href="../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <ul>
<li><a class="reference internal" href="#">Reference</a><ul>
<li><a class="reference internal" href="#module-sklearn.base"><tt class="docutils literal"><span class="pre">sklearn.base</span></tt>: Base classes and utility functions</a><ul>
<li><a class="reference internal" href="#base-classes">Base classes</a></li>
<li><a class="reference internal" href="#functions">Functions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.cluster"><tt class="docutils literal"><span class="pre">sklearn.cluster</span></tt>: Clustering</a><ul>
<li><a class="reference internal" href="#classes">Classes</a></li>
<li><a class="reference internal" href="#id1">Functions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.cluster.bicluster"><tt class="docutils literal"><span class="pre">sklearn.cluster.bicluster</span></tt>: Biclustering</a><ul>
<li><a class="reference internal" href="#id2">Classes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.covariance"><tt class="docutils literal"><span class="pre">sklearn.covariance</span></tt>: Covariance Estimators</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.cross_validation"><tt class="docutils literal"><span class="pre">sklearn.cross_validation</span></tt>: Cross Validation</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.datasets"><tt class="docutils literal"><span class="pre">sklearn.datasets</span></tt>: Datasets</a><ul>
<li><a class="reference internal" href="#loaders">Loaders</a></li>
<li><a class="reference internal" href="#samples-generator">Samples generator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.decomposition"><tt class="docutils literal"><span class="pre">sklearn.decomposition</span></tt>: Matrix Decomposition</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.dummy"><tt class="docutils literal"><span class="pre">sklearn.dummy</span></tt>: Dummy estimators</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.ensemble"><tt class="docutils literal"><span class="pre">sklearn.ensemble</span></tt>: Ensemble Methods</a><ul>
<li><a class="reference internal" href="#module-sklearn.ensemble.partial_dependence">partial dependence</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.feature_extraction"><tt class="docutils literal"><span class="pre">sklearn.feature_extraction</span></tt>: Feature Extraction</a><ul>
<li><a class="reference internal" href="#module-sklearn.feature_extraction.image">From images</a></li>
<li><a class="reference internal" href="#module-sklearn.feature_extraction.text">From text</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.feature_selection"><tt class="docutils literal"><span class="pre">sklearn.feature_selection</span></tt>: Feature Selection</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.gaussian_process"><tt class="docutils literal"><span class="pre">sklearn.gaussian_process</span></tt>: Gaussian Processes</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.grid_search"><tt class="docutils literal"><span class="pre">sklearn.grid_search</span></tt>: Grid Search</a></li>
<li><a class="reference internal" href="#module-sklearn.hmm"><tt class="docutils literal"><span class="pre">sklearn.hmm</span></tt>: Hidden Markov Models</a></li>
<li><a class="reference internal" href="#module-sklearn.isotonic"><tt class="docutils literal"><span class="pre">sklearn.isotonic</span></tt>: Isotonic regression</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.kernel_approximation"><tt class="docutils literal"><span class="pre">sklearn.kernel_approximation</span></tt> Kernel Approximation</a></li>
<li><a class="reference internal" href="#module-sklearn.lda"><tt class="docutils literal"><span class="pre">sklearn.lda</span></tt>: Linear Discriminant Analysis</a></li>
<li><a class="reference internal" href="#sklearn-learning-curve-learning-curve-evaluation"><tt class="docutils literal"><span class="pre">sklearn.learning_curve</span></tt> Learning curve evaluation</a></li>
<li><a class="reference internal" href="#module-sklearn.linear_model"><tt class="docutils literal"><span class="pre">sklearn.linear_model</span></tt>: Generalized Linear Models</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.manifold"><tt class="docutils literal"><span class="pre">sklearn.manifold</span></tt>: Manifold Learning</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#sklearn-metrics-metrics"><tt class="docutils literal"><span class="pre">sklearn.metrics</span></tt>: Metrics</a><ul>
<li><a class="reference internal" href="#model-selection-interface">Model Selection Interface</a></li>
<li><a class="reference internal" href="#classification-metrics">Classification metrics</a></li>
<li><a class="reference internal" href="#regression-metrics">Regression metrics</a></li>
<li><a class="reference internal" href="#clustering-metrics">Clustering metrics</a></li>
<li><a class="reference internal" href="#biclustering-metrics">Biclustering metrics</a></li>
<li><a class="reference internal" href="#module-sklearn.metrics.pairwise">Pairwise metrics</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.mixture"><tt class="docutils literal"><span class="pre">sklearn.mixture</span></tt>: Gaussian Mixture Models</a></li>
<li><a class="reference internal" href="#module-sklearn.multiclass"><tt class="docutils literal"><span class="pre">sklearn.multiclass</span></tt>: Multiclass and multilabel classification</a><ul>
<li><a class="reference internal" href="#multiclass-and-multilabel-classification-strategies">Multiclass and multilabel classification strategies</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.naive_bayes"><tt class="docutils literal"><span class="pre">sklearn.naive_bayes</span></tt>: Naive Bayes</a></li>
<li><a class="reference internal" href="#module-sklearn.neighbors"><tt class="docutils literal"><span class="pre">sklearn.neighbors</span></tt>: Nearest Neighbors</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.neural_network"><tt class="docutils literal"><span class="pre">sklearn.neural_network</span></tt>: Neural network models</a></li>
<li><a class="reference internal" href="#module-sklearn.cross_decomposition"><tt class="docutils literal"><span class="pre">sklearn.cross_decomposition</span></tt>: Cross decomposition</a></li>
<li><a class="reference internal" href="#module-sklearn.pipeline"><tt class="docutils literal"><span class="pre">sklearn.pipeline</span></tt>: Pipeline</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.preprocessing"><tt class="docutils literal"><span class="pre">sklearn.preprocessing</span></tt>: Preprocessing and Normalization</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.qda"><tt class="docutils literal"><span class="pre">sklearn.qda</span></tt>: Quadratic Discriminant Analysis</a></li>
<li><a class="reference internal" href="#module-sklearn.random_projection"><tt class="docutils literal"><span class="pre">sklearn.random_projection</span></tt>: Random projection</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.semi_supervised"><tt class="docutils literal"><span class="pre">sklearn.semi_supervised</span></tt> Semi-Supervised Learning</a></li>
<li><a class="reference internal" href="#module-sklearn.svm"><tt class="docutils literal"><span class="pre">sklearn.svm</span></tt>: Support Vector Machines</a><ul>
<li><a class="reference internal" href="#estimators">Estimators</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#low-level-methods">Low-level methods</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.tree"><tt class="docutils literal"><span class="pre">sklearn.tree</span></tt>: Decision Trees</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-sklearn.utils"><tt class="docutils literal"><span class="pre">sklearn.utils</span></tt>: Utilities</a></li>
</ul>
</li>
</ul>

    </div>
</div>



      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="reference">
<h1>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h1>
<p>This is the class and function reference of scikit-learn. Please refer to
the <a class="reference internal" href="../user_guide.html#user-guide"><em>full user guide</em></a> for further details, as the class and
function raw specifications may not be enough to give full guidelines on their
uses.</p>
<div class="section" id="module-sklearn.base">
<span id="sklearn-base-base-classes-and-utility-functions"></span><span id="base-ref"></span><h2><a class="reference internal" href="#module-sklearn.base" title="sklearn.base"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.base</span></tt></a>: Base classes and utility functions<a class="headerlink" href="#module-sklearn.base" title="Permalink to this headline">¶</a></h2>
<p>Base class for all estimators.</p>
<div class="section" id="base-classes">
<h3>Base classes<a class="headerlink" href="#base-classes" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator"><tt class="xref py py-obj docutils literal"><span class="pre">base.BaseEstimator</span></tt></a></td>
<td>Base class for all estimators in scikit-learn   ..</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><tt class="xref py py-obj docutils literal"><span class="pre">base.ClassifierMixin</span></tt></a></td>
<td>Mixin class for all classifiers in scikit-learn.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.base.ClusterMixin.html#sklearn.base.ClusterMixin" title="sklearn.base.ClusterMixin"><tt class="xref py py-obj docutils literal"><span class="pre">base.ClusterMixin</span></tt></a></td>
<td>Mixin class for all cluster estimators in scikit-learn.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="sklearn.base.RegressorMixin"><tt class="xref py py-obj docutils literal"><span class="pre">base.RegressorMixin</span></tt></a></td>
<td>Mixin class for all regression estimators in scikit-learn.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin" title="sklearn.base.TransformerMixin"><tt class="xref py py-obj docutils literal"><span class="pre">base.TransformerMixin</span></tt></a></td>
<td>Mixin class for all transformers in scikit-learn.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone"><tt class="xref py py-obj docutils literal"><span class="pre">base.clone</span></tt></a>(estimator[,&nbsp;safe])</td>
<td>Constructs a new estimator with the same parameters.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.cluster">
<span id="sklearn-cluster-clustering"></span><span id="cluster-ref"></span><h2><a class="reference internal" href="#module-sklearn.cluster" title="sklearn.cluster"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.cluster</span></tt></a>: Clustering<a class="headerlink" href="#module-sklearn.cluster" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.cluster" title="sklearn.cluster"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.cluster</span></tt></a> module gathers popular unsupervised clustering
algorithms.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="clustering.html#clustering"><em>Clustering</em></a> section for further details.</p>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation" title="sklearn.cluster.AffinityPropagation"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.AffinityPropagation</span></tt></a>([damping,&nbsp;...])</td>
<td>Perform Affinity Propagation Clustering of data   :Parameters:      <strong>damping: float, optional, default: 0.5</strong> :           Damping factor between 0.5 and 1.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.DBSCAN</span></tt></a>([eps,&nbsp;min_samples,&nbsp;metric,&nbsp;...])</td>
<td>Perform DBSCAN clustering from vector array or distance matrix.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.KMeans</span></tt></a>([n_clusters,&nbsp;init,&nbsp;n_init,&nbsp;...])</td>
<td>K-Means clustering   :Parameters:      <strong>n_clusters</strong> : int, optional, default: 8          The number of clusters to form as well as the number of         centroids to generate.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.MiniBatchKMeans</span></tt></a>([n_clusters,&nbsp;init,&nbsp;...])</td>
<td>Mini-Batch K-Means clustering   :Parameters:      <strong>n_clusters</strong> : int, optional, default: 8          The number of clusters to form as well as the number of         centroids to generate.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift" title="sklearn.cluster.MeanShift"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.MeanShift</span></tt></a>([bandwidth,&nbsp;seeds,&nbsp;...])</td>
<td>MeanShift clustering   :Parameters:      <strong>bandwidth</strong> : float, optional          Bandwidth used in the RBF kernel         If not set, the bandwidth is estimated.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" title="sklearn.cluster.SpectralClustering"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.SpectralClustering</span></tt></a>([n_clusters,&nbsp;...])</td>
<td>Apply clustering to a projection to the normalized laplacian.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.Ward.html#sklearn.cluster.Ward" title="sklearn.cluster.Ward"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.Ward</span></tt></a>([n_clusters,&nbsp;memory,&nbsp;...])</td>
<td>Ward hierarchical clustering: constructs a tree and cuts it.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id1">
<h3>Functions<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.estimate_bandwidth.html#sklearn.cluster.estimate_bandwidth" title="sklearn.cluster.estimate_bandwidth"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.estimate_bandwidth</span></tt></a>(X[,&nbsp;quantile,&nbsp;...])</td>
<td>Estimate the bandwidth to use with MeanShift algorithm   :Parameters:      <strong>X</strong> : array [n_samples, n_features]          Input points.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cluster.k_means.html#sklearn.cluster.k_means" title="sklearn.cluster.k_means"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.k_means</span></tt></a>(X,&nbsp;n_clusters[,&nbsp;init,&nbsp;...])</td>
<td>K-means clustering algorithm.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.ward_tree.html#sklearn.cluster.ward_tree" title="sklearn.cluster.ward_tree"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.ward_tree</span></tt></a>(X[,&nbsp;connectivity,&nbsp;...])</td>
<td>Ward clustering based on a Feature matrix.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cluster.affinity_propagation.html#sklearn.cluster.affinity_propagation" title="sklearn.cluster.affinity_propagation"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.affinity_propagation</span></tt></a>(S[,&nbsp;...])</td>
<td>Perform Affinity Propagation Clustering of data   :Parameters:      <strong>S: array [n_samples, n_samples]</strong> :           Matrix of similarities between points               <strong>preference: array [n_samples,] or float, optional, default: None</strong> :           Preferences for each point - points with larger values of         preferences are more likely to be chosen as exemplars.</td>
</tr>
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">cluster.dbscan</span></tt>(X[,&nbsp;eps,&nbsp;min_samples,&nbsp;...])</td>
<td>Perform DBSCAN clustering from vector array or distance matrix.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cluster.mean_shift.html#sklearn.cluster.mean_shift" title="sklearn.cluster.mean_shift"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.mean_shift</span></tt></a>(X[,&nbsp;bandwidth,&nbsp;seeds,&nbsp;...])</td>
<td>Perform MeanShift Clustering of data using a flat kernel  Seed using a binning technique for scalability.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.spectral_clustering.html#sklearn.cluster.spectral_clustering" title="sklearn.cluster.spectral_clustering"><tt class="xref py py-obj docutils literal"><span class="pre">cluster.spectral_clustering</span></tt></a>(affinity[,&nbsp;...])</td>
<td>Apply clustering to a projection to the normalized laplacian.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.cluster.bicluster">
<span id="sklearn-cluster-bicluster-biclustering"></span><span id="bicluster-ref"></span><h2><a class="reference internal" href="#module-sklearn.cluster.bicluster" title="sklearn.cluster.bicluster"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.cluster.bicluster</span></tt></a>: Biclustering<a class="headerlink" href="#module-sklearn.cluster.bicluster" title="Permalink to this headline">¶</a></h2>
<p><strong>User guide:</strong> See the <a class="reference internal" href="biclustering.html#biclustering"><em>Biclustering</em></a> section for further details.</p>
<div class="section" id="id2">
<h3>Classes<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cluster.bicluster.SpectralBiclustering.html#sklearn.cluster.bicluster.SpectralBiclustering" title="sklearn.cluster.bicluster.SpectralBiclustering"><tt class="xref py py-obj docutils literal"><span class="pre">SpectralBiclustering</span></tt></a>([n_clusters,&nbsp;method,&nbsp;...])</td>
<td>Spectral biclustering (Kluger, 2003).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cluster.bicluster.SpectralCoclustering.html#sklearn.cluster.bicluster.SpectralCoclustering" title="sklearn.cluster.bicluster.SpectralCoclustering"><tt class="xref py py-obj docutils literal"><span class="pre">SpectralCoclustering</span></tt></a>([n_clusters,&nbsp;...])</td>
<td>Spectral Co-Clustering algorithm (Dhillon, 2001).</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.covariance">
<span id="sklearn-covariance-covariance-estimators"></span><span id="covariance-ref"></span><h2><a class="reference internal" href="#module-sklearn.covariance" title="sklearn.covariance"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.covariance</span></tt></a>: Covariance Estimators<a class="headerlink" href="#module-sklearn.covariance" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.covariance" title="sklearn.covariance"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.covariance</span></tt></a> module includes methods and algorithms to
robustly estimate the covariance of features given a set of points. The
precision matrix defined as the inverse of the covariance is also estimated.
Covariance estimation is closely related to the theory of Gaussian Graphical
Models.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="covariance.html#covariance"><em>Covariance estimation</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.covariance.EmpiricalCovariance.html#sklearn.covariance.EmpiricalCovariance" title="sklearn.covariance.EmpiricalCovariance"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.EmpiricalCovariance</span></tt></a>([...])</td>
<td>Maximum likelihood covariance estimator   :Parameters:      <strong>store_precision</strong> : bool          Specifies if the estimated precision is stored.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope" title="sklearn.covariance.EllipticEnvelope"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.EllipticEnvelope</span></tt></a>([...])</td>
<td>An object for detecting outliers in a Gaussian distributed dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.covariance.GraphLasso.html#sklearn.covariance.GraphLasso" title="sklearn.covariance.GraphLasso"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.GraphLasso</span></tt></a>([alpha,&nbsp;mode,&nbsp;tol,&nbsp;...])</td>
<td>Sparse inverse covariance estimation with an l1-penalized estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.covariance.GraphLassoCV.html#sklearn.covariance.GraphLassoCV" title="sklearn.covariance.GraphLassoCV"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.GraphLassoCV</span></tt></a>([alphas,&nbsp;...])</td>
<td>Sparse inverse covariance w/ cross-validated choice of the l1 penalty   :Parameters:      <strong>alphas</strong> : integer, or list positive float, optional          If an integer is given, it fixes the number of points on the         grids of alpha to be used.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.covariance.LedoitWolf.html#sklearn.covariance.LedoitWolf" title="sklearn.covariance.LedoitWolf"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.LedoitWolf</span></tt></a>([store_precision,&nbsp;...])</td>
<td>LedoitWolf Estimator  Ledoit-Wolf is a particular form of shrinkage, where the shrinkage coefficient is computed using O.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.covariance.MinCovDet.html#sklearn.covariance.MinCovDet" title="sklearn.covariance.MinCovDet"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.MinCovDet</span></tt></a>([store_precision,&nbsp;...])</td>
<td>Minimum Covariance Determinant (MCD): robust estimator of covariance.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.covariance.OAS.html#sklearn.covariance.OAS" title="sklearn.covariance.OAS"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.OAS</span></tt></a>([store_precision,&nbsp;...])</td>
<td>Oracle Approximating Shrinkage Estimator  OAS is a particular form of shrinkage described in &#8220;Shrinkage Algorithms for MMSE Covariance Estimation&#8221; Chen et al., IEEE Trans.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.covariance.ShrunkCovariance.html#sklearn.covariance.ShrunkCovariance" title="sklearn.covariance.ShrunkCovariance"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.ShrunkCovariance</span></tt></a>([...])</td>
<td>Covariance estimator with shrinkage   :Parameters:      <strong>store_precision</strong> : bool          Specify if the estimated precision is stored               <strong>shrinkage</strong> : float, 0 &lt;= shrinkage &lt;= 1          Coefficient in the convex combination used for the computation         of the shrunk estimate.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.covariance.empirical_covariance.html#sklearn.covariance.empirical_covariance" title="sklearn.covariance.empirical_covariance"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.empirical_covariance</span></tt></a>(X[,&nbsp;...])</td>
<td>Computes the Maximum likelihood covariance estimator   :Parameters:      <strong>X</strong> : 2D ndarray, shape (n_samples, n_features)          Data from which to compute the covariance estimate               <strong>assume_centered</strong> : Boolean          If True, data are not centered before computation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.covariance.ledoit_wolf.html#sklearn.covariance.ledoit_wolf" title="sklearn.covariance.ledoit_wolf"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.ledoit_wolf</span></tt></a>(X[,&nbsp;assume_centered,&nbsp;...])</td>
<td>Estimates the shrunk Ledoit-Wolf covariance matrix.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.covariance.shrunk_covariance.html#sklearn.covariance.shrunk_covariance" title="sklearn.covariance.shrunk_covariance"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.shrunk_covariance</span></tt></a>(emp_cov[,&nbsp;...])</td>
<td>Calculates a covariance matrix shrunk on the diagonal   :Parameters:      <strong>emp_cov</strong> : array-like, shape (n_features, n_features)          Covariance matrix to be shrunk               <strong>shrinkage</strong> : float, 0 &lt;= shrinkage &lt;= 1          Coefficient in the convex combination used for the computation         of the shrunk estimate.</td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">covariance.oas</span></tt>(X[,&nbsp;assume_centered])</td>
<td>Estimate covariance with the Oracle Approximating Shrinkage algorithm.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.covariance.graph_lasso.html#sklearn.covariance.graph_lasso" title="sklearn.covariance.graph_lasso"><tt class="xref py py-obj docutils literal"><span class="pre">covariance.graph_lasso</span></tt></a>(emp_cov,&nbsp;alpha[,&nbsp;...])</td>
<td>l1-penalized covariance estimator</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.cross_validation">
<span id="sklearn-cross-validation-cross-validation"></span><span id="cross-validation-ref"></span><h2><a class="reference internal" href="#module-sklearn.cross_validation" title="sklearn.cross_validation"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.cross_validation</span></tt></a>: Cross Validation<a class="headerlink" href="#module-sklearn.cross_validation" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.cross_validation" title="sklearn.cross_validation"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.cross_validation</span></tt></a> module includes utilities for cross-
validation and performance evaluation.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="cross_validation.html#cross-validation"><em>Cross-validation: evaluating estimator performance</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_validation.Bootstrap.html#sklearn.cross_validation.Bootstrap" title="sklearn.cross_validation.Bootstrap"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.Bootstrap</span></tt></a>(n[,&nbsp;n_iter,&nbsp;...])</td>
<td>Random sampling with replacement cross-validation iterator  Provides train/test indices to split data in train test sets while resampling the input n_iter times: each time a new random split of the data is performed and then samples are drawn (with replacement) on each side of the split to build the training and test sets.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_validation.KFold.html#sklearn.cross_validation.KFold" title="sklearn.cross_validation.KFold"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.KFold</span></tt></a>(n[,&nbsp;n_folds,&nbsp;...])</td>
<td>K-Folds cross validation iterator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_validation.LeaveOneLabelOut.html#sklearn.cross_validation.LeaveOneLabelOut" title="sklearn.cross_validation.LeaveOneLabelOut"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.LeaveOneLabelOut</span></tt></a>(labels[,&nbsp;...])</td>
<td>Leave-One-Label_Out cross-validation iterator  Provides train/test indices to split data according to a third-party provided label.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_validation.LeaveOneOut.html#sklearn.cross_validation.LeaveOneOut" title="sklearn.cross_validation.LeaveOneOut"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.LeaveOneOut</span></tt></a>(n[,&nbsp;indices])</td>
<td>Leave-One-Out cross validation iterator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_validation.LeavePLabelOut.html#sklearn.cross_validation.LeavePLabelOut" title="sklearn.cross_validation.LeavePLabelOut"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.LeavePLabelOut</span></tt></a>(labels,&nbsp;p[,&nbsp;...])</td>
<td>Leave-P-Label_Out cross-validation iterator  Provides train/test indices to split data according to a third-party provided label.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_validation.LeavePOut.html#sklearn.cross_validation.LeavePOut" title="sklearn.cross_validation.LeavePOut"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.LeavePOut</span></tt></a>(n,&nbsp;p[,&nbsp;indices])</td>
<td>Leave-P-Out cross validation iterator  Provides train/test indices to split data in train test sets.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_validation.StratifiedKFold.html#sklearn.cross_validation.StratifiedKFold" title="sklearn.cross_validation.StratifiedKFold"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.StratifiedKFold</span></tt></a>(y[,&nbsp;...])</td>
<td>Stratified K-Folds cross validation iterator  Provides train/test indices to split data in train test sets.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_validation.ShuffleSplit.html#sklearn.cross_validation.ShuffleSplit" title="sklearn.cross_validation.ShuffleSplit"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.ShuffleSplit</span></tt></a>(n[,&nbsp;n_iter,&nbsp;...])</td>
<td>Random permutation cross-validation iterator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_validation.StratifiedShuffleSplit.html#sklearn.cross_validation.StratifiedShuffleSplit" title="sklearn.cross_validation.StratifiedShuffleSplit"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.StratifiedShuffleSplit</span></tt></a>(y[,&nbsp;...])</td>
<td>Stratified ShuffleSplit cross validation iterator  Provides train/test indices to split data in train test sets.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_validation.train_test_split.html#sklearn.cross_validation.train_test_split" title="sklearn.cross_validation.train_test_split"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.train_test_split</span></tt></a>(*arrays,&nbsp;...)</td>
<td>Split arrays or matrices into random train and test subsets  Quick utility that wraps calls to <tt class="docutils literal"><span class="pre">check_arrays</span></tt> and <tt class="docutils literal"><span class="pre">next(iter(ShuffleSplit(n_samples)))</span></tt> and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score" title="sklearn.cross_validation.cross_val_score"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.cross_val_score</span></tt></a>(estimator,&nbsp;X)</td>
<td>Evaluate a score by cross-validation   :Parameters:      <strong>estimator</strong> : estimator object implementing &#8216;fit&#8217;          The object to use to fit the data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_validation.permutation_test_score.html#sklearn.cross_validation.permutation_test_score" title="sklearn.cross_validation.permutation_test_score"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.permutation_test_score</span></tt></a>(...)</td>
<td>Evaluate the significance of a cross-validated score with permutations   :Parameters:      <strong>estimator</strong> : estimator object implementing &#8216;fit&#8217;          The object to use to fit the data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_validation.check_cv.html#sklearn.cross_validation.check_cv" title="sklearn.cross_validation.check_cv"><tt class="xref py py-obj docutils literal"><span class="pre">cross_validation.check_cv</span></tt></a>(cv[,&nbsp;X,&nbsp;y,&nbsp;classifier])</td>
<td>Input checker utility for building a CV in a user friendly way.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.datasets">
<span id="sklearn-datasets-datasets"></span><span id="datasets-ref"></span><h2><a class="reference internal" href="#module-sklearn.datasets" title="sklearn.datasets"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.datasets</span></tt></a>: Datasets<a class="headerlink" href="#module-sklearn.datasets" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.datasets" title="sklearn.datasets"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.datasets</span></tt></a> module includes utilities to load datasets,
including methods to load and fetch popular reference datasets. It also
features some artificial data generators.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="../datasets/index.html#datasets"><em>Dataset loading utilities</em></a> section for further details.</p>
<div class="section" id="loaders">
<h3>Loaders<a class="headerlink" href="#loaders" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups" title="sklearn.datasets.fetch_20newsgroups"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_20newsgroups</span></tt></a>([data_home,&nbsp;...])</td>
<td>Load the filenames and data from the 20 newsgroups dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized" title="sklearn.datasets.fetch_20newsgroups_vectorized"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_20newsgroups_vectorized</span></tt></a>([...])</td>
<td>Load the 20 newsgroups dataset and transform it into tf-idf vectors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston" title="sklearn.datasets.load_boston"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_boston</span></tt></a>()</td>
<td>Load and return the boston house-prices dataset (regression).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes" title="sklearn.datasets.load_diabetes"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_diabetes</span></tt></a>()</td>
<td>Load and return the diabetes dataset (regression).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits" title="sklearn.datasets.load_digits"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_digits</span></tt></a>([n_class])</td>
<td>Load and return the digits dataset (classification).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.load_files.html#sklearn.datasets.load_files" title="sklearn.datasets.load_files"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_files</span></tt></a>(container_path[,&nbsp;...])</td>
<td>Load text files with categories as subfolder names.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris" title="sklearn.datasets.load_iris"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_iris</span></tt></a>()</td>
<td>Load and return the iris dataset (classification).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.load_lfw_pairs.html#sklearn.datasets.load_lfw_pairs" title="sklearn.datasets.load_lfw_pairs"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_lfw_pairs</span></tt></a>([download_if_missing])</td>
<td>Alias for fetch_lfw_pairs(download_if_missing=False)  Check fetch_lfw_pairs.__doc__ for the documentation and parameter list.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_lfw_pairs.html#sklearn.datasets.fetch_lfw_pairs" title="sklearn.datasets.fetch_lfw_pairs"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_lfw_pairs</span></tt></a>([subset,&nbsp;...])</td>
<td>Loader for the Labeled Faces in the Wild (LFW) pairs dataset  This dataset is a collection of JPEG pictures of famous people collected on the internet, all details are available on the official website:      <a class="reference external" href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a>  Each picture is centered on a single face.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.load_lfw_people.html#sklearn.datasets.load_lfw_people" title="sklearn.datasets.load_lfw_people"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_lfw_people</span></tt></a>([download_if_missing])</td>
<td>Alias for fetch_lfw_people(download_if_missing=False)  Check fetch_lfw_people.__doc__ for the documentation and parameter list.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_lfw_people.html#sklearn.datasets.fetch_lfw_people" title="sklearn.datasets.fetch_lfw_people"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_lfw_people</span></tt></a>([data_home,&nbsp;...])</td>
<td>Loader for the Labeled Faces in the Wild (LFW) people dataset  This dataset is a collection of JPEG pictures of famous people collected on the internet, all details are available on the official website:      <a class="reference external" href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a>  Each picture is centered on a single face.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.load_linnerud.html#sklearn.datasets.load_linnerud" title="sklearn.datasets.load_linnerud"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_linnerud</span></tt></a>()</td>
<td>Load and return the linnerud dataset (multivariate regression).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_mldata.html#sklearn.datasets.fetch_mldata" title="sklearn.datasets.fetch_mldata"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_mldata</span></tt></a>(dataname[,&nbsp;...])</td>
<td>Fetch an mldata.org data set  If the file does not exist yet, it is downloaded from mldata.org .</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces" title="sklearn.datasets.fetch_olivetti_faces"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_olivetti_faces</span></tt></a>([data_home,&nbsp;...])</td>
<td>Loader for the Olivetti faces data-set from AT&amp;T.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing" title="sklearn.datasets.fetch_california_housing"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_california_housing</span></tt></a>([...])</td>
<td>Loader for the California housing dataset from StatLib.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype" title="sklearn.datasets.fetch_covtype"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.fetch_covtype</span></tt></a>([data_home,&nbsp;...])</td>
<td>Load the covertype dataset, downloading it if necessary.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.load_mlcomp.html#sklearn.datasets.load_mlcomp" title="sklearn.datasets.load_mlcomp"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_mlcomp</span></tt></a>(name_or_id[,&nbsp;<a href="#id3"><span class="problematic" id="id4">set_</span></a>,&nbsp;...])</td>
<td>Load a datasets as downloaded from <a class="reference external" href="http://mlcomp.org">http://mlcomp.org</a>   :Parameters:      <strong>name_or_id</strong> : the integer id or the string name metadata of the MLComp          dataset to load               <strong>`set_`</strong> : select the portion to load: &#8216;train&#8217;, &#8216;test&#8217; or &#8216;raw&#8217;                <strong>mlcomp_root</strong> : the filesystem path to the root folder where MLComp datasets          are stored, if mlcomp_root is None, the MLCOMP_DATASETS_HOME         environment variable is looked up instead.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.load_sample_image.html#sklearn.datasets.load_sample_image" title="sklearn.datasets.load_sample_image"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_sample_image</span></tt></a>(image_name)</td>
<td>Load the numpy array of a single sample image   :Parameters:      <strong>image_name: {`china.jpg`, `flower.jpg`}</strong> :           The name of the sample image loaded  :Returns:      <strong>img: 3D array</strong> :           The image as a numpy array: height x width x color  ..</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.load_sample_images.html#sklearn.datasets.load_sample_images" title="sklearn.datasets.load_sample_images"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_sample_images</span></tt></a>()</td>
<td>Load sample images for image manipulation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.load_svmlight_file.html#sklearn.datasets.load_svmlight_file" title="sklearn.datasets.load_svmlight_file"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.load_svmlight_file</span></tt></a>(f[,&nbsp;n_features,&nbsp;...])</td>
<td>Load datasets in the svmlight / libsvm format into sparse CSR matrix  This format is a text-based format, with one sample per line.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.dump_svmlight_file.html#sklearn.datasets.dump_svmlight_file" title="sklearn.datasets.dump_svmlight_file"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.dump_svmlight_file</span></tt></a>(X,&nbsp;y,&nbsp;f[,&nbsp;...])</td>
<td>Dump the dataset in svmlight / libsvm file format.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="samples-generator">
<h3>Samples generator<a class="headerlink" href="#samples-generator" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs" title="sklearn.datasets.make_blobs"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_blobs</span></tt></a>([n_samples,&nbsp;n_features,&nbsp;...])</td>
<td>Generate isotropic Gaussian blobs for clustering.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification" title="sklearn.datasets.make_classification"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_classification</span></tt></a>([n_samples,&nbsp;...])</td>
<td>Generate a random n-class classification problem.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_circles.html#sklearn.datasets.make_circles" title="sklearn.datasets.make_circles"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_circles</span></tt></a>([n_samples,&nbsp;shuffle,&nbsp;...])</td>
<td>Make a large circle containing a smaller circle in 2d.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_friedman1.html#sklearn.datasets.make_friedman1" title="sklearn.datasets.make_friedman1"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_friedman1</span></tt></a>([n_samples,&nbsp;...])</td>
<td>Generate the &#8220;Friedman #1&#8221; regression problem  This dataset is described in Friedman [1] and Breiman [2].</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_friedman2.html#sklearn.datasets.make_friedman2" title="sklearn.datasets.make_friedman2"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_friedman2</span></tt></a>([n_samples,&nbsp;noise,&nbsp;...])</td>
<td>Generate the &#8220;Friedman #2&#8221; regression problem  This dataset is described in Friedman [1] and Breiman [2].</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_friedman3.html#sklearn.datasets.make_friedman3" title="sklearn.datasets.make_friedman3"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_friedman3</span></tt></a>([n_samples,&nbsp;noise,&nbsp;...])</td>
<td>Generate the &#8220;Friedman #3&#8221; regression problem  This dataset is described in Friedman [1] and Breiman [2].</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_gaussian_quantiles.html#sklearn.datasets.make_gaussian_quantiles" title="sklearn.datasets.make_gaussian_quantiles"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_gaussian_quantiles</span></tt></a>([mean,&nbsp;...])</td>
<td>Generate isotropic Gaussian and label samples by quantile  This classification dataset is constructed by taking a multi-dimensional standard normal distribution and defining classes separated by nested concentric multi-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the <img class="math" src="../_images/math/8bd0685e3bf9101859d24cf0e851651f182364c9.png" alt="\chi^2"/> distribution).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_hastie_10_2.html#sklearn.datasets.make_hastie_10_2" title="sklearn.datasets.make_hastie_10_2"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_hastie_10_2</span></tt></a>([n_samples,&nbsp;...])</td>
<td>Generates data for binary classification used in Hastie et al.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_low_rank_matrix.html#sklearn.datasets.make_low_rank_matrix" title="sklearn.datasets.make_low_rank_matrix"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_low_rank_matrix</span></tt></a>([n_samples,&nbsp;...])</td>
<td>Generate a mostly low rank matrix with bell-shaped singular values  Most of the variance can be explained by a bell-shaped curve of width effective_rank: the low rank part of the singular values profile is::      (1 - tail_strength) * exp(-1.0 * (i / effective_rank) ** 2)  The remaining singular values&#8217; tail is fat, decreasing as::      tail_strength * exp(-0.1 * i / effective_rank).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_moons.html#sklearn.datasets.make_moons" title="sklearn.datasets.make_moons"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_moons</span></tt></a>([n_samples,&nbsp;shuffle,&nbsp;...])</td>
<td>Make two interleaving half circles  A simple toy dataset to visualize clustering and classification algorithms.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification" title="sklearn.datasets.make_multilabel_classification"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_multilabel_classification</span></tt></a>([...])</td>
<td>Generate a random multilabel classification problem.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression" title="sklearn.datasets.make_regression"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_regression</span></tt></a>([n_samples,&nbsp;...])</td>
<td>Generate a random regression problem.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_s_curve.html#sklearn.datasets.make_s_curve" title="sklearn.datasets.make_s_curve"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_s_curve</span></tt></a>([n_samples,&nbsp;noise,&nbsp;...])</td>
<td>Generate an S curve dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_sparse_coded_signal.html#sklearn.datasets.make_sparse_coded_signal" title="sklearn.datasets.make_sparse_coded_signal"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_sparse_coded_signal</span></tt></a>(n_samples,&nbsp;...)</td>
<td>Generate a signal as a sparse combination of dictionary elements.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_sparse_spd_matrix.html#sklearn.datasets.make_sparse_spd_matrix" title="sklearn.datasets.make_sparse_spd_matrix"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_sparse_spd_matrix</span></tt></a>([dim,&nbsp;...])</td>
<td>Generate a sparse symmetric definite positive matrix.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_sparse_uncorrelated.html#sklearn.datasets.make_sparse_uncorrelated" title="sklearn.datasets.make_sparse_uncorrelated"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_sparse_uncorrelated</span></tt></a>([...])</td>
<td>Generate a random regression problem with sparse uncorrelated design  This dataset is described in Celeux et al [1].</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_spd_matrix.html#sklearn.datasets.make_spd_matrix" title="sklearn.datasets.make_spd_matrix"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_spd_matrix</span></tt></a>(n_dim[,&nbsp;random_state])</td>
<td>Generate a random symmetric, positive-definite matrix.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_swiss_roll.html#sklearn.datasets.make_swiss_roll" title="sklearn.datasets.make_swiss_roll"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_swiss_roll</span></tt></a>([n_samples,&nbsp;noise,&nbsp;...])</td>
<td>Generate a swiss roll dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.datasets.make_biclusters.html#sklearn.datasets.make_biclusters" title="sklearn.datasets.make_biclusters"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_biclusters</span></tt></a>(shape,&nbsp;n_clusters)</td>
<td>Generate an array with constant block diagonal structure for biclustering.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.datasets.make_checkerboard.html#sklearn.datasets.make_checkerboard" title="sklearn.datasets.make_checkerboard"><tt class="xref py py-obj docutils literal"><span class="pre">datasets.make_checkerboard</span></tt></a>(shape,&nbsp;n_clusters)</td>
<td>Generate an array with block checkerboard structure for biclustering.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.decomposition">
<span id="sklearn-decomposition-matrix-decomposition"></span><span id="decomposition-ref"></span><h2><a class="reference internal" href="#module-sklearn.decomposition" title="sklearn.decomposition"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.decomposition</span></tt></a>: Matrix Decomposition<a class="headerlink" href="#module-sklearn.decomposition" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.decomposition" title="sklearn.decomposition"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.decomposition</span></tt></a> module includes matrix decomposition
algorithms, including among others PCA, NMF or ICA. Most of the algorithms of
this module can be regarded as dimensionality reduction techniques.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="decomposition.html#decompositions"><em>Decomposing signals in components (matrix factorization problems)</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="sklearn.decomposition.PCA"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.PCA</span></tt></a>([n_components,&nbsp;copy,&nbsp;whiten])</td>
<td>Principal component analysis (PCA)  Linear dimensionality reduction using Singular Value Decomposition of the data and keeping only the most significant singular vectors to project the data to a lower dimensional space.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.ProjectedGradientNMF.html#sklearn.decomposition.ProjectedGradientNMF" title="sklearn.decomposition.ProjectedGradientNMF"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.ProjectedGradientNMF</span></tt></a>([...])</td>
<td>Non-Negative matrix factorization by Projected Gradient (NMF)   :Parameters:      <strong>n_components</strong> : int or None          Number of components, if n_components is not set all components         are kept               <strong>init</strong> :  &#8216;nndsvd&#8217; |  &#8216;nndsvda&#8217; | &#8216;nndsvdar&#8217; | &#8216;random&#8217;          Method used to initialize the procedure.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.RandomizedPCA.html#sklearn.decomposition.RandomizedPCA" title="sklearn.decomposition.RandomizedPCA"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.RandomizedPCA</span></tt></a>([n_components,&nbsp;...])</td>
<td>Principal component analysis (PCA) using randomized SVD  Linear dimensionality reduction using approximated Singular Value Decomposition of the data and keeping only the most significant singular vectors to project the data to a lower dimensional space.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA" title="sklearn.decomposition.KernelPCA"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.KernelPCA</span></tt></a>([n_components,&nbsp;...])</td>
<td>Kernel Principal component analysis (KPCA)  Non-linear dimensionality reduction through the use of kernels.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.FactorAnalysis.html#sklearn.decomposition.FactorAnalysis" title="sklearn.decomposition.FactorAnalysis"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.FactorAnalysis</span></tt></a>([n_components,&nbsp;...])</td>
<td>Factor Analysis (FA)  A simple linear generative model with Gaussian latent variables.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.FastICA.html#sklearn.decomposition.FastICA" title="sklearn.decomposition.FastICA"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.FastICA</span></tt></a>([n_components,&nbsp;...])</td>
<td>FastICA: a fast algorithm for Independent Component Analysis.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD" title="sklearn.decomposition.TruncatedSVD"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.TruncatedSVD</span></tt></a>([n_components,&nbsp;...])</td>
<td>Dimensionality reduction using truncated SVD (aka LSA).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF" title="sklearn.decomposition.NMF"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.NMF</span></tt></a>([n_components,&nbsp;init,&nbsp;...])</td>
<td>Non-Negative matrix factorization by Projected Gradient (NMF)   :Parameters:      <strong>n_components</strong> : int or None          Number of components, if n_components is not set all components         are kept               <strong>init</strong> :  &#8216;nndsvd&#8217; |  &#8216;nndsvda&#8217; | &#8216;nndsvdar&#8217; | &#8216;random&#8217;          Method used to initialize the procedure.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.SparsePCA.html#sklearn.decomposition.SparsePCA" title="sklearn.decomposition.SparsePCA"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.SparsePCA</span></tt></a>([n_components,&nbsp;...])</td>
<td>Sparse Principal Components Analysis (SparsePCA)  Finds the set of sparse components that can optimally reconstruct the data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.MiniBatchSparsePCA.html#sklearn.decomposition.MiniBatchSparsePCA" title="sklearn.decomposition.MiniBatchSparsePCA"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.MiniBatchSparsePCA</span></tt></a>([...])</td>
<td>Mini-batch Sparse Principal Components Analysis  Finds the set of sparse components that can optimally reconstruct the data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.SparseCoder.html#sklearn.decomposition.SparseCoder" title="sklearn.decomposition.SparseCoder"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.SparseCoder</span></tt></a>(dictionary[,&nbsp;...])</td>
<td>Sparse coding  Finds a sparse representation of data against a fixed, precomputed dictionary.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.DictionaryLearning.html#sklearn.decomposition.DictionaryLearning" title="sklearn.decomposition.DictionaryLearning"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.DictionaryLearning</span></tt></a>([...])</td>
<td>Dictionary learning  Finds a dictionary (a set of atoms) that can best be used to represent data using a sparse code.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.MiniBatchDictionaryLearning.html#sklearn.decomposition.MiniBatchDictionaryLearning" title="sklearn.decomposition.MiniBatchDictionaryLearning"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.MiniBatchDictionaryLearning</span></tt></a>([...])</td>
<td>Mini-batch dictionary learning  Finds a dictionary (a set of atoms) that can best be used to represent data using a sparse code.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.fastica</span></tt>(X[,&nbsp;n_components,&nbsp;...])</td>
<td>Perform Fast Independent Component Analysis.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.dict_learning.html#sklearn.decomposition.dict_learning" title="sklearn.decomposition.dict_learning"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.dict_learning</span></tt></a>(X,&nbsp;n_components,&nbsp;...)</td>
<td>Solves a dictionary learning matrix factorization problem.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.decomposition.dict_learning_online.html#sklearn.decomposition.dict_learning_online" title="sklearn.decomposition.dict_learning_online"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.dict_learning_online</span></tt></a>(X[,&nbsp;...])</td>
<td>Solves a dictionary learning matrix factorization problem online.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.decomposition.sparse_encode.html#sklearn.decomposition.sparse_encode" title="sklearn.decomposition.sparse_encode"><tt class="xref py py-obj docutils literal"><span class="pre">decomposition.sparse_encode</span></tt></a>(X,&nbsp;dictionary[,&nbsp;...])</td>
<td>Sparse coding  Each row of the result is the solution to a sparse coding problem.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.dummy">
<span id="sklearn-dummy-dummy-estimators"></span><span id="dummy-ref"></span><h2><a class="reference internal" href="#module-sklearn.dummy" title="sklearn.dummy"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.dummy</span></tt></a>: Dummy estimators<a class="headerlink" href="#module-sklearn.dummy" title="Permalink to this headline">¶</a></h2>
<p><strong>User guide:</strong> See the <a class="reference internal" href="model_evaluation.html#model-evaluation"><em>Model evaluation: quantifying the quality of predictions</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier" title="sklearn.dummy.DummyClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">dummy.DummyClassifier</span></tt></a>([strategy,&nbsp;random_state])</td>
<td>DummyClassifier is a classifier that makes predictions using simple rules.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.dummy.DummyRegressor.html#sklearn.dummy.DummyRegressor" title="sklearn.dummy.DummyRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">dummy.DummyRegressor</span></tt></a></td>
<td>DummyRegressor is a regressor that always predicts the mean of the training targets.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.ensemble">
<span id="sklearn-ensemble-ensemble-methods"></span><span id="ensemble-ref"></span><h2><a class="reference internal" href="#module-sklearn.ensemble" title="sklearn.ensemble"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.ensemble</span></tt></a>: Ensemble Methods<a class="headerlink" href="#module-sklearn.ensemble" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.ensemble" title="sklearn.ensemble"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.ensemble</span></tt></a> module includes ensemble-based methods for
classification and regression.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="ensemble.html#ensemble"><em>Ensemble methods</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.AdaBoostClassifier</span></tt>(...[,&nbsp;criterion])</td>
<td>An AdaBoost classifier.</td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.AdaBoostRegressor</span></tt>(...[,&nbsp;criterion,&nbsp;...])</td>
<td>An AdaBoost regressor.</td>
</tr>
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.BaggingClassifier</span></tt></td>
<td></td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.BaggingRegressor</span></tt></td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier" title="sklearn.ensemble.ExtraTreesClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.ExtraTreesClassifier</span></tt></a>([...])</td>
<td>An extra-trees classifier.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor" title="sklearn.ensemble.ExtraTreesRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.ExtraTreesRegressor</span></tt></a>([n_estimators,&nbsp;...])</td>
<td>An extra-trees regressor.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.GradientBoostingClassifier</span></tt></a>([loss,&nbsp;...])</td>
<td>Gradient Boosting for classification.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.GradientBoostingRegressor</span></tt></a>([loss,&nbsp;...])</td>
<td>Gradient Boosting for regression.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier" title="sklearn.ensemble.RandomForestClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.RandomForestClassifier</span></tt></a>([...])</td>
<td>A random forest classifier.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.ensemble.RandomTreesEmbedding.html#sklearn.ensemble.RandomTreesEmbedding" title="sklearn.ensemble.RandomTreesEmbedding"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.RandomTreesEmbedding</span></tt></a>([...])</td>
<td>An ensemble of totally random trees.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.RandomForestRegressor</span></tt></a>([...])</td>
<td>A random forest regressor.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
</tbody>
</table>
<div class="section" id="module-sklearn.ensemble.partial_dependence">
<span id="partial-dependence"></span><h3>partial dependence<a class="headerlink" href="#module-sklearn.ensemble.partial_dependence" title="Permalink to this headline">¶</a></h3>
<p>Partial dependence plots for tree ensembles.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.ensemble.partial_dependence.partial_dependence.html#sklearn.ensemble.partial_dependence.partial_dependence" title="sklearn.ensemble.partial_dependence.partial_dependence"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.partial_dependence.partial_dependence</span></tt></a>(...)</td>
<td>Partial dependence of <tt class="docutils literal"><span class="pre">target_variables</span></tt>.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.ensemble.partial_dependence.plot_partial_dependence.html#sklearn.ensemble.partial_dependence.plot_partial_dependence" title="sklearn.ensemble.partial_dependence.plot_partial_dependence"><tt class="xref py py-obj docutils literal"><span class="pre">ensemble.partial_dependence.plot_partial_dependence</span></tt></a>(...)</td>
<td>Partial dependence plots for <tt class="docutils literal"><span class="pre">features</span></tt>.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.feature_extraction">
<span id="sklearn-feature-extraction-feature-extraction"></span><span id="feature-extraction-ref"></span><h2><a class="reference internal" href="#module-sklearn.feature_extraction" title="sklearn.feature_extraction"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.feature_extraction</span></tt></a>: Feature Extraction<a class="headerlink" href="#module-sklearn.feature_extraction" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.feature_extraction" title="sklearn.feature_extraction"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.feature_extraction</span></tt></a> module deals with feature extraction
from raw data. It currently includes methods to extract features from text and
images.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="feature_extraction.html#feature-extraction"><em>Feature extraction</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer" title="sklearn.feature_extraction.DictVectorizer"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.DictVectorizer</span></tt></a>([dtype,&nbsp;...])</td>
<td>Transforms lists of feature-value mappings to vectors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher" title="sklearn.feature_extraction.FeatureHasher"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.FeatureHasher</span></tt></a>([...])</td>
<td>Implements feature hashing, aka the hashing trick.</td>
</tr>
</tbody>
</table>
<div class="section" id="module-sklearn.feature_extraction.image">
<span id="from-images"></span><h3>From images<a class="headerlink" href="#module-sklearn.feature_extraction.image" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="#module-sklearn.feature_extraction.image" title="sklearn.feature_extraction.image"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.feature_extraction.image</span></tt></a> submodule gathers utilities to
extract features from images.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_extraction.image.img_to_graph.html#sklearn.feature_extraction.image.img_to_graph" title="sklearn.feature_extraction.image.img_to_graph"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.image.img_to_graph</span></tt></a>(img[,&nbsp;...])</td>
<td>Graph of the pixel-to-pixel gradient connections  Edges are weighted with the gradient values.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_extraction.image.grid_to_graph.html#sklearn.feature_extraction.image.grid_to_graph" title="sklearn.feature_extraction.image.grid_to_graph"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.image.grid_to_graph</span></tt></a>(n_x,&nbsp;n_y)</td>
<td>Graph of the pixel-to-pixel connections  Edges exist if 2 voxels are connected.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_extraction.image.extract_patches_2d.html#sklearn.feature_extraction.image.extract_patches_2d" title="sklearn.feature_extraction.image.extract_patches_2d"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.image.extract_patches_2d</span></tt></a>(...)</td>
<td>Reshape a 2D image into a collection of patches  The resulting patches are allocated in a dedicated array.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d.html#sklearn.feature_extraction.image.reconstruct_from_patches_2d" title="sklearn.feature_extraction.image.reconstruct_from_patches_2d"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.image.reconstruct_from_patches_2d</span></tt></a>(...)</td>
<td>Reconstruct the image from all of its patches.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_extraction.image.PatchExtractor.html#sklearn.feature_extraction.image.PatchExtractor" title="sklearn.feature_extraction.image.PatchExtractor"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.image.PatchExtractor</span></tt></a>([...])</td>
<td>Extracts patches from a collection of images   :Parameters:      <strong>patch_size: tuple of ints (patch_height, patch_width)</strong> :           the dimensions of one patch               <strong>max_patches: integer or float, optional default is None</strong> :           The maximum number of patches per image to extract.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.feature_extraction.text">
<span id="from-text"></span><span id="text-feature-extraction-ref"></span><h3>From text<a class="headerlink" href="#module-sklearn.feature_extraction.text" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="#module-sklearn.feature_extraction.text" title="sklearn.feature_extraction.text"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.feature_extraction.text</span></tt></a> submodule gathers utilities to
build feature vectors from text documents.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="sklearn.feature_extraction.text.CountVectorizer"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.text.CountVectorizer</span></tt></a>([...])</td>
<td>Convert a collection of text documents to a matrix of token counts  This implementation produces a sparse representation of the counts using scipy.sparse.coo_matrix.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="sklearn.feature_extraction.text.HashingVectorizer"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.text.HashingVectorizer</span></tt></a>([...])</td>
<td>Convert a collection of text documents to a matrix of token occurrences  It turns a collection of text documents into a scipy.sparse matrix holding token occurrence counts (or binary occurrence information), possibly normalized as token frequencies if norm=&#8217;l1&#8217; or projected on the euclidean unit sphere if norm=&#8217;l2&#8217;.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer" title="sklearn.feature_extraction.text.TfidfTransformer"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.text.TfidfTransformer</span></tt></a>([...])</td>
<td>Transform a count matrix to a normalized tf or tf–idf representation  Tf means term-frequency while tf–idf means term-frequency times inverse document-frequency.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer" title="sklearn.feature_extraction.text.TfidfVectorizer"><tt class="xref py py-obj docutils literal"><span class="pre">feature_extraction.text.TfidfVectorizer</span></tt></a>([...])</td>
<td>Convert a collection of raw documents to a matrix of TF-IDF features.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.feature_selection">
<span id="sklearn-feature-selection-feature-selection"></span><span id="feature-selection-ref"></span><h2><a class="reference internal" href="#module-sklearn.feature_selection" title="sklearn.feature_selection"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.feature_selection</span></tt></a>: Feature Selection<a class="headerlink" href="#module-sklearn.feature_selection" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.feature_selection" title="sklearn.feature_selection"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.feature_selection</span></tt></a> module implements feature selection
algorithms. It currently includes univariate filter selection methods and the
recursive feature elimination algorithm.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="feature_selection.html#feature-selection"><em>Feature selection</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile" title="sklearn.feature_selection.SelectPercentile"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.SelectPercentile</span></tt></a>([...])</td>
<td>Select features according to a percentile of the highest scores.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" title="sklearn.feature_selection.SelectKBest"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.SelectKBest</span></tt></a>([score_func,&nbsp;k])</td>
<td>Select features according to the k highest scores.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_selection.SelectFpr.html#sklearn.feature_selection.SelectFpr" title="sklearn.feature_selection.SelectFpr"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.SelectFpr</span></tt></a>([score_func,&nbsp;alpha])</td>
<td>Filter: Select the pvalues below alpha based on a FPR test.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_selection.SelectFdr.html#sklearn.feature_selection.SelectFdr" title="sklearn.feature_selection.SelectFdr"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.SelectFdr</span></tt></a>([score_func,&nbsp;alpha])</td>
<td>Filter: Select the p-values for an estimated false discovery rate  This uses the Benjamini-Hochberg procedure.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_selection.SelectFwe.html#sklearn.feature_selection.SelectFwe" title="sklearn.feature_selection.SelectFwe"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.SelectFwe</span></tt></a>([score_func,&nbsp;alpha])</td>
<td>Filter: Select the p-values corresponding to Family-wise error rate   :Parameters:      <strong>score_func</strong> : callable          Function taking two arrays X and y, and returning a pair of arrays         (scores, pvalues).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE" title="sklearn.feature_selection.RFE"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.RFE</span></tt></a>(estimator[,&nbsp;...])</td>
<td>Feature ranking with recursive feature elimination.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV" title="sklearn.feature_selection.RFECV"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.RFECV</span></tt></a>(estimator[,&nbsp;step,&nbsp;...])</td>
<td>Feature ranking with recursive feature elimination and cross-validated    selection of the best number of features.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2" title="sklearn.feature_selection.chi2"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.chi2</span></tt></a>(X,&nbsp;y)</td>
<td>Compute χ² (chi-squared) statistic for each class/feature combination.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif" title="sklearn.feature_selection.f_classif"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.f_classif</span></tt></a>(X,&nbsp;y)</td>
<td>Compute the Anova F-value for the provided sample   :Parameters:      <strong>X</strong> : {array-like, sparse matrix} shape = [n_samples, n_features]          The set of regressors that will tested sequentially.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression" title="sklearn.feature_selection.f_regression"><tt class="xref py py-obj docutils literal"><span class="pre">feature_selection.f_regression</span></tt></a>(X,&nbsp;y[,&nbsp;center])</td>
<td>Univariate linear regression tests  Quick linear model for testing the effect of a single regressor, sequentially for many regressors.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.gaussian_process">
<span id="sklearn-gaussian-process-gaussian-processes"></span><span id="gaussian-process-ref"></span><h2><a class="reference internal" href="#module-sklearn.gaussian_process" title="sklearn.gaussian_process"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.gaussian_process</span></tt></a>: Gaussian Processes<a class="headerlink" href="#module-sklearn.gaussian_process" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.gaussian_process" title="sklearn.gaussian_process"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.gaussian_process</span></tt></a> module implements scalar Gaussian Process
based predictions.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="gaussian_process.html#gaussian-process"><em>Gaussian Processes</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.gaussian_process.GaussianProcess.html#sklearn.gaussian_process.GaussianProcess" title="sklearn.gaussian_process.GaussianProcess"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.GaussianProcess</span></tt></a>([regr,&nbsp;...])</td>
<td>The Gaussian Process model class.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.gaussian_process.correlation_models.absolute_exponential.html#sklearn.gaussian_process.correlation_models.absolute_exponential" title="sklearn.gaussian_process.correlation_models.absolute_exponential"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.correlation_models.absolute_exponential</span></tt></a>(...)</td>
<td>Absolute exponential autocorrelation model.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.gaussian_process.correlation_models.squared_exponential.html#sklearn.gaussian_process.correlation_models.squared_exponential" title="sklearn.gaussian_process.correlation_models.squared_exponential"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.correlation_models.squared_exponential</span></tt></a>(...)</td>
<td>Squared exponential correlation model (Radial Basis Function).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.gaussian_process.correlation_models.generalized_exponential.html#sklearn.gaussian_process.correlation_models.generalized_exponential" title="sklearn.gaussian_process.correlation_models.generalized_exponential"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.correlation_models.generalized_exponential</span></tt></a>(...)</td>
<td>Generalized exponential correlation model.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.gaussian_process.correlation_models.pure_nugget.html#sklearn.gaussian_process.correlation_models.pure_nugget" title="sklearn.gaussian_process.correlation_models.pure_nugget"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.correlation_models.pure_nugget</span></tt></a>(...)</td>
<td>Spatial independence correlation model (pure nugget).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.gaussian_process.correlation_models.cubic.html#sklearn.gaussian_process.correlation_models.cubic" title="sklearn.gaussian_process.correlation_models.cubic"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.correlation_models.cubic</span></tt></a>(...)</td>
<td>Cubic correlation model::      theta, dx &#8211;&gt; r(theta, dx) =       n     prod max(0, 1 - 3(theta_j*d_ij)^2 + 2(theta_j*d_ij)^3) ,  i = 1,...,m     j = 1  :Parameters:      <strong>theta</strong> : array_like          An array with shape 1 (isotropic) or n (anisotropic) giving the         autocorrelation parameter(s).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.gaussian_process.correlation_models.linear.html#sklearn.gaussian_process.correlation_models.linear" title="sklearn.gaussian_process.correlation_models.linear"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.correlation_models.linear</span></tt></a>(...)</td>
<td>Linear correlation model::      theta, dx &#8211;&gt; r(theta, dx) =           n         prod max(0, 1 - theta_j*d_ij) ,  i = 1,...,m         j = 1  :Parameters:      <strong>theta</strong> : array_like          An array with shape 1 (isotropic) or n (anisotropic) giving the         autocorrelation parameter(s).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.gaussian_process.regression_models.constant.html#sklearn.gaussian_process.regression_models.constant" title="sklearn.gaussian_process.regression_models.constant"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.regression_models.constant</span></tt></a>(x)</td>
<td>Zero order polynomial (constant, p = 1) regression model.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.gaussian_process.regression_models.linear.html#sklearn.gaussian_process.regression_models.linear" title="sklearn.gaussian_process.regression_models.linear"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.regression_models.linear</span></tt></a>(x)</td>
<td>First order polynomial (linear, p = n+1) regression model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.gaussian_process.regression_models.quadratic.html#sklearn.gaussian_process.regression_models.quadratic" title="sklearn.gaussian_process.regression_models.quadratic"><tt class="xref py py-obj docutils literal"><span class="pre">gaussian_process.regression_models.quadratic</span></tt></a>(x)</td>
<td>Second order polynomial (quadratic, p = n*(n-1)/2+n+1) regression model.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.grid_search">
<span id="sklearn-grid-search-grid-search"></span><span id="grid-search-ref"></span><h2><a class="reference internal" href="#module-sklearn.grid_search" title="sklearn.grid_search"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.grid_search</span></tt></a>: Grid Search<a class="headerlink" href="#module-sklearn.grid_search" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.grid_search" title="sklearn.grid_search"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.grid_search</span></tt></a> includes utilities to fine-tune the parameters
of an estimator.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="grid_search.html#grid-search"><em>Grid Search: Searching for estimator parameters</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV" title="sklearn.grid_search.GridSearchCV"><tt class="xref py py-obj docutils literal"><span class="pre">grid_search.GridSearchCV</span></tt></a>(estimator,&nbsp;param_grid)</td>
<td>Exhaustive search over specified parameter values for an estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.grid_search.ParameterGrid.html#sklearn.grid_search.ParameterGrid" title="sklearn.grid_search.ParameterGrid"><tt class="xref py py-obj docutils literal"><span class="pre">grid_search.ParameterGrid</span></tt></a>(param_grid)</td>
<td>Grid of parameters with a discrete number of values for each.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.grid_search.ParameterSampler.html#sklearn.grid_search.ParameterSampler" title="sklearn.grid_search.ParameterSampler"><tt class="xref py py-obj docutils literal"><span class="pre">grid_search.ParameterSampler</span></tt></a>(...[,&nbsp;random_state])</td>
<td>Generator on parameters sampled from given distributions.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.grid_search.RandomizedSearchCV.html#sklearn.grid_search.RandomizedSearchCV" title="sklearn.grid_search.RandomizedSearchCV"><tt class="xref py py-obj docutils literal"><span class="pre">grid_search.RandomizedSearchCV</span></tt></a>(estimator,&nbsp;...)</td>
<td>Randomized search on hyper parameters.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.hmm">
<span id="sklearn-hmm-hidden-markov-models"></span><span id="hmm-ref"></span><h2><a class="reference internal" href="#module-sklearn.hmm" title="sklearn.hmm"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.hmm</span></tt></a>: Hidden Markov Models<a class="headerlink" href="#module-sklearn.hmm" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.hmm" title="sklearn.hmm"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.hmm</span></tt></a> module implements hidden Markov models.</p>
<p><strong>Warning:</strong> <a class="reference internal" href="#module-sklearn.hmm" title="sklearn.hmm"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.hmm</span></tt></a> is orphaned, undocumented and has known
numerical stability issues. If nobody volunteers to write documentation and
make it more stable, this module will be removed in version 0.11.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="hmm.html#hmm"><em>Hidden Markov Models</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.hmm.GaussianHMM.html#sklearn.hmm.GaussianHMM" title="sklearn.hmm.GaussianHMM"><tt class="xref py py-obj docutils literal"><span class="pre">hmm.GaussianHMM</span></tt></a>([n_components,&nbsp;...])</td>
<td>Hidden Markov Model with Gaussian emissions  Representation of a hidden Markov model probability distribution.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.hmm.MultinomialHMM.html#sklearn.hmm.MultinomialHMM" title="sklearn.hmm.MultinomialHMM"><tt class="xref py py-obj docutils literal"><span class="pre">hmm.MultinomialHMM</span></tt></a>([n_components,&nbsp;...])</td>
<td>Hidden Markov Model with multinomial (discrete) emissions   ..</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.hmm.GMMHMM.html#sklearn.hmm.GMMHMM" title="sklearn.hmm.GMMHMM"><tt class="xref py py-obj docutils literal"><span class="pre">hmm.GMMHMM</span></tt></a>([n_components,&nbsp;n_mix,&nbsp;startprob,&nbsp;...])</td>
<td>Hidden Markov Model with Gaussin mixture emissions   ..</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.isotonic">
<span id="sklearn-isotonic-isotonic-regression"></span><span id="isotonic-ref"></span><h2><a class="reference internal" href="#module-sklearn.isotonic" title="sklearn.isotonic"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.isotonic</span></tt></a>: Isotonic regression<a class="headerlink" href="#module-sklearn.isotonic" title="Permalink to this headline">¶</a></h2>
<p><strong>User guide:</strong> See the <a class="reference internal" href="isotonic.html#isotonic"><em>Isotonic regression</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.isotonic.IsotonicRegression.html#sklearn.isotonic.IsotonicRegression" title="sklearn.isotonic.IsotonicRegression"><tt class="xref py py-obj docutils literal"><span class="pre">isotonic.IsotonicRegression</span></tt></a>([y_min,&nbsp;y_max,&nbsp;...])</td>
<td>Isotonic regression model.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.isotonic.isotonic_regression.html#sklearn.isotonic.isotonic_regression" title="sklearn.isotonic.isotonic_regression"><tt class="xref py py-obj docutils literal"><span class="pre">isotonic.isotonic_regression</span></tt></a>(y[,&nbsp;...])</td>
<td>Solve the isotonic regression model::      min sum w[i] (y[i] - y_[i]) ** 2      subject to y_min = y_[1] &lt;= y_[2] ...</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.kernel_approximation">
<span id="sklearn-kernel-approximation-kernel-approximation"></span><span id="kernel-approximation-ref"></span><h2><a class="reference internal" href="#module-sklearn.kernel_approximation" title="sklearn.kernel_approximation"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.kernel_approximation</span></tt></a> Kernel Approximation<a class="headerlink" href="#module-sklearn.kernel_approximation" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.kernel_approximation" title="sklearn.kernel_approximation"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.kernel_approximation</span></tt></a> module implements several
approximate kernel feature maps base on Fourier transforms.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="kernel_approximation.html#kernel-approximation"><em>Kernel Approximation</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.kernel_approximation.AdditiveChi2Sampler.html#sklearn.kernel_approximation.AdditiveChi2Sampler" title="sklearn.kernel_approximation.AdditiveChi2Sampler"><tt class="xref py py-obj docutils literal"><span class="pre">kernel_approximation.AdditiveChi2Sampler</span></tt></a>([...])</td>
<td>Approximate feature map for additive chi² kernel.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><tt class="xref py py-obj docutils literal"><span class="pre">kernel_approximation.Nystroem</span></tt></a>([kernel,&nbsp;...])</td>
<td>Approximate a kernel map using a subset of the training data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler" title="sklearn.kernel_approximation.RBFSampler"><tt class="xref py py-obj docutils literal"><span class="pre">kernel_approximation.RBFSampler</span></tt></a>([gamma,&nbsp;...])</td>
<td>Approximates feature map of an RBF kernel by Monte Carlo approximation of its Fourier transform.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.kernel_approximation.SkewedChi2Sampler.html#sklearn.kernel_approximation.SkewedChi2Sampler" title="sklearn.kernel_approximation.SkewedChi2Sampler"><tt class="xref py py-obj docutils literal"><span class="pre">kernel_approximation.SkewedChi2Sampler</span></tt></a>([...])</td>
<td>Approximates feature map of the &#8220;skewed chi-squared&#8221; kernel by Monte Carlo approximation of its Fourier transform.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.lda">
<span id="sklearn-lda-linear-discriminant-analysis"></span><span id="lda-ref"></span><h2><a class="reference internal" href="#module-sklearn.lda" title="sklearn.lda"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.lda</span></tt></a>: Linear Discriminant Analysis<a class="headerlink" href="#module-sklearn.lda" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.lda" title="sklearn.lda"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.lda</span></tt></a> module implements Linear Discriminant Analysis (LDA).</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="lda_qda.html#lda-qda"><em>Linear and quadratic discriminant analysis</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.lda.LDA.html#sklearn.lda.LDA" title="sklearn.lda.LDA"><tt class="xref py py-obj docutils literal"><span class="pre">lda.LDA</span></tt></a>([n_components,&nbsp;priors])</td>
<td>Linear Discriminant Analysis (LDA)  A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes&#8217; rule.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="sklearn-learning-curve-learning-curve-evaluation">
<span id="learning-curve-ref"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.learning_curve</span></tt> Learning curve evaluation<a class="headerlink" href="#sklearn-learning-curve-learning-curve-evaluation" title="Permalink to this headline">¶</a></h2>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">learning_curve.learning_curve</span></tt></td>
<td></td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">learning_curve.validation_curve</span></tt></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.linear_model">
<span id="sklearn-linear-model-generalized-linear-models"></span><span id="linear-model-ref"></span><h2><a class="reference internal" href="#module-sklearn.linear_model" title="sklearn.linear_model"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.linear_model</span></tt></a>: Generalized Linear Models<a class="headerlink" href="#module-sklearn.linear_model" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.linear_model" title="sklearn.linear_model"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.linear_model</span></tt></a> module implements generalized linear models. It
includes Ridge regression, Bayesian Regression, Lasso and Elastic Net
estimators computed with Least Angle Regression and coordinate descent. It also
implements Stochastic Gradient Descent related algorithms.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="linear_model.html#linear-model"><em>Generalized Linear Models</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression" title="sklearn.linear_model.ARDRegression"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.ARDRegression</span></tt></a>([n_iter,&nbsp;tol,&nbsp;...])</td>
<td>Bayesian ARD regression.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge" title="sklearn.linear_model.BayesianRidge"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.BayesianRidge</span></tt></a>([n_iter,&nbsp;tol,&nbsp;...])</td>
<td>Bayesian ridge regression  Fit a Bayesian ridge model and optimize the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet" title="sklearn.linear_model.ElasticNet"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.ElasticNet</span></tt></a>([alpha,&nbsp;l1_ratio,&nbsp;...])</td>
<td>Linear Model trained with L1 and L2 prior as regularizer  Minimizes the objective function::          1 / (2 * n_samples) * ||y - Xw||^2_2 +         + alpha * l1_ratio * ||w||_1         + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2  If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to::          a * L1 + b * L2  where::          alpha = a + b and l1_ratio = a / (a + b)  The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV" title="sklearn.linear_model.ElasticNetCV"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.ElasticNetCV</span></tt></a>([l1_ratio,&nbsp;eps,&nbsp;...])</td>
<td>Elastic Net model with iterative fitting along a regularization path  The best model is selected by cross-validation.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.Lars.html#sklearn.linear_model.Lars" title="sklearn.linear_model.Lars"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.Lars</span></tt></a>([fit_intercept,&nbsp;verbose,&nbsp;...])</td>
<td>Least Angle Regression model a.k.a.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.LarsCV.html#sklearn.linear_model.LarsCV" title="sklearn.linear_model.LarsCV"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.LarsCV</span></tt></a>([fit_intercept,&nbsp;...])</td>
<td>Cross-validated Least Angle Regression model   :Parameters:      <strong>fit_intercept</strong> : boolean          whether to calculate the intercept for this model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.Lasso</span></tt></a>([alpha,&nbsp;fit_intercept,&nbsp;...])</td>
<td>Linear Model trained with L1 prior as regularizer (aka the Lasso)  The optimization objective for Lasso is::      (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1  Technically the Lasso model is optimizing the same objective function as the Elastic Net with <tt class="docutils literal"><span class="pre">l1_ratio=1.0</span></tt> (no L2 penalty).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.LassoCV</span></tt></a>([eps,&nbsp;n_alphas,&nbsp;...])</td>
<td>Lasso linear model with iterative fitting along a regularization path  The best model is selected by cross-validation.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.LassoLars.html#sklearn.linear_model.LassoLars" title="sklearn.linear_model.LassoLars"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.LassoLars</span></tt></a>([alpha,&nbsp;...])</td>
<td>Lasso model fit with Least Angle Regression a.k.a.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.LassoLarsCV</span></tt></a>([fit_intercept,&nbsp;...])</td>
<td>Cross-validated Lasso, using the LARS algorithm  The optimization objective for Lasso is::  (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1  :Parameters:      <strong>fit_intercept</strong> : boolean          whether to calculate the intercept for this model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.LassoLarsIC.html#sklearn.linear_model.LassoLarsIC" title="sklearn.linear_model.LassoLarsIC"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.LassoLarsIC</span></tt></a>([criterion,&nbsp;...])</td>
<td>Lasso model fit with Lars using BIC or AIC for model selection  The optimization objective for Lasso is::  (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1  AIC is the Akaike information criterion and BIC is the Bayes Information criterion.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.LinearRegression</span></tt></a>([...])</td>
<td>Ordinary least squares Linear Regression.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.LogisticRegression</span></tt></a>([penalty,&nbsp;...])</td>
<td>Logistic Regression (aka logit, MaxEnt) classifier.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.MultiTaskLasso.html#sklearn.linear_model.MultiTaskLasso" title="sklearn.linear_model.MultiTaskLasso"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.MultiTaskLasso</span></tt></a>([alpha,&nbsp;...])</td>
<td>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer  The optimization objective for Lasso is::      (1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21  Where::      ||W||_21 = sum_i sqrt{sum_j w_{ij}^2}  i.e.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet" title="sklearn.linear_model.MultiTaskElasticNet"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.MultiTaskElasticNet</span></tt></a>([alpha,&nbsp;...])</td>
<td>Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer  The optimization objective for Lasso is::      (1 / (2 * n_samples)) * ||Y - XW||^Fro_2     + alpha * l1_ratio * ||W||_21     + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2  Where::      ||W||_21 = sum_i sqrt{sum_j w_{ij}^2}  i.e.</td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.MultiTaskLassoCV</span></tt></td>
<td></td>
</tr>
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.MultiTaskElasticNetCV</span></tt></td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.OrthogonalMatchingPursuit.html#sklearn.linear_model.OrthogonalMatchingPursuit" title="sklearn.linear_model.OrthogonalMatchingPursuit"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.OrthogonalMatchingPursuit</span></tt></a>([...])</td>
<td>Orthogonal Mathching Pursuit model (OMP)   :Parameters:      <strong>n_nonzero_coefs</strong> : int, optional          Desired number of non-zero entries in the solution.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.OrthogonalMatchingPursuitCV.html#sklearn.linear_model.OrthogonalMatchingPursuitCV" title="sklearn.linear_model.OrthogonalMatchingPursuitCV"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.OrthogonalMatchingPursuitCV</span></tt></a>([...])</td>
<td>Cross-validated Orthogonal Mathching Pursuit model (OMP)   :Parameters:      <strong>copy</strong> : bool, optional          Whether the design matrix X must be copied by the algorithm.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.PassiveAggressiveClassifier.html#sklearn.linear_model.PassiveAggressiveClassifier" title="sklearn.linear_model.PassiveAggressiveClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.PassiveAggressiveClassifier</span></tt></a>([...])</td>
<td>Passive Aggressive Classifier   :Parameters:      <strong>C</strong> : float          Maximum step size (regularization).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.PassiveAggressiveRegressor.html#sklearn.linear_model.PassiveAggressiveRegressor" title="sklearn.linear_model.PassiveAggressiveRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.PassiveAggressiveRegressor</span></tt></a>([C,&nbsp;...])</td>
<td>Passive Aggressive Regressor   :Parameters:      <strong>C</strong> : float          Maximum step size (regularization).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron" title="sklearn.linear_model.Perceptron"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.Perceptron</span></tt></a>([penalty,&nbsp;alpha,&nbsp;...])</td>
<td>Perceptron   :Parameters:      <strong>penalty</strong> : None, &#8216;l2&#8217; or &#8216;l1&#8217; or &#8216;elasticnet&#8217;          The penalty (aka regularization term) to be used.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.RandomizedLasso.html#sklearn.linear_model.RandomizedLasso" title="sklearn.linear_model.RandomizedLasso"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.RandomizedLasso</span></tt></a>([alpha,&nbsp;...])</td>
<td>Randomized Lasso.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.RandomizedLogisticRegression.html#sklearn.linear_model.RandomizedLogisticRegression" title="sklearn.linear_model.RandomizedLogisticRegression"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.RandomizedLogisticRegression</span></tt></a>([...])</td>
<td>Randomized Logistic Regression  Randomized Regression works by resampling the train data and computing a LogisticRegression on each resampling.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.Ridge</span></tt></a>([alpha,&nbsp;fit_intercept,&nbsp;...])</td>
<td>Linear least squares with l2 regularization.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier" title="sklearn.linear_model.RidgeClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.RidgeClassifier</span></tt></a>([alpha,&nbsp;...])</td>
<td>Classifier using Ridge regression.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV" title="sklearn.linear_model.RidgeClassifierCV"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.RidgeClassifierCV</span></tt></a>([alphas,&nbsp;...])</td>
<td>Ridge classifier with built-in cross-validation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.RidgeCV</span></tt></a>([alphas,&nbsp;...])</td>
<td>Ridge regression with built-in cross-validation.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.SGDClassifier</span></tt></a>([loss,&nbsp;penalty,&nbsp;...])</td>
<td>Linear classifiers (SVM, logistic regression, a.o.) with SGD training.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.SGDRegressor</span></tt></a>([loss,&nbsp;penalty,&nbsp;...])</td>
<td>Linear model fitted by minimizing a regularized empirical loss with SGD  SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.lars_path.html#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.lars_path</span></tt></a>(X,&nbsp;y[,&nbsp;Xy,&nbsp;Gram,&nbsp;...])</td>
<td>Compute Least Angle Regression or Lasso path using LARS algorithm [1]  The optimization objective for the case method=&#8217;lasso&#8217; is::  (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1  in the case of method=&#8217;lars&#8217;, the objective function is only known in the form of an implicit equation (see discussion in [1])  :Parameters:      <strong>X</strong> : array, shape: (n_samples, n_features)          Input data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path" title="sklearn.linear_model.lasso_path"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.lasso_path</span></tt></a>(X,&nbsp;y[,&nbsp;eps,&nbsp;...])</td>
<td>Compute Lasso path with coordinate descent  The optimization objective for Lasso is::      (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1  :Parameters:      <strong>X</strong> : {array-like, sparse matrix}, shape (n_samples, n_features)          Training data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.lasso_stability_path.html#sklearn.linear_model.lasso_stability_path" title="sklearn.linear_model.lasso_stability_path"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.lasso_stability_path</span></tt></a>(X,&nbsp;y[,&nbsp;...])</td>
<td>Stabiliy path based on randomized Lasso estimates   :Parameters:      <strong>X</strong> : array-like, shape = [n_samples, n_features]          training data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.linear_model.orthogonal_mp.html#sklearn.linear_model.orthogonal_mp" title="sklearn.linear_model.orthogonal_mp"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.orthogonal_mp</span></tt></a>(X,&nbsp;y[,&nbsp;...])</td>
<td>Orthogonal Matching Pursuit (OMP)  Solves n_targets Orthogonal Matching Pursuit problems.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.linear_model.orthogonal_mp_gram.html#sklearn.linear_model.orthogonal_mp_gram" title="sklearn.linear_model.orthogonal_mp_gram"><tt class="xref py py-obj docutils literal"><span class="pre">linear_model.orthogonal_mp_gram</span></tt></a>(Gram,&nbsp;Xy[,&nbsp;...])</td>
<td>Gram Orthogonal Matching Pursuit (OMP)  Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.manifold">
<span id="sklearn-manifold-manifold-learning"></span><span id="manifold-ref"></span><h2><a class="reference internal" href="#module-sklearn.manifold" title="sklearn.manifold"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.manifold</span></tt></a>: Manifold Learning<a class="headerlink" href="#module-sklearn.manifold" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.manifold" title="sklearn.manifold"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.manifold</span></tt></a> module implements data embedding techniques.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="manifold.html#manifold"><em>Manifold learning</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.manifold.LocallyLinearEmbedding.html#sklearn.manifold.LocallyLinearEmbedding" title="sklearn.manifold.LocallyLinearEmbedding"><tt class="xref py py-obj docutils literal"><span class="pre">manifold.LocallyLinearEmbedding</span></tt></a>([...])</td>
<td>Locally Linear Embedding   :Parameters:      <strong>n_neighbors</strong> : integer          number of neighbors to consider for each point.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.manifold.Isomap.html#sklearn.manifold.Isomap" title="sklearn.manifold.Isomap"><tt class="xref py py-obj docutils literal"><span class="pre">manifold.Isomap</span></tt></a>([n_neighbors,&nbsp;n_components,&nbsp;...])</td>
<td>Isomap Embedding  Non-linear dimensionality reduction through Isometric Mapping  :Parameters:      <strong>n_neighbors</strong> : integer          number of neighbors to consider for each point.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.manifold.MDS.html#sklearn.manifold.MDS" title="sklearn.manifold.MDS"><tt class="xref py py-obj docutils literal"><span class="pre">manifold.MDS</span></tt></a>([n_components,&nbsp;metric,&nbsp;n_init,&nbsp;...])</td>
<td>Multidimensional scaling   :Parameters:      <strong>metric</strong> : boolean, optional, default: True          compute metric or nonmetric SMACOF (Scaling by Majorizing a         Complicated Function) algorithm               <strong>n_components</strong> : int, optional, default: 2          number of dimension in which to immerse the similarities         overridden if initial array is provided.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.manifold.SpectralEmbedding.html#sklearn.manifold.SpectralEmbedding" title="sklearn.manifold.SpectralEmbedding"><tt class="xref py py-obj docutils literal"><span class="pre">manifold.SpectralEmbedding</span></tt></a>([n_components,&nbsp;...])</td>
<td>Spectral Embedding for Non-linear Dimensionality Reduction.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.manifold.locally_linear_embedding.html#sklearn.manifold.locally_linear_embedding" title="sklearn.manifold.locally_linear_embedding"><tt class="xref py py-obj docutils literal"><span class="pre">manifold.locally_linear_embedding</span></tt></a>(X,&nbsp;...[,&nbsp;...])</td>
<td>Perform a Locally Linear Embedding analysis on the data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.manifold.spectral_embedding.html#sklearn.manifold.spectral_embedding" title="sklearn.manifold.spectral_embedding"><tt class="xref py py-obj docutils literal"><span class="pre">manifold.spectral_embedding</span></tt></a>(adjacency[,&nbsp;...])</td>
<td>Project the sample on the first eigen vectors of the graph Laplacian.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="sklearn-metrics-metrics">
<span id="metrics-ref"></span><h2><a class="reference internal" href="#module-sklearn.metrics" title="sklearn.metrics"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.metrics</span></tt></a>: Metrics<a class="headerlink" href="#sklearn-metrics-metrics" title="Permalink to this headline">¶</a></h2>
<p>See the <a class="reference internal" href="model_evaluation.html#model-evaluation"><em>Model evaluation: quantifying the quality of predictions</em></a> section and the <a class="reference internal" href="metrics.html#metrics"><em>Pairwise metrics, Affinities and Kernels</em></a> section of the
user guide for further details.</p>
<span class="target" id="module-sklearn.metrics"></span><p>The <a class="reference internal" href="#module-sklearn.metrics" title="sklearn.metrics"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.metrics</span></tt></a> module includes score functions, performance metrics
and pairwise metrics and distance computations.</p>
<div class="section" id="model-selection-interface">
<h3>Model Selection Interface<a class="headerlink" href="#model-selection-interface" title="Permalink to this headline">¶</a></h3>
<p>See the <a class="reference internal" href="model_evaluation.html#scoring-parameter"><em>The scoring parameter: defining model evaluation rules</em></a> section of the user guide for further
details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.make_scorer</span></tt></a>(score_func[,&nbsp;...])</td>
<td>Make a scorer from a performance metric or loss function.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="classification-metrics">
<h3>Classification metrics<a class="headerlink" href="#classification-metrics" title="Permalink to this headline">¶</a></h3>
<p>See the <a class="reference internal" href="model_evaluation.html#classification-metrics"><em>Classification metrics</em></a> section of the user guide for further
details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.accuracy_score</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;...])</td>
<td>Accuracy classification score.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.auc.html#sklearn.metrics.auc" title="sklearn.metrics.auc"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.auc</span></tt></a>(x,&nbsp;y[,&nbsp;reorder])</td>
<td>Compute Area Under the Curve (AUC) using the trapezoidal rule  This is a general function, given points on a curve.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.average_precision_score</span></tt></a>(y_true,&nbsp;y_score)</td>
<td>Compute average precision (AP) from prediction scores  This score corresponds to the area under the precision-recall curve.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report" title="sklearn.metrics.classification_report"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.classification_report</span></tt></a>(y_true,&nbsp;y_pred)</td>
<td>Build a text report showing the main classification metrics   :Parameters:      <strong>y_true</strong> : array-like or list of labels or label indicator matrix          Ground truth (correct) target values.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="sklearn.metrics.confusion_matrix"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.confusion_matrix</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;...])</td>
<td>Compute confusion matrix to evaluate the accuracy of a classification  By definition a confusion matrix <img class="math" src="../_images/math/2bcc65482aa8e15cd4c9e9f2542451fb4e971a91.png" alt="C"/> is such that <img class="math" src="../_images/math/def967005305b517d635567d0537f11fe13a8b2a.png" alt="C_{i, j}"/> is equal to the number of observations known to be in group <img class="math" src="../_images/math/a581f053bbfa5115f42c13094857cdd12a37ec49.png" alt="i"/> but predicted to be in group <img class="math" src="../_images/math/d32c78b759903e3f4bd4fd2ce0b86358f7500c5d.png" alt="j"/>.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.f1_score</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;...])</td>
<td>Compute the F1 score, also known as balanced F-score or F-measure  The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.fbeta_score</span></tt></a>(y_true,&nbsp;y_pred,&nbsp;beta[,&nbsp;...])</td>
<td>Compute the F-beta score  The F-beta score is the weighted harmonic mean of precision and recall, reaching its optimal value at 1 and its worst value at 0.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.hamming_loss</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;classes])</td>
<td>Compute the average Hamming loss.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.hinge_loss</span></tt></a>(y_true,&nbsp;pred_decision[,&nbsp;...])</td>
<td>Average hinge loss (non-regularized)  Assuming labels in y_true are encoded with +1 and -1, when a prediction mistake is made, <tt class="docutils literal"><span class="pre">margin</span> <span class="pre">=</span> <span class="pre">y_true</span> <span class="pre">*</span> <span class="pre">pred_decision</span></tt> is always negative (since the signs disagree), implying <tt class="docutils literal"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">margin</span></tt> is always greater than 1.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.jaccard_similarity_score.html#sklearn.metrics.jaccard_similarity_score" title="sklearn.metrics.jaccard_similarity_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.jaccard_similarity_score</span></tt></a>(y_true,&nbsp;y_pred)</td>
<td>Jaccard similarity coefficient score  The Jaccard index [1], or Jaccard similarity coefficient, defined as the size of the intersection divided by the size of the union of two label sets, is used to compare set of predicted labels for a sample to the corresponding set of labels in <tt class="docutils literal"><span class="pre">y_true</span></tt>.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="sklearn.metrics.log_loss"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.log_loss</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;eps,&nbsp;...])</td>
<td>Log loss, aka logistic loss or cross-entropy loss.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef" title="sklearn.metrics.matthews_corrcoef"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.matthews_corrcoef</span></tt></a>(y_true,&nbsp;y_pred)</td>
<td>Compute the Matthews correlation coefficient (MCC) for binary classes  The Matthews correlation coefficient is used in machine learning as a measure of the quality of binary (two-class) classifications.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.precision_recall_curve</span></tt></a>(y_true,&nbsp;...)</td>
<td>Compute precision-recall pairs for different probability thresholds  Note: this implementation is restricted to the binary classification task.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.precision_recall_fscore_support</span></tt></a>(...)</td>
<td>Compute precision, recall, F-measure and support for each class  The precision is the ratio <tt class="docutils literal"><span class="pre">tp</span> <span class="pre">/</span> <span class="pre">(tp</span> <span class="pre">+</span> <span class="pre">fp)</span></tt> where <tt class="docutils literal"><span class="pre">tp</span></tt> is the number of true positives and <tt class="docutils literal"><span class="pre">fp</span></tt> the number of false positives.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.precision_score</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;...])</td>
<td>Compute the precision  The precision is the ratio <tt class="docutils literal"><span class="pre">tp</span> <span class="pre">/</span> <span class="pre">(tp</span> <span class="pre">+</span> <span class="pre">fp)</span></tt> where <tt class="docutils literal"><span class="pre">tp</span></tt> is the number of true positives and <tt class="docutils literal"><span class="pre">fp</span></tt> the number of false positives.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.recall_score</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;...])</td>
<td>Compute the recall  The recall is the ratio <tt class="docutils literal"><span class="pre">tp</span> <span class="pre">/</span> <span class="pre">(tp</span> <span class="pre">+</span> <span class="pre">fn)</span></tt> where <tt class="docutils literal"><span class="pre">tp</span></tt> is the number of true positives and <tt class="docutils literal"><span class="pre">fn</span></tt> the number of false negatives.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.roc_auc_score</span></tt></a>(y_true,&nbsp;y_score)</td>
<td>Compute Area Under the Curve (AUC) from prediction scores  Note: this implementation is restricted to the binary classification task.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve" title="sklearn.metrics.roc_curve"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.roc_curve</span></tt></a>(y_true,&nbsp;y_score[,&nbsp;pos_label])</td>
<td>Compute Receiver operating characteristic (ROC)  Note: this implementation is restricted to the binary classification task.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="sklearn.metrics.zero_one_loss"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.zero_one_loss</span></tt></a>(y_true,&nbsp;y_pred[,&nbsp;...])</td>
<td>Zero-one classification loss.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="regression-metrics">
<h3>Regression metrics<a class="headerlink" href="#regression-metrics" title="Permalink to this headline">¶</a></h3>
<p>See the <a class="reference internal" href="model_evaluation.html#regression-metrics"><em>Regression metrics</em></a> section of the user guide for further
details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.explained_variance_score</span></tt></a>(y_true,&nbsp;y_pred)</td>
<td>Explained variance regression score function  Best possible score is 1.0, lower values are worse.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.mean_absolute_error</span></tt></a>(y_true,&nbsp;y_pred)</td>
<td>Mean absolute error regression loss   :Parameters:      <strong>y_true</strong> : array-like of shape = [n_samples] or [n_samples, n_outputs]          Ground truth (correct) target values.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.mean_squared_error</span></tt></a>(y_true,&nbsp;y_pred)</td>
<td>Mean squared error regression loss   :Parameters:      <strong>y_true</strong> : array-like of shape = [n_samples] or [n_samples, n_outputs]          Ground truth (correct) target values.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.r2_score</span></tt></a>(y_true,&nbsp;y_pred)</td>
<td>R² (coefficient of determination) regression score function.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="clustering-metrics">
<h3>Clustering metrics<a class="headerlink" href="#clustering-metrics" title="Permalink to this headline">¶</a></h3>
<p>See the <a class="reference internal" href="clustering.html#clustering-evaluation"><em>Clustering performance evaluation</em></a> section of the user guide for further
details.</p>
<span class="target" id="module-sklearn.metrics.cluster"></span><p>The <a class="reference internal" href="#module-sklearn.metrics.cluster" title="sklearn.metrics.cluster"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.metrics.cluster</span></tt></a> submodule contains evaluation metrics for
cluster analysis results. There are two forms of evaluation:</p>
<ul class="simple">
<li>supervised, which uses a ground truth class values for each sample.</li>
<li>unsupervised, which does not and measures the &#8216;quality&#8217; of the model itself.</li>
</ul>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score" title="sklearn.metrics.adjusted_mutual_info_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.adjusted_mutual_info_score</span></tt></a>(...)</td>
<td>Adjusted Mutual Information between two clusterings  Adjusted Mutual Information (AMI) is an adjustment of the Mutual Information (MI) score to account for chance.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score" title="sklearn.metrics.adjusted_rand_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.adjusted_rand_score</span></tt></a>(labels_true,&nbsp;...)</td>
<td>Rand index adjusted for chance  The Rand Index computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score" title="sklearn.metrics.completeness_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.completeness_score</span></tt></a>(labels_true,&nbsp;...)</td>
<td>Completeness metric of a cluster labeling given a ground truth  A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.homogeneity_completeness_v_measure.html#sklearn.metrics.homogeneity_completeness_v_measure" title="sklearn.metrics.homogeneity_completeness_v_measure"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.homogeneity_completeness_v_measure</span></tt></a>(...)</td>
<td>Compute the homogeneity and completeness and V-Measure scores at once  Those metrics are based on normalized conditional entropy measures of the clustering labeling to evaluate given the knowledge of a Ground Truth class labels of the same samples.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score" title="sklearn.metrics.homogeneity_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.homogeneity_score</span></tt></a>(labels_true,&nbsp;...)</td>
<td>Homogeneity metric of a cluster labeling given a ground truth  A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score" title="sklearn.metrics.mutual_info_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.mutual_info_score</span></tt></a>(labels_true,&nbsp;...)</td>
<td>Mutual Information between two clusterings  The Mutual Information is a measure of the similarity between two labels of the same data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score" title="sklearn.metrics.normalized_mutual_info_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.normalized_mutual_info_score</span></tt></a>(...)</td>
<td>Normalized Mutual Information between two clusterings  Normalized Mutual Information (NMI) is an normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score" title="sklearn.metrics.silhouette_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.silhouette_score</span></tt></a>(X,&nbsp;labels[,&nbsp;...])</td>
<td>Compute the mean Silhouette Coefficient of all samples.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.silhouette_samples.html#sklearn.metrics.silhouette_samples" title="sklearn.metrics.silhouette_samples"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.silhouette_samples</span></tt></a>(X,&nbsp;labels[,&nbsp;metric])</td>
<td>Compute the Silhouette Coefficient for each sample.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score" title="sklearn.metrics.v_measure_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.v_measure_score</span></tt></a>(labels_true,&nbsp;labels_pred)</td>
<td>V-measure cluster labeling given a ground truth.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="biclustering-metrics">
<h3>Biclustering metrics<a class="headerlink" href="#biclustering-metrics" title="Permalink to this headline">¶</a></h3>
<p>See the <a class="reference internal" href="biclustering.html#biclustering-evaluation"><em>Biclustering evaluation</em></a> section of the user guide for
further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.consensus_score.html#sklearn.metrics.consensus_score" title="sklearn.metrics.consensus_score"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.consensus_score</span></tt></a>(a,&nbsp;b[,&nbsp;similarity])</td>
<td>The similarity of two sets of biclusters.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.metrics.pairwise">
<span id="pairwise-metrics"></span><h3>Pairwise metrics<a class="headerlink" href="#module-sklearn.metrics.pairwise" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="#module-sklearn.metrics.pairwise" title="sklearn.metrics.pairwise"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.metrics.pairwise</span></tt></a> submodule implements utilities to evaluate
pairwise distances or affinity of sets of samples.</p>
<p>This module contains both distance metrics and kernels. A brief summary is
given on the two here.</p>
<p>Distance metrics are a function d(a, b) such that d(a, b) &lt; d(a, c) if objects
a and b are considered &#8220;more similar&#8221; to objects a and c. Two objects exactly
alike would have a distance of zero.
One of the most popular examples is Euclidean distance.
To be a &#8216;true&#8217; metric, it must obey the following four conditions:</p>
<div class="highlight-python"><div class="highlight"><pre>1. d(a, b) &gt;= 0, for all a and b
2. d(a, b) == 0, if and only if a = b, positive definiteness
3. d(a, b) == d(b, a), symmetry
4. d(a, c) &lt;= d(a, b) + d(b, c), the triangle inequality
</pre></div>
</div>
<p>Kernels are measures of similarity, i.e. <tt class="docutils literal"><span class="pre">s(a,</span> <span class="pre">b)</span> <span class="pre">&gt;</span> <span class="pre">s(a,</span> <span class="pre">c)</span></tt>
if objects <tt class="docutils literal"><span class="pre">a</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> are considered &#8220;more similar&#8221; to objects
<tt class="docutils literal"><span class="pre">a</span></tt> and <tt class="docutils literal"><span class="pre">c</span></tt>. A kernel must also be positive semi-definite.</p>
<p>There are a number of ways to convert between a distance metric and a
similarity measure, such as a kernel. Let D be the distance, and S be the
kernel:</p>
<blockquote>
<div><ol class="arabic simple">
<li><tt class="docutils literal"><span class="pre">S</span> <span class="pre">=</span> <span class="pre">np.exp(-D</span> <span class="pre">*</span> <span class="pre">gamma)</span></tt>, where one heuristic for choosing
<tt class="docutils literal"><span class="pre">gamma</span></tt> is <tt class="docutils literal"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">num_features</span></tt></li>
<li><tt class="docutils literal"><span class="pre">S</span> <span class="pre">=</span> <span class="pre">1.</span> <span class="pre">/</span> <span class="pre">(D</span> <span class="pre">/</span> <span class="pre">np.max(D))</span></tt></li>
</ol>
</div></blockquote>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.additive_chi2_kernel.html#sklearn.metrics.pairwise.additive_chi2_kernel" title="sklearn.metrics.pairwise.additive_chi2_kernel"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.additive_chi2_kernel</span></tt></a>(X[,&nbsp;Y])</td>
<td>Computes the additive chi-squared kernel between observations in X and Y  The chi-squared kernel is computed between each pair of rows in X and Y.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.chi2_kernel.html#sklearn.metrics.pairwise.chi2_kernel" title="sklearn.metrics.pairwise.chi2_kernel"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.chi2_kernel</span></tt></a>(X[,&nbsp;Y,&nbsp;gamma])</td>
<td>Computes the exponential chi-squared kernel X and Y.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics" title="sklearn.metrics.pairwise.distance_metrics"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.distance_metrics</span></tt></a>()</td>
<td>Valid metrics for pairwise_distances.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.euclidean_distances.html#sklearn.metrics.pairwise.euclidean_distances" title="sklearn.metrics.pairwise.euclidean_distances"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.euclidean_distances</span></tt></a>(X[,&nbsp;Y,&nbsp;...])</td>
<td>Considering the rows of X (and Y=X) as vectors, compute the distance matrix between each pair of vectors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.kernel_metrics.html#sklearn.metrics.pairwise.kernel_metrics" title="sklearn.metrics.pairwise.kernel_metrics"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.kernel_metrics</span></tt></a>()</td>
<td>Valid metrics for pairwise_kernels  This function simply returns the valid pairwise distance metrics.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.linear_kernel.html#sklearn.metrics.pairwise.linear_kernel" title="sklearn.metrics.pairwise.linear_kernel"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.linear_kernel</span></tt></a>(X[,&nbsp;Y])</td>
<td>Compute the linear kernel between X and Y.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.manhattan_distances.html#sklearn.metrics.pairwise.manhattan_distances" title="sklearn.metrics.pairwise.manhattan_distances"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.manhattan_distances</span></tt></a>(X[,&nbsp;Y,&nbsp;...])</td>
<td>Compute the L1 distances between the vectors in X and Y.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.pairwise_distances.html#sklearn.metrics.pairwise.pairwise_distances" title="sklearn.metrics.pairwise.pairwise_distances"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.pairwise_distances</span></tt></a>(X[,&nbsp;Y,&nbsp;...])</td>
<td>Compute the distance matrix from a vector array X and optional Y.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.pairwise_kernels.html#sklearn.metrics.pairwise.pairwise_kernels" title="sklearn.metrics.pairwise.pairwise_kernels"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.pairwise_kernels</span></tt></a>(X[,&nbsp;Y,&nbsp;...])</td>
<td>Compute the kernel between arrays X and optional array Y.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.polynomial_kernel.html#sklearn.metrics.pairwise.polynomial_kernel" title="sklearn.metrics.pairwise.polynomial_kernel"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.polynomial_kernel</span></tt></a>(X[,&nbsp;Y,&nbsp;...])</td>
<td>Compute the polynomial kernel between X and Y:</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.pairwise.rbf_kernel.html#sklearn.metrics.pairwise.rbf_kernel" title="sklearn.metrics.pairwise.rbf_kernel"><tt class="xref py py-obj docutils literal"><span class="pre">metrics.pairwise.rbf_kernel</span></tt></a>(X[,&nbsp;Y,&nbsp;gamma])</td>
<td>Compute the rbf (gaussian) kernel between X and Y::      K(x, y) = exp(-γ ||x-y||²)  for each pair of rows x in X and y in Y.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.mixture">
<span id="sklearn-mixture-gaussian-mixture-models"></span><span id="mixture-ref"></span><h2><a class="reference internal" href="#module-sklearn.mixture" title="sklearn.mixture"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.mixture</span></tt></a>: Gaussian Mixture Models<a class="headerlink" href="#module-sklearn.mixture" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.mixture" title="sklearn.mixture"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.mixture</span></tt></a> module implements mixture modeling algorithms.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="mixture.html#mixture"><em>Gaussian mixture models</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.mixture.GMM.html#sklearn.mixture.GMM" title="sklearn.mixture.GMM"><tt class="xref py py-obj docutils literal"><span class="pre">mixture.GMM</span></tt></a>([n_components,&nbsp;covariance_type,&nbsp;...])</td>
<td>Gaussian Mixture Model  Representation of a Gaussian mixture model probability distribution.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.mixture.DPGMM.html#sklearn.mixture.DPGMM" title="sklearn.mixture.DPGMM"><tt class="xref py py-obj docutils literal"><span class="pre">mixture.DPGMM</span></tt></a>([n_components,&nbsp;...])</td>
<td>Variational Inference for the Infinite Gaussian Mixture Model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.mixture.VBGMM.html#sklearn.mixture.VBGMM" title="sklearn.mixture.VBGMM"><tt class="xref py py-obj docutils literal"><span class="pre">mixture.VBGMM</span></tt></a>([n_components,&nbsp;...])</td>
<td>Variational Inference for the Gaussian Mixture Model  Variational inference for a Gaussian mixture model probability distribution.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.multiclass">
<span id="sklearn-multiclass-multiclass-and-multilabel-classification"></span><span id="multiclass-ref"></span><h2><a class="reference internal" href="#module-sklearn.multiclass" title="sklearn.multiclass"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.multiclass</span></tt></a>: Multiclass and multilabel classification<a class="headerlink" href="#module-sklearn.multiclass" title="Permalink to this headline">¶</a></h2>
<div class="section" id="multiclass-and-multilabel-classification-strategies">
<h3>Multiclass and multilabel classification strategies<a class="headerlink" href="#multiclass-and-multilabel-classification-strategies" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>This module implements multiclass learning algorithms:</dt>
<dd><ul class="first last simple">
<li>one-vs-the-rest / one-vs-all</li>
<li>one-vs-one</li>
<li>error correcting output codes</li>
</ul>
</dd>
</dl>
<p>The estimators provided in this module are meta-estimators: they require a base
estimator to be provided in their constructor. For example, it is possible to
use these estimators to turn a binary classifier or a regressor into a
multiclass classifier. It is also possible to use these estimators with
multiclass estimators in the hope that their accuracy or runtime performance
improves.</p>
<p>All classifiers in scikit-learn implement multiclass classification; you
only need to use this module if you want to experiment with custom multiclass
strategies.</p>
<p>The one-vs-the-rest meta-classifier also implements a <cite>predict_proba</cite> method,
so long as such a method is implemented by the base classifier. This method
returns probabilities of class membership in both the single label and
multilabel case.  Note that in the multilabel case, probabilities are the
marginal probability that a given sample falls in the given class. As such, in
the multilabel case the sum of these probabilities over all possible labels
for a given sample <em>will not</em> sum to unity, as they do in the single label
case.</p>
</div>
<p><strong>User guide:</strong> See the <a class="reference internal" href="multiclass.html#multiclass"><em>Multiclass and multilabel algorithms</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier" title="sklearn.multiclass.OneVsRestClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.OneVsRestClassifier</span></tt></a>(estimator[,&nbsp;...])</td>
<td>One-vs-the-rest (OvR) multiclass/multilabel strategy  Also known as one-vs-all, this strategy consists in fitting one classifier per class.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier" title="sklearn.multiclass.OneVsOneClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.OneVsOneClassifier</span></tt></a>(estimator[,&nbsp;...])</td>
<td>One-vs-one multiclass strategy  This strategy consists in fitting one classifier per class pair.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.multiclass.OutputCodeClassifier.html#sklearn.multiclass.OutputCodeClassifier" title="sklearn.multiclass.OutputCodeClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.OutputCodeClassifier</span></tt></a>(estimator[,&nbsp;...])</td>
<td>(Error-Correcting) Output-Code multiclass strategy</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.multiclass.fit_ovr.html#sklearn.multiclass.fit_ovr" title="sklearn.multiclass.fit_ovr"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.fit_ovr</span></tt></a>(estimator,&nbsp;X,&nbsp;y[,&nbsp;n_jobs])</td>
<td>Fit a one-vs-the-rest strategy.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.multiclass.predict_ovr.html#sklearn.multiclass.predict_ovr" title="sklearn.multiclass.predict_ovr"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.predict_ovr</span></tt></a>(estimators,&nbsp;...)</td>
<td>Make predictions using the one-vs-the-rest strategy.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.multiclass.fit_ovo.html#sklearn.multiclass.fit_ovo" title="sklearn.multiclass.fit_ovo"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.fit_ovo</span></tt></a>(estimator,&nbsp;X,&nbsp;y[,&nbsp;n_jobs])</td>
<td>Fit a one-vs-one strategy.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.multiclass.predict_ovo.html#sklearn.multiclass.predict_ovo" title="sklearn.multiclass.predict_ovo"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.predict_ovo</span></tt></a>(estimators,&nbsp;classes,&nbsp;X)</td>
<td>Make predictions using the one-vs-one strategy.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.multiclass.fit_ecoc.html#sklearn.multiclass.fit_ecoc" title="sklearn.multiclass.fit_ecoc"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.fit_ecoc</span></tt></a>(estimator,&nbsp;X,&nbsp;y[,&nbsp;...])</td>
<td>Fit an error-correcting output-code strategy.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.multiclass.predict_ecoc.html#sklearn.multiclass.predict_ecoc" title="sklearn.multiclass.predict_ecoc"><tt class="xref py py-obj docutils literal"><span class="pre">multiclass.predict_ecoc</span></tt></a>(estimators,&nbsp;classes,&nbsp;...)</td>
<td>Make predictions using the error-correcting output-code strategy.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.naive_bayes">
<span id="sklearn-naive-bayes-naive-bayes"></span><span id="naive-bayes-ref"></span><h2><a class="reference internal" href="#module-sklearn.naive_bayes" title="sklearn.naive_bayes"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.naive_bayes</span></tt></a>: Naive Bayes<a class="headerlink" href="#module-sklearn.naive_bayes" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.naive_bayes" title="sklearn.naive_bayes"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.naive_bayes</span></tt></a> module implements Naive Bayes algorithms. These
are supervised learning methods based on applying Bayes&#8217; theorem with strong
(naive) feature independence assumptions.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="naive_bayes.html#naive-bayes"><em>Naive Bayes</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB" title="sklearn.naive_bayes.GaussianNB"><tt class="xref py py-obj docutils literal"><span class="pre">naive_bayes.GaussianNB</span></tt></a></td>
<td>Gaussian Naive Bayes (GaussianNB)   :Parameters:      <strong>X</strong> : array-like, shape = [n_samples, n_features]          Training vector, where n_samples in the number of samples and         n_features is the number of features.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB" title="sklearn.naive_bayes.MultinomialNB"><tt class="xref py py-obj docutils literal"><span class="pre">naive_bayes.MultinomialNB</span></tt></a>([alpha,&nbsp;...])</td>
<td>Naive Bayes classifier for multinomial models  The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB" title="sklearn.naive_bayes.BernoulliNB"><tt class="xref py py-obj docutils literal"><span class="pre">naive_bayes.BernoulliNB</span></tt></a>([alpha,&nbsp;binarize,&nbsp;...])</td>
<td>Naive Bayes classifier for multivariate Bernoulli models.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.neighbors">
<span id="sklearn-neighbors-nearest-neighbors"></span><span id="neighbors-ref"></span><h2><a class="reference internal" href="#module-sklearn.neighbors" title="sklearn.neighbors"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.neighbors</span></tt></a>: Nearest Neighbors<a class="headerlink" href="#module-sklearn.neighbors" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.neighbors" title="sklearn.neighbors"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.neighbors</span></tt></a> module implements the k-nearest neighbors
algorithm.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="neighbors.html#neighbors"><em>Nearest Neighbors</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors" title="sklearn.neighbors.NearestNeighbors"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.NearestNeighbors</span></tt></a>([n_neighbors,&nbsp;...])</td>
<td>Unsupervised learner for implementing neighbor searches.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.KNeighborsClassifier</span></tt></a>([...])</td>
<td>Classifier implementing the k-nearest neighbors vote.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier" title="sklearn.neighbors.RadiusNeighborsClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.RadiusNeighborsClassifier</span></tt></a>([...])</td>
<td>Classifier implementing a vote among neighbors within a given radius   :Parameters:      <strong>radius</strong> : float, optional (default = 1.0)          Range of parameter space to use by default for :meth`radius_neighbors`         queries.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor" title="sklearn.neighbors.KNeighborsRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.KNeighborsRegressor</span></tt></a>([n_neighbors,&nbsp;...])</td>
<td>Regression based on k-nearest neighbors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.neighbors.RadiusNeighborsRegressor.html#sklearn.neighbors.RadiusNeighborsRegressor" title="sklearn.neighbors.RadiusNeighborsRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.RadiusNeighborsRegressor</span></tt></a>([radius,&nbsp;...])</td>
<td>Regression based on neighbors within a fixed radius.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.neighbors.NearestCentroid.html#sklearn.neighbors.NearestCentroid" title="sklearn.neighbors.NearestCentroid"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.NearestCentroid</span></tt></a>([metric,&nbsp;...])</td>
<td>Nearest centroid classifier.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.BallTree</span></tt></a></td>
<td>BallTree for fast generalized N-point problems  BallTree(X, leaf_size=40, metric=&#8217;minkowski&#8217;, <strong>kwargs)  :Parameters:      **X</strong> : array-like, shape = [n_samples, n_features]          n_samples is the number of points in the data set, and         n_features is the dimension of the parameter space.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.KDTree</span></tt></a></td>
<td>KDTree for fast generalized N-point problems  KDTree(X, leaf_size=40, metric=&#8217;minkowski&#8217;, <strong>kwargs)  :Parameters:      **X</strong> : array-like, shape = [n_samples, n_features]          n_samples is the number of points in the data set, and         n_features is the dimension of the parameter space.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.DistanceMetric</span></tt></a></td>
<td>DistanceMetric class  This class provides a uniform interface to fast distance metric functions.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity" title="sklearn.neighbors.KernelDensity"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.KernelDensity</span></tt></a>([bandwidth,&nbsp;...])</td>
<td>Kernel Density Estimation   :Parameters:      <strong>bandwidth</strong> : float          The bandwidth of the kernel.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.kneighbors_graph</span></tt></a>(X,&nbsp;n_neighbors[,&nbsp;...])</td>
<td>Computes the (weighted) graph of k-Neighbors for points in X   :Parameters:      <strong>X</strong> : array-like or BallTree, shape = [n_samples, n_features]          Sample data, in the form of a numpy array or a precomputed         <tt class="xref py py-class docutils literal"><span class="pre">BallTree</span></tt>.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.neighbors.radius_neighbors_graph.html#sklearn.neighbors.radius_neighbors_graph" title="sklearn.neighbors.radius_neighbors_graph"><tt class="xref py py-obj docutils literal"><span class="pre">neighbors.radius_neighbors_graph</span></tt></a>(X,&nbsp;radius)</td>
<td>Computes the (weighted) graph of Neighbors for points in X  Neighborhoods are restricted the points at a distance lower than radius.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.neural_network">
<span id="sklearn-neural-network-neural-network-models"></span><span id="neural-network-ref"></span><h2><a class="reference internal" href="#module-sklearn.neural_network" title="sklearn.neural_network"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.neural_network</span></tt></a>: Neural network models<a class="headerlink" href="#module-sklearn.neural_network" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.neural_network" title="sklearn.neural_network"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.neural_network</span></tt></a> module includes models based on neural
networks.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="neural_networks.html#neural-network"><em>Neural network models (unsupervised)</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.neural_network.BernoulliRBM.html#sklearn.neural_network.BernoulliRBM" title="sklearn.neural_network.BernoulliRBM"><tt class="xref py py-obj docutils literal"><span class="pre">neural_network.BernoulliRBM</span></tt></a>([n_components,&nbsp;...])</td>
<td>Bernoulli Restricted Boltzmann Machine (RBM).</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.cross_decomposition">
<span id="sklearn-cross-decomposition-cross-decomposition"></span><span id="cross-decomposition-ref"></span><h2><a class="reference internal" href="#module-sklearn.cross_decomposition" title="sklearn.cross_decomposition"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.cross_decomposition</span></tt></a>: Cross decomposition<a class="headerlink" href="#module-sklearn.cross_decomposition" title="Permalink to this headline">¶</a></h2>
<p><strong>User guide:</strong> See the <a class="reference internal" href="cross_decomposition.html#cross-decomposition"><em>Cross decomposition</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_decomposition.PLSRegression.html#sklearn.cross_decomposition.PLSRegression" title="sklearn.cross_decomposition.PLSRegression"><tt class="xref py py-obj docutils literal"><span class="pre">cross_decomposition.PLSRegression</span></tt></a>([...])</td>
<td>PLS regression  PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1 in case of one dimensional response.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><tt class="xref py py-obj docutils literal"><span class="pre">cross_decomposition.PLSCanonical</span></tt></a>([...])</td>
<td>PLSCanonical implements the 2 blocks canonical PLS of the original Wold algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.cross_decomposition.CCA.html#sklearn.cross_decomposition.CCA" title="sklearn.cross_decomposition.CCA"><tt class="xref py py-obj docutils literal"><span class="pre">cross_decomposition.CCA</span></tt></a>([n_components,&nbsp;...])</td>
<td>CCA Canonical Correlation Analysis.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD" title="sklearn.cross_decomposition.PLSSVD"><tt class="xref py py-obj docutils literal"><span class="pre">cross_decomposition.PLSSVD</span></tt></a>([n_components,&nbsp;...])</td>
<td>Partial Least Square SVD  Simply perform a svd on the crosscovariance matrix: X&#8217;Y There are no iterative deflation here.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.pipeline">
<span id="sklearn-pipeline-pipeline"></span><span id="pipeline-ref"></span><h2><a class="reference internal" href="#module-sklearn.pipeline" title="sklearn.pipeline"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.pipeline</span></tt></a>: Pipeline<a class="headerlink" href="#module-sklearn.pipeline" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.pipeline" title="sklearn.pipeline"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.pipeline</span></tt></a> module implements utilities to build a composite
estimator, as a chain of transforms and estimators.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><tt class="xref py py-obj docutils literal"><span class="pre">pipeline.Pipeline</span></tt></a>(steps)</td>
<td>Pipeline of transforms with a final estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion" title="sklearn.pipeline.FeatureUnion"><tt class="xref py py-obj docutils literal"><span class="pre">pipeline.FeatureUnion</span></tt></a>(transformer_list[,&nbsp;...])</td>
<td>Concatenates results of multiple transformer objects.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">pipeline.make_pipeline</span></tt></td>
<td></td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">pipeline.make_union</span></tt></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.preprocessing">
<span id="sklearn-preprocessing-preprocessing-and-normalization"></span><span id="preprocessing-ref"></span><h2><a class="reference internal" href="#module-sklearn.preprocessing" title="sklearn.preprocessing"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.preprocessing</span></tt></a>: Preprocessing and Normalization<a class="headerlink" href="#module-sklearn.preprocessing" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.preprocessing" title="sklearn.preprocessing"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.preprocessing</span></tt></a> module includes scaling, centering,
normalization, binarization and imputation methods.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="preprocessing.html#preprocessing"><em>Preprocessing data</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.Binarizer</span></tt></a>([threshold,&nbsp;copy])</td>
<td>Binarize data (set feature values to 0 or 1) according to a threshold  Values greater than the threshold map to 1, while values less than or equal to the threshold map to 0.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.preprocessing.Imputer.html#sklearn.preprocessing.Imputer" title="sklearn.preprocessing.Imputer"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.Imputer</span></tt></a>([missing_values,&nbsp;...])</td>
<td>Imputation transformer for completing missing values.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.KernelCenterer.html#sklearn.preprocessing.KernelCenterer" title="sklearn.preprocessing.KernelCenterer"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.KernelCenterer</span></tt></a></td>
<td>Center a kernel matrix  Let K(x, z) be a kernel defined by phi(x)^T phi(z), where phi is a function mapping x to a Hilbert space.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer" title="sklearn.preprocessing.LabelBinarizer"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.LabelBinarizer</span></tt></a>([neg_label,&nbsp;...])</td>
<td>Binarize labels in a one-vs-all fashion  Several regression and binary classification algorithms are available in the scikit.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.LabelEncoder</span></tt></a></td>
<td>Encode labels with value between 0 and n_classes-1.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.MinMaxScaler</span></tt></a>([feature_range,&nbsp;copy])</td>
<td>Standardizes features by scaling each feature to a given range.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.Normalizer</span></tt></a>([norm,&nbsp;copy])</td>
<td>Normalize samples individually to unit norm  Each sample (i.e.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.OneHotEncoder</span></tt></a>([n_values,&nbsp;...])</td>
<td>Encode categorical integer features using a one-hot aka one-of-K scheme.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.StandardScaler</span></tt></a>([copy,&nbsp;...])</td>
<td>Standardize features by removing the mean and scaling to unit variance  Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set.</td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.PolynomialFeatures</span></tt></td>
<td></td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.add_dummy_feature.html#sklearn.preprocessing.add_dummy_feature" title="sklearn.preprocessing.add_dummy_feature"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.add_dummy_feature</span></tt></a>(X[,&nbsp;value])</td>
<td>Augment dataset with an additional dummy feature.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize" title="sklearn.preprocessing.binarize"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.binarize</span></tt></a>(X[,&nbsp;threshold,&nbsp;copy])</td>
<td>Boolean thresholding of array-like or scipy.sparse matrix   :Parameters:      <strong>X</strong> : array or scipy.sparse matrix with shape [n_samples, n_features]          The data to binarize, element by element.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.label_binarize.html#sklearn.preprocessing.label_binarize" title="sklearn.preprocessing.label_binarize"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.label_binarize</span></tt></a>(y,&nbsp;classes[,&nbsp;...])</td>
<td>Binarize labels in a one-vs-all fashion  Several regression and binary classification algorithms are available in the scikit.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize" title="sklearn.preprocessing.normalize"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.normalize</span></tt></a>(X[,&nbsp;norm,&nbsp;axis,&nbsp;copy])</td>
<td>Normalize a dataset along any axis   :Parameters:      <strong>X</strong> : array or scipy.sparse matrix with shape [n_samples, n_features]          The data to normalize, element by element.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><tt class="xref py py-obj docutils literal"><span class="pre">preprocessing.scale</span></tt></a>(X[,&nbsp;axis,&nbsp;with_mean,&nbsp;...])</td>
<td>Standardize a dataset along any axis  Center to the mean and component wise scale to unit variance.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.qda">
<span id="sklearn-qda-quadratic-discriminant-analysis"></span><h2><a class="reference internal" href="#module-sklearn.qda" title="sklearn.qda"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.qda</span></tt></a>: Quadratic Discriminant Analysis<a class="headerlink" href="#module-sklearn.qda" title="Permalink to this headline">¶</a></h2>
<p>Quadratic Discriminant Analysis</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="lda_qda.html#lda-qda"><em>Linear and quadratic discriminant analysis</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.qda.QDA.html#sklearn.qda.QDA" title="sklearn.qda.QDA"><tt class="xref py py-obj docutils literal"><span class="pre">qda.QDA</span></tt></a>([priors,&nbsp;reg_param])</td>
<td>Quadratic Discriminant Analysis (QDA)  A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes&#8217; rule.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.random_projection">
<span id="sklearn-random-projection-random-projection"></span><span id="random-projection-ref"></span><h2><a class="reference internal" href="#module-sklearn.random_projection" title="sklearn.random_projection"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.random_projection</span></tt></a>: Random projection<a class="headerlink" href="#module-sklearn.random_projection" title="Permalink to this headline">¶</a></h2>
<p>Random Projection transformers</p>
<p>Random Projections are a simple and computationally efficient way to
reduce the dimensionality of the data by trading a controlled amount
of accuracy (as additional variance) for faster processing times and
smaller model sizes.</p>
<p>The dimensions and distribution of Random Projections matrices are
controlled so as to preserve the pairwise distances between any two
samples of the dataset.</p>
<p>The main theoretical result behind the efficiency of random projection is the
<a class="reference external" href="http://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma">Johnson-Lindenstrauss lemma (quoting Wikipedia)</a>:</p>
<blockquote>
<div>In mathematics, the Johnson-Lindenstrauss lemma is a result
concerning low-distortion embeddings of points from high-dimensional
into low-dimensional Euclidean space. The lemma states that a small set
of points in a high-dimensional space can be embedded into a space of
much lower dimension in such a way that distances between the points are
nearly preserved. The map used for the embedding is at least Lipschitz,
and can even be taken to be an orthogonal projection.</div></blockquote>
<p><strong>User guide:</strong> See the <a class="reference internal" href="random_projection.html#random-projection"><em>Random Projection</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.random_projection.GaussianRandomProjection.html#sklearn.random_projection.GaussianRandomProjection" title="sklearn.random_projection.GaussianRandomProjection"><tt class="xref py py-obj docutils literal"><span class="pre">random_projection.GaussianRandomProjection</span></tt></a>([...])</td>
<td>Reduce dimensionality through Gaussian random projection  The components of the random matrix are drawn from N(0, 1 / n_components).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.random_projection.SparseRandomProjection.html#sklearn.random_projection.SparseRandomProjection" title="sklearn.random_projection.SparseRandomProjection"><tt class="xref py py-obj docutils literal"><span class="pre">random_projection.SparseRandomProjection</span></tt></a>([...])</td>
<td>Reduce dimensionality through sparse random projection  Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.random_projection.johnson_lindenstrauss_min_dim.html#sklearn.random_projection.johnson_lindenstrauss_min_dim" title="sklearn.random_projection.johnson_lindenstrauss_min_dim"><tt class="xref py py-obj docutils literal"><span class="pre">random_projection.johnson_lindenstrauss_min_dim</span></tt></a>(...)</td>
<td>Find a &#8216;safe&#8217; number of components to randomly project to  The distortion introduced by a random projection <cite>p</cite> only changes the distance between two points by a factor (1 ± eps) in an euclidean space with good probability.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.semi_supervised">
<span id="sklearn-semi-supervised-semi-supervised-learning"></span><span id="semi-supervised-ref"></span><h2><a class="reference internal" href="#module-sklearn.semi_supervised" title="sklearn.semi_supervised"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.semi_supervised</span></tt></a> Semi-Supervised Learning<a class="headerlink" href="#module-sklearn.semi_supervised" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.semi_supervised" title="sklearn.semi_supervised"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.semi_supervised</span></tt></a> module implements semi-supervised learning
algorithms. These algorithms utilized small amounts of labeled data and large
amounts of unlabeled data for classification tasks. This module includes Label
Propagation.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="label_propagation.html#semi-supervised"><em>Semi-Supervised</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.semi_supervised.LabelPropagation.html#sklearn.semi_supervised.LabelPropagation" title="sklearn.semi_supervised.LabelPropagation"><tt class="xref py py-obj docutils literal"><span class="pre">semi_supervised.LabelPropagation</span></tt></a>([kernel,&nbsp;...])</td>
<td>Label Propagation classifier   :Parameters:      <strong>kernel</strong> : {&#8216;knn&#8217;, &#8216;rbf&#8217;}          String identifier for kernel function to use.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.semi_supervised.LabelSpreading.html#sklearn.semi_supervised.LabelSpreading" title="sklearn.semi_supervised.LabelSpreading"><tt class="xref py py-obj docutils literal"><span class="pre">semi_supervised.LabelSpreading</span></tt></a>([kernel,&nbsp;...])</td>
<td>LabelSpreading model for semi-supervised learning  This model is similar to the basic Label Propgation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.svm">
<span id="sklearn-svm-support-vector-machines"></span><span id="svm-ref"></span><h2><a class="reference internal" href="#module-sklearn.svm" title="sklearn.svm"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.svm</span></tt></a>: Support Vector Machines<a class="headerlink" href="#module-sklearn.svm" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.svm" title="sklearn.svm"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.svm</span></tt></a> module includes Support Vector Machine algorithms.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="svm.html#svm"><em>Support Vector Machines</em></a> section for further details.</p>
<div class="section" id="estimators">
<h3>Estimators<a class="headerlink" href="#estimators" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><tt class="xref py py-obj docutils literal"><span class="pre">svm.SVC</span></tt></a>([C,&nbsp;kernel,&nbsp;degree,&nbsp;gamma,&nbsp;coef0,&nbsp;...])</td>
<td>C-Support Vector Classification.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><tt class="xref py py-obj docutils literal"><span class="pre">svm.LinearSVC</span></tt></a>([penalty,&nbsp;loss,&nbsp;dual,&nbsp;tol,&nbsp;C,&nbsp;...])</td>
<td>Linear Support Vector Classification.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><tt class="xref py py-obj docutils literal"><span class="pre">svm.NuSVC</span></tt></a>([nu,&nbsp;kernel,&nbsp;degree,&nbsp;gamma,&nbsp;...])</td>
<td>Nu-Support Vector Classification.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.svm.SVR.html#sklearn.svm.SVR" title="sklearn.svm.SVR"><tt class="xref py py-obj docutils literal"><span class="pre">svm.SVR</span></tt></a>([kernel,&nbsp;degree,&nbsp;gamma,&nbsp;coef0,&nbsp;tol,&nbsp;...])</td>
<td>epsilon-Support Vector Regression.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><tt class="xref py py-obj docutils literal"><span class="pre">svm.NuSVR</span></tt></a>([nu,&nbsp;C,&nbsp;kernel,&nbsp;degree,&nbsp;gamma,&nbsp;...])</td>
<td>Nu Support Vector Regression.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><tt class="xref py py-obj docutils literal"><span class="pre">svm.OneClassSVM</span></tt></a>([kernel,&nbsp;degree,&nbsp;gamma,&nbsp;...])</td>
<td>Unsupervised Outliers Detection.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.svm.l1_min_c.html#sklearn.svm.l1_min_c" title="sklearn.svm.l1_min_c"><tt class="xref py py-obj docutils literal"><span class="pre">svm.l1_min_c</span></tt></a>(X,&nbsp;y[,&nbsp;loss,&nbsp;fit_intercept,&nbsp;...])</td>
<td>Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="low-level-methods">
<h3>Low-level methods<a class="headerlink" href="#low-level-methods" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.svm.libsvm.fit.html#sklearn.svm.libsvm.fit" title="sklearn.svm.libsvm.fit"><tt class="xref py py-obj docutils literal"><span class="pre">svm.libsvm.fit</span></tt></a></td>
<td>Train the model using libsvm (low-level method)   :Parameters:      <strong>X</strong> : array-like, dtype=float64, size=[n_samples, n_features]                <strong>Y</strong> : array, dtype=float64, size=[n_samples]          target vector               <strong>svm_type</strong> : {0, 1, 2, 3, 4}, optional          Type of SVM: C_SVC, NuSVC, OneClassSVM, EpsilonSVR or NuSVR         respectively.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.svm.libsvm.decision_function.html#sklearn.svm.libsvm.decision_function" title="sklearn.svm.libsvm.decision_function"><tt class="xref py py-obj docutils literal"><span class="pre">svm.libsvm.decision_function</span></tt></a></td>
<td>Predict margin (libsvm name for this is predict_values)  We have to reconstruct model and parameters to make sure we stay in sync with the python object.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.svm.libsvm.predict.html#sklearn.svm.libsvm.predict" title="sklearn.svm.libsvm.predict"><tt class="xref py py-obj docutils literal"><span class="pre">svm.libsvm.predict</span></tt></a></td>
<td>Predict target values of X given a model (low-level method)   :Parameters:      <strong>X: array-like, dtype=float, size=[n_samples, n_features]</strong> :                 <strong>svm_type</strong> : {0, 1, 2, 3, 4}          Type of SVM: C SVC, nu SVC, one class, epsilon SVR, nu SVR      <strong>kernel</strong> : {&#8216;linear&#8217;, &#8216;rbf&#8217;, &#8216;poly&#8217;, &#8216;sigmoid&#8217;, &#8216;precomputed&#8217;}          Type of kernel.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.svm.libsvm.predict_proba.html#sklearn.svm.libsvm.predict_proba" title="sklearn.svm.libsvm.predict_proba"><tt class="xref py py-obj docutils literal"><span class="pre">svm.libsvm.predict_proba</span></tt></a></td>
<td>Predict probabilities  svm_model stores all parameters needed to predict a given value.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.svm.libsvm.cross_validation.html#sklearn.svm.libsvm.cross_validation" title="sklearn.svm.libsvm.cross_validation"><tt class="xref py py-obj docutils literal"><span class="pre">svm.libsvm.cross_validation</span></tt></a></td>
<td>Binding of the cross-validation routine (low-level routine)   :Parameters:      <strong>X: array-like, dtype=float, size=[n_samples, n_features]</strong> :                 <strong>Y: array, dtype=float, size=[n_samples]</strong> :           target vector               <strong>svm_type</strong> : {0, 1, 2, 3, 4}          Type of SVM: C SVC, nu SVC, one class, epsilon SVR, nu SVR               <strong>kernel</strong> : {&#8216;linear&#8217;, &#8216;rbf&#8217;, &#8216;poly&#8217;, &#8216;sigmoid&#8217;, &#8216;precomputed&#8217;}          Kernel to use in the model: linear, polynomial, RBF, sigmoid         or precomputed.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="module-sklearn.tree">
<span id="sklearn-tree-decision-trees"></span><span id="tree-ref"></span><h2><a class="reference internal" href="#module-sklearn.tree" title="sklearn.tree"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.tree</span></tt></a>: Decision Trees<a class="headerlink" href="#module-sklearn.tree" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.tree" title="sklearn.tree"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.tree</span></tt></a> module includes decision tree-based models for
classification and regression.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="tree.html#tree"><em>Decision Trees</em></a> section for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">tree.DecisionTreeClassifier</span></tt></a>([criterion,&nbsp;...])</td>
<td>A decision tree classifier.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor" title="sklearn.tree.DecisionTreeRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">tree.DecisionTreeRegressor</span></tt></a>([criterion,&nbsp;...])</td>
<td>A tree regressor.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier" title="sklearn.tree.ExtraTreeClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">tree.ExtraTreeClassifier</span></tt></a>([criterion,&nbsp;...])</td>
<td>An extremely randomized tree classifier.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.tree.ExtraTreeRegressor.html#sklearn.tree.ExtraTreeRegressor" title="sklearn.tree.ExtraTreeRegressor"><tt class="xref py py-obj docutils literal"><span class="pre">tree.ExtraTreeRegressor</span></tt></a>([criterion,&nbsp;...])</td>
<td>An extremely randomized tree regressor.</td>
</tr>
</tbody>
</table>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz" title="sklearn.tree.export_graphviz"><tt class="xref py py-obj docutils literal"><span class="pre">tree.export_graphviz</span></tt></a>(decision_tree[,&nbsp;...])</td>
<td>Export a decision tree in DOT format.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-sklearn.utils">
<span id="sklearn-utils-utilities"></span><span id="utils-ref"></span><h2><a class="reference internal" href="#module-sklearn.utils" title="sklearn.utils"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.utils</span></tt></a>: Utilities<a class="headerlink" href="#module-sklearn.utils" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.utils" title="sklearn.utils"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.utils</span></tt></a> module includes various utilities.</p>
<p><strong>Developer guide:</strong> See the <a class="reference internal" href="../developers/utilities.html#developers-utils"><em>Utilities for Developers</em></a> page for further details.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.utils.check_random_state.html#sklearn.utils.check_random_state" title="sklearn.utils.check_random_state"><tt class="xref py py-obj docutils literal"><span class="pre">utils.check_random_state</span></tt></a>(seed)</td>
<td>Turn seed into a np.random.RandomState instance  If seed is None, return the RandomState singleton used by np.random.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.utils.resample.html#sklearn.utils.resample" title="sklearn.utils.resample"><tt class="xref py py-obj docutils literal"><span class="pre">utils.resample</span></tt></a>(*arrays,&nbsp;**options)</td>
<td>Resample arrays or sparse matrices in a consistent way  The default strategy implements one step of the bootstrapping procedure.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.utils.shuffle.html#sklearn.utils.shuffle" title="sklearn.utils.shuffle"><tt class="xref py py-obj docutils literal"><span class="pre">utils.shuffle</span></tt></a>(*arrays,&nbsp;**options)</td>
<td>Shuffle arrays or sparse matrices in a consistent way  This is a convenience alias to <tt class="docutils literal"><span class="pre">resample(*arrays,</span> <span class="pre">replace=False)</span></tt> to do random permutations of the collections.</td>
</tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010 - 2014, scikit-learn developers (BSD License).
      <a href="../_sources/modules/classes.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="../datasets/twenty_newsgroups.html">Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="generated/sklearn.base.BaseEstimator.html">Next
      </a>
    </div>
    <div class="buttonPrevious">
      <a href="../np-modindex.html">Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="../py-modindex.html">Next
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>