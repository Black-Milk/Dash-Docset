

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Scaling the regularization parameter for SVCs &mdash; scikit-learn 0.13.1 documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.13.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/sidebar.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="top" title="scikit-learn 0.13.1 documentation" href="../../index.html" />
    <link rel="up" title="Examples" href="../index.html" />
    <link rel="next" title="RBF SVM parameters" href="plot_rbf_parameters.html" />
    <link rel="prev" title="SVM Margins Example" href="plot_svm_margin.html" />


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>



  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="../../install.html">Download</a></li>
            <li><a href="../../support.html">Support</a></li>
            <li><a href="../../user_guide.html">User Guide</a></li>
            <li><a href="../index.html">Examples</a></li>
            <li><a href="../../modules/classes.html">Reference</a></li>
       </ul>

<div class="search_form">

<div id="cse" style="width: 100%;"></div>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
  google.load('search', '1', {language : 'en'});
  google.setOnLoadCallback(function() {
    var customSearchControl = new google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
    customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
    var options = new google.search.DrawOptions();
    options.setAutoComplete(true);
    customSearchControl.draw('cse', options);
  }, true);
</script>

</div>
          </div> <!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
	  <div class="rel">
	   
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  -->
	<div class="rellink">
	<a href="plot_svm_margin.html" title="SVM Margins Example"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    SVM Margins Exam...
	    </span>
	    <span class="hiddenrellink">
	    SVM Margins Example
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="plot_rbf_parameters.html" title="RBF SVM parameters"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    RBF SVM paramete...
	    </span>
	    <span class="hiddenrellink">
	    RBF SVM parameters
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page -->
	<div class="spacer">
	&nbsp;
	</div>
	<div class="rellink">
	<a href="../index.html" title="Examples" >
	Up
	<br>
	<span class="smallrellink">
	Examples
	</span>
	<span class="hiddenrellink">
	Examples
	</span>
	
	</a>
	</div>
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.13.1</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3><a href="../../about.html#citing-scikit-learn">Citing</a></h3>
    <p>If you use the software, please consider
    <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">Scaling the regularization parameter for SVCs</a><ul>
<li><a class="reference internal" href="#l1-penalty-case">L1-penalty case</a></li>
<li><a class="reference internal" href="#l2-penalty-case">L2-penalty case</a></li>
<li><a class="reference internal" href="#simulations">Simulations</a></li>
</ul>
</li>
</ul>

    
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="scaling-the-regularization-parameter-for-svcs">
<span id="example-svm-plot-svm-scale-c-py"></span><h1>Scaling the regularization parameter for SVCs<a class="headerlink" href="#scaling-the-regularization-parameter-for-svcs" title="Permalink to this headline">¶</a></h1>
<p>The following example illustrates the effect of scaling the
regularization parameter when using <a class="reference internal" href="../../modules/svm.html#svm"><em>Support Vector Machines</em></a> for
<a class="reference internal" href="../../modules/svm.html#svm-classification"><em>classification</em></a>.
For SVC classification, we are interested in a risk minimization for the
equation:</p>
<div class="math">
<p><img src="../../_images/math/fc7ec7d9823ca17c1383c839e94e0fc38e56678a.png" alt="C \sum_{i=1, n} \mathcal{L} (f(x_i), y_i) + \Omega (w)"/></p>
</div><p>where</p>
<blockquote>
<div><ul class="simple">
<li><img class="math" src="../../_images/math/c3355896da590fc491a10150a50416687626d7cc.png" alt="C"/> is used to set the amount of regularization</li>
<li><img class="math" src="../../_images/math/f58392aca325862b9672f1ad5e9b2967461d6144.png" alt="\mathcal{L}"/> is a <cite>loss</cite> function of our samples
and our model parameters.</li>
<li><img class="math" src="../../_images/math/9e2b196e9b7e57d1ec99f6534c581ea9759d2170.png" alt="\Omega"/> is a <cite>penalty</cite> function of our model parameters</li>
</ul>
</div></blockquote>
<p>If we consider the loss function to be the individual error per
sample, then the data-fit term, or the sum of the error for each sample, will
increase as we add more samples. The penalization term, however, will not
increase.</p>
<p>When using, for example, <a class="reference internal" href="../../modules/cross_validation.html#cross-validation"><em>cross validation</em></a>, to
set the amount of regularization with <cite>C</cite>, there will be a
different amount of samples between the main problem and the smaller problems
within the folds of the cross validation.</p>
<p>Since our loss function is dependent on the amount of samples, the latter
will influence the selected value of <cite>C</cite>.
The question that arises is <cite>How do we optimally adjust C to
account for the different amount of training samples?</cite></p>
<p>The figures below are used to illustrate the effect of scaling our
<cite>C</cite> to compensate for the change in the number of samples, in the
case of using an <cite>L1</cite> penalty, as well as the <cite>L2</cite> penalty.</p>
<div class="section" id="l1-penalty-case">
<h2>L1-penalty case<a class="headerlink" href="#l1-penalty-case" title="Permalink to this headline">¶</a></h2>
<p>In the <cite>L1</cite> case, theory says that prediction consistency
(i.e. that under given hypothesis, the estimator
learned predicts as well as a model knowing the true distribution)
is not possible because of the bias of the <cite>L1</cite>. It does say, however,
that model consistency, in terms of finding the right set of non-zero
parameters as well as their signs, can be achieved by scaling
<cite>C1</cite>.</p>
</div>
<div class="section" id="l2-penalty-case">
<h2>L2-penalty case<a class="headerlink" href="#l2-penalty-case" title="Permalink to this headline">¶</a></h2>
<p>The theory says that in order to achieve prediction consistency, the
penalty parameter should be kept constant
as the number of samples grow.</p>
</div>
<div class="section" id="simulations">
<h2>Simulations<a class="headerlink" href="#simulations" title="Permalink to this headline">¶</a></h2>
<p>The two figures below plot the values of <cite>C</cite> on the <cite>x-axis</cite> and the
corresponding cross-validation scores on the <cite>y-axis</cite>, for several different
fractions of a generated data-set.</p>
<p>In the <cite>L1</cite> penalty case, the cross-validation-error correlates best with
the test-error, when scaling our <cite>C</cite> with the number of samples, <cite>n</cite>,
which can be seen in the first figure.</p>
<p>For the <cite>L2</cite> penalty case, the best result comes from the case where <cite>C</cite>
is not scaled.</p>
<div class="topic">
<p class="topic-title first">Note:</p>
<p>Two separate datasets are used for the two different plots. The reason
behind this is the <cite>L1</cite> case works better on sparse data, while <cite>L2</cite>
is better suited to the non-sparse case.</p>
</div>
<p><strong>Python source code:</strong> <a class="reference download internal" href="../../_downloads/plot_svm_scale_c.py"><tt class="xref download docutils literal"><span class="pre">plot_svm_scale_c.py</span></tt></a></p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="n">__doc__</span><span class="p">)</span>


<span class="c"># Author: Andreas Mueller &lt;amueller@ais.uni-bonn.de&gt;</span>
<span class="c">#         Jaques Grobler &lt;jaques.grobler@inria.fr&gt;</span>
<span class="c"># License: BSD 3 clause</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="kn">as</span> <span class="nn">pl</span>

<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>


<span class="n">rnd</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># set up dataset</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">300</span>

<span class="c"># L1 data (only 5 informative features)</span>
<span class="n">X_1</span><span class="p">,</span> <span class="n">y_1</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
                                        <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                        <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># L2 data: non sparse, but less features</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span> <span class="o">-</span> <span class="n">rnd</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span>
<span class="n">X_2</span> <span class="o">=</span> <span class="n">rnd</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">/</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="n">y_2</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">X_2</span> <span class="o">+=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">rnd</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">/</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">clf_sets</span> <span class="o">=</span> <span class="p">[(</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s">&#39;L1&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">&#39;L2&#39;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                       <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
             <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">X_1</span><span class="p">,</span> <span class="n">y_1</span><span class="p">),</span>
            <span class="p">(</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s">&#39;L2&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">&#39;L2&#39;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                       <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">),</span>
             <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mf">4.5</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">X_2</span><span class="p">,</span> <span class="n">y_2</span><span class="p">)]</span>

<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="s">&#39;g&#39;</span><span class="p">,</span> <span class="s">&#39;r&#39;</span><span class="p">,</span> <span class="s">&#39;c&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">fignum</span><span class="p">,</span> <span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">cs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clf_sets</span><span class="p">):</span>
    <span class="c"># set up the plot for each regressor</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">fignum</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">train_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">3</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">cs</span><span class="p">)</span>
        <span class="c"># To get nice curve, we need a large number of iterations to</span>
        <span class="c"># reduce the variance</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
                            <span class="n">cv</span><span class="o">=</span><span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
                                            <span class="n">n_iter</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">grid</span><span class="o">.</span><span class="n">cv_scores_</span><span class="p">]</span>

        <span class="n">scales</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="s">&#39;No scaling&#39;</span><span class="p">),</span>
                  <span class="p">((</span><span class="n">n_samples</span> <span class="o">*</span> <span class="n">train_size</span><span class="p">),</span> <span class="s">&#39;1/n_samples&#39;</span><span class="p">),</span>
                  <span class="p">]</span>

        <span class="k">for</span> <span class="n">subplotnum</span><span class="p">,</span> <span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">scales</span><span class="p">):</span>
            <span class="n">pl</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">subplotnum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">pl</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;C&#39;</span><span class="p">)</span>
            <span class="n">pl</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;CV Score&#39;</span><span class="p">)</span>
            <span class="n">grid_cs</span> <span class="o">=</span> <span class="n">cs</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">scaler</span><span class="p">)</span>  <span class="c"># scale the C&#39;s</span>
            <span class="n">pl</span><span class="o">.</span><span class="n">semilogx</span><span class="p">(</span><span class="n">grid_cs</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">&quot;fraction </span><span class="si">%.2f</span><span class="s">&quot;</span> <span class="o">%</span>
                        <span class="n">train_size</span><span class="p">)</span>
            <span class="n">pl</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;scaling=</span><span class="si">%s</span><span class="s">, penalty=</span><span class="si">%s</span><span class="s">, loss=</span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">penalty</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">loss</span><span class="p">))</span>

    <span class="n">pl</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">&quot;best&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010–2013, scikit-learn developers (BSD License).
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="../../_sources/auto_examples/svm/plot_svm_scale_c.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="plot_svm_margin.html">
        Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="plot_rbf_parameters.html">
        Next
      </a>
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
       var bodywrapper = $('.bodywrapper');
   	var sidebarbutton = $('#sidebarbutton');
        sidebarbutton.css({
	    'height': '900px'
       });
     </script>
  </body>
</html>