

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>8.24.1. sklearn.pls.PLSRegression &mdash; scikit-learn 0.13.1 documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.13.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/sidebar.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="top" title="scikit-learn 0.13.1 documentation" href="../../index.html" />
    <link rel="up" title="8. Reference" href="../classes.html" />
    <link rel="next" title="8.24.2. sklearn.pls.PLSCanonical" href="sklearn.pls.PLSCanonical.html" />
    <link rel="prev" title="8.23.9. sklearn.neighbors.radius_neighbors_graph" href="sklearn.neighbors.radius_neighbors_graph.html" />


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>



  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="../../install.html">Download</a></li>
            <li><a href="../../support.html">Support</a></li>
            <li><a href="../../user_guide.html">User Guide</a></li>
            <li><a href="../../auto_examples/index.html">Examples</a></li>
            <li><a href="../classes.html">Reference</a></li>
       </ul>

<div class="search_form">

<div id="cse" style="width: 100%;"></div>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
  google.load('search', '1', {language : 'en'});
  google.setOnLoadCallback(function() {
    var customSearchControl = new google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
    customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
    var options = new google.search.DrawOptions();
    options.setAutoComplete(true);
    customSearchControl.draw('cse', options);
  }, true);
</script>

</div>
          </div> <!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
	  <div class="rel">
	   
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  -->
	<div class="rellink">
	<a href="sklearn.neighbors.radius_neighbors_graph.html" title="8.23.9. sklearn.neighbors.radius_neighbors_graph"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    8.23.9. sklearn....
	    </span>
	    <span class="hiddenrellink">
	    8.23.9. sklearn.neighbors.radius_neighbors_graph
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="sklearn.pls.PLSCanonical.html" title="8.24.2. sklearn.pls.PLSCanonical"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    8.24.2. sklearn....
	    </span>
	    <span class="hiddenrellink">
	    8.24.2. sklearn.pls.PLSCanonical
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page -->
	<div class="spacer">
	&nbsp;
	</div>
	<div class="rellink">
	<a href="../classes.html" title="8. Reference" >
	Up
	<br>
	<span class="smallrellink">
	8. Reference
	</span>
	<span class="hiddenrellink">
	8. Reference
	</span>
	
	</a>
	</div>
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.13.1</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3><a href="../../about.html#citing-scikit-learn">Citing</a></h3>
    <p>If you use the software, please consider
    <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">8.24.1. sklearn.pls.PLSRegression</a></li>
</ul>

    
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="sklearn-pls-plsregression">
<h1>8.24.1. sklearn.pls.PLSRegression<a class="headerlink" href="#sklearn-pls-plsregression" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.pls.PLSRegression">
<em class="property">class </em><tt class="descclassname">sklearn.pls.</tt><tt class="descname">PLSRegression</tt><big>(</big><em>n_components=2</em>, <em>scale=True</em>, <em>max_iter=500</em>, <em>tol=1e-06</em>, <em>copy=True</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>PLS regression</p>
<p>PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1
in case of one dimensional response.
This class inherits from _PLS with mode=&#8221;A&#8221;, deflation_mode=&#8221;regression&#8221;,
norm_y_weights=False and algorithm=&#8221;nipals&#8221;.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of predictors, shape = [n_samples, p]</p>
<blockquote>
<div><p>Training vectors, where n_samples in the number of samples and
p is the number of predictors.</p>
</div></blockquote>
<p><strong>Y</strong> : array-like of response, shape = [n_samples, q]</p>
<blockquote>
<div><p>Training vectors, where n_samples in the number of samples and
q is the number of response variables.</p>
</div></blockquote>
<p><strong>n_components</strong> : int, (default 2)</p>
<blockquote>
<div><p>Number of components to keep.</p>
</div></blockquote>
<p><strong>scale</strong> : boolean, (default True)</p>
<blockquote>
<div><p>whether to scale the data</p>
</div></blockquote>
<p><strong>max_iter</strong> : an integer, (default 500)</p>
<blockquote>
<div><p>the maximum number of iterations of the NIPALS inner loop (used
only if algorithm=&#8221;nipals&#8221;)</p>
</div></blockquote>
<p><strong>tol</strong> : non-negative real</p>
<blockquote>
<div><p>Tolerance used in the iterative algorithm default 1e-06.</p>
</div></blockquote>
<p><strong>copy</strong> : boolean, default True</p>
<blockquote class="last">
<div><p>Whether the deflation should be done on a copy. Let the default
value to True unless you don&#8217;t care about side effect</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>For each component k, find weights u, v that optimizes:
<tt class="docutils literal"><span class="pre">max</span> <span class="pre">corr(Xk</span> <span class="pre">u,</span> <span class="pre">Yk</span> <span class="pre">v)</span> <span class="pre">*</span> <span class="pre">var(Xk</span> <span class="pre">u)</span> <span class="pre">var(Yk</span> <span class="pre">u)</span></tt>, such that <tt class="docutils literal"><span class="pre">|u|</span> <span class="pre">=</span> <span class="pre">1</span></tt></p>
<p>Note that it maximizes both the correlations between the scores and the
intra-block variances.</p>
<p>The residual matrix of X (Xk+1) block is obtained by the deflation on
the current X score: x_score.</p>
<p>The residual matrix of Y (Yk+1) block is obtained by deflation on the
current X score. This performs the PLS regression known as PLS2. This
mode is prediction oriented.</p>
<p>This implementation provides the same results that 3 PLS packages
provided in the R language (R-project):</p>
<blockquote>
<div><ul class="simple">
<li>&#8220;mixOmics&#8221; with function pls(X, Y, mode = &#8220;regression&#8221;)</li>
<li>&#8220;plspm &#8221; with function plsreg2(X, Y)</li>
<li>&#8220;pls&#8221; with function oscorespls.fit(X, Y)</li>
</ul>
</div></blockquote>
<p class="rubric">References</p>
<p>Jacob A. Wegelin. A survey of Partial Least Squares (PLS) methods, with
emphasis on the two-block case. Technical Report 371, Department of
Statistics, University of Washington, Seattle, 2000.</p>
<p>In french but still a reference:
Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris:
Editions Technic.</p>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pls</span> <span class="kn">import</span> <span class="n">PLSCanonical</span><span class="p">,</span> <span class="n">PLSRegression</span><span class="p">,</span> <span class="n">CCA</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span><span class="mf">5.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.2</span><span class="p">,</span> <span class="mf">5.9</span><span class="p">],</span> <span class="p">[</span><span class="mf">11.9</span><span class="p">,</span> <span class="mf">12.3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pls2</span> <span class="o">=</span> <span class="n">PLSRegression</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pls2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="gp">... </span>
<span class="go">PLSRegression(copy=True, max_iter=500, n_components=2, scale=True,</span>
<span class="go">        tol=1e-06)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_pred</span> <span class="o">=</span> <span class="n">pls2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="19%" />
<col width="30%" />
<col width="51%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><cite>x_weights_</cite></td>
<td>array, [p, n_components]</td>
<td>X block weights vectors.</td>
</tr>
<tr class="row-even"><td><cite>y_weights_</cite></td>
<td>array, [q, n_components]</td>
<td>Y block weights vectors.</td>
</tr>
<tr class="row-odd"><td><cite>x_loadings_</cite></td>
<td>array, [p, n_components]</td>
<td>X block loadings vectors.</td>
</tr>
<tr class="row-even"><td><cite>y_loadings_</cite></td>
<td>array, [q, n_components]</td>
<td>Y block loadings vectors.</td>
</tr>
<tr class="row-odd"><td><cite>x_scores_</cite></td>
<td>array, [n_samples, n_components]</td>
<td>X scores.</td>
</tr>
<tr class="row-even"><td><cite>y_scores_</cite></td>
<td>array, [n_samples, n_components]</td>
<td>Y scores.</td>
</tr>
<tr class="row-odd"><td><cite>x_rotations_</cite></td>
<td>array, [p, n_components]</td>
<td>X block to latents rotations.</td>
</tr>
<tr class="row-even"><td><cite>y_rotations_</cite></td>
<td>array, [q, n_components]</td>
<td>Y block to latents rotations.</td>
</tr>
<tr class="row-odd"><td>coefs: array, [p, q]</td>
<td>&nbsp;</td>
<td>The coeficients of the linear model: Y = X coefs + Err</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">fit</span></tt>(X,&nbsp;Y)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.pls.PLSRegression.fit_transform" title="sklearn.pls.PLSRegression.fit_transform"><tt class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></tt></a>(X[,&nbsp;y])</td>
<td>Learn and apply the dimension reduction on the train data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.pls.PLSRegression.get_params" title="sklearn.pls.PLSRegression.get_params"><tt class="xref py py-obj docutils literal"><span class="pre">get_params</span></tt></a>([deep])</td>
<td>Get parameters for the estimator</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.pls.PLSRegression.predict" title="sklearn.pls.PLSRegression.predict"><tt class="xref py py-obj docutils literal"><span class="pre">predict</span></tt></a>(X[,&nbsp;copy])</td>
<td>Apply the dimension reduction learned on the train data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.pls.PLSRegression.score" title="sklearn.pls.PLSRegression.score"><tt class="xref py py-obj docutils literal"><span class="pre">score</span></tt></a>(X,&nbsp;y)</td>
<td>Returns the coefficient of determination R^2 of the prediction.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.pls.PLSRegression.set_params" title="sklearn.pls.PLSRegression.set_params"><tt class="xref py py-obj docutils literal"><span class="pre">set_params</span></tt></a>(**params)</td>
<td>Set the parameters of the estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.pls.PLSRegression.transform" title="sklearn.pls.PLSRegression.transform"><tt class="xref py py-obj docutils literal"><span class="pre">transform</span></tt></a>(X[,&nbsp;Y,&nbsp;copy])</td>
<td>Apply the dimension reduction learned on the train data.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.pls.PLSRegression.__init__">
<tt class="descname">__init__</tt><big>(</big><em>n_components=2</em>, <em>scale=True</em>, <em>max_iter=500</em>, <em>tol=1e-06</em>, <em>copy=True</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="sklearn.pls.PLSRegression.fit_transform">
<tt class="descname">fit_transform</tt><big>(</big><em>X</em>, <em>y=None</em>, <em>**fit_params</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn and apply the dimension reduction on the train data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of predictors, shape = [n_samples, p]</p>
<blockquote>
<div><p>Training vectors, where n_samples in the number of samples and
p is the number of predictors.</p>
</div></blockquote>
<p><strong>Y</strong> : array-like of response, shape = [n_samples, q], optional</p>
<blockquote>
<div><p>Training vectors, where n_samples in the number of samples and
q is the number of response variables.</p>
</div></blockquote>
<p><strong>copy</strong> : boolean</p>
<blockquote>
<div><p>Whether to copy X and Y, or perform in-place normalization.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last"><strong>x_scores if Y is not given, (x_scores, y_scores) otherwise.</strong> :</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.pls.PLSRegression.get_params">
<tt class="descname">get_params</tt><big>(</big><em>deep=True</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for the estimator</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>deep: boolean, optional</strong> :</p>
<blockquote class="last">
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.pls.PLSRegression.predict">
<tt class="descname">predict</tt><big>(</big><em>X</em>, <em>copy=True</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the dimension reduction learned on the train data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of predictors, shape = [n_samples, p]</p>
<blockquote>
<div><p>Training vectors, where n_samples in the number of samples and
p is the number of predictors.</p>
</div></blockquote>
<p><strong>copy</strong> : boolean</p>
<blockquote class="last">
<div><p>Whether to copy X and Y, or perform in-place normalization.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>This call require the estimation of a p x q matrix, which may
be an issue in high dimensional space.</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.pls.PLSRegression.score">
<tt class="descname">score</tt><big>(</big><em>X</em>, <em>y</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the regression
sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual
sum of squares ((y_true - y_true.mean()) ** 2).sum().
Best possible score is 1.0, lower values are worse.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Training set.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = [n_samples]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last"><strong>z</strong> : float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.pls.PLSRegression.set_params">
<tt class="descname">set_params</tt><big>(</big><em>**params</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of the estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<tt class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></tt> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns :</th><td class="field-body"><strong>self</strong> :</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.pls.PLSRegression.transform">
<tt class="descname">transform</tt><big>(</big><em>X</em>, <em>Y=None</em>, <em>copy=True</em><big>)</big><a class="headerlink" href="#sklearn.pls.PLSRegression.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the dimension reduction learned on the train data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of predictors, shape = [n_samples, p]</p>
<blockquote>
<div><p>Training vectors, where n_samples in the number of samples and
p is the number of predictors.</p>
</div></blockquote>
<p><strong>Y</strong> : array-like of response, shape = [n_samples, q], optional</p>
<blockquote>
<div><p>Training vectors, where n_samples in the number of samples and
q is the number of response variables.</p>
</div></blockquote>
<p><strong>copy</strong> : boolean</p>
<blockquote>
<div><p>Whether to copy X and Y, or perform in-place normalization.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last"><strong>x_scores if Y is not given, (x_scores, y_scores) otherwise.</strong> :</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010–2013, scikit-learn developers (BSD License).
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="../../_sources/modules/generated/sklearn.pls.PLSRegression.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="sklearn.neighbors.radius_neighbors_graph.html">
        Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="sklearn.pls.PLSCanonical.html">
        Next
      </a>
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
       var bodywrapper = $('.bodywrapper');
   	var sidebarbutton = $('#sidebarbutton');
        sidebarbutton.css({
	    'height': '900px'
       });
     </script>
  </body>
</html>