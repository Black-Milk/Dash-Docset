

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>8.30.2. sklearn.tree.DecisionTreeRegressor &mdash; scikit-learn 0.13.1 documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.13.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/sidebar.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="top" title="scikit-learn 0.13.1 documentation" href="../../index.html" />
    <link rel="up" title="8. Reference" href="../classes.html" />
    <link rel="next" title="8.30.3. sklearn.tree.ExtraTreeClassifier" href="sklearn.tree.ExtraTreeClassifier.html" />
    <link rel="prev" title="8.30.1. sklearn.tree.DecisionTreeClassifier" href="sklearn.tree.DecisionTreeClassifier.html" />


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>



  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="../../install.html">Download</a></li>
            <li><a href="../../support.html">Support</a></li>
            <li><a href="../../user_guide.html">User Guide</a></li>
            <li><a href="../../auto_examples/index.html">Examples</a></li>
            <li><a href="../classes.html">Reference</a></li>
       </ul>

<div class="search_form">

<div id="cse" style="width: 100%;"></div>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
  google.load('search', '1', {language : 'en'});
  google.setOnLoadCallback(function() {
    var customSearchControl = new google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
    customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
    var options = new google.search.DrawOptions();
    options.setAutoComplete(true);
    customSearchControl.draw('cse', options);
  }, true);
</script>

</div>
          </div> <!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
	  <div class="rel">
	   
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  -->
	<div class="rellink">
	<a href="sklearn.tree.DecisionTreeClassifier.html" title="8.30.1. sklearn.tree.DecisionTreeClassifier"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    8.30.1. sklearn....
	    </span>
	    <span class="hiddenrellink">
	    8.30.1. sklearn.tree.DecisionTreeClassifier
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="sklearn.tree.ExtraTreeClassifier.html" title="8.30.3. sklearn.tree.ExtraTreeClassifier"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    8.30.3. sklearn....
	    </span>
	    <span class="hiddenrellink">
	    8.30.3. sklearn.tree.ExtraTreeClassifier
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="../../np-modindex.html" title="Python Module Index"
	    >Modules
	    <br>
	    <span class="smallrellink">
	    Python Module In...
	    </span>
	    <span class="hiddenrellink">
	    Python Module Index
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="../../py-modindex.html" title="Python Module Index"
	    >Modules
	    <br>
	    <span class="smallrellink">
	    Python Module In...
	    </span>
	    <span class="hiddenrellink">
	    Python Module Index
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page -->
	<div class="spacer">
	&nbsp;
	</div>
	<div class="rellink">
	<a href="../classes.html" title="8. Reference" >
	Up
	<br>
	<span class="smallrellink">
	8. Reference
	</span>
	<span class="hiddenrellink">
	8. Reference
	</span>
	
	</a>
	</div>
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.13.1</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3><a href="../../about.html#citing-scikit-learn">Citing</a></h3>
    <p>If you use the software, please consider
    <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">8.30.2. sklearn.tree.DecisionTreeRegressor</a></li>
</ul>

    
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="sklearn-tree-decisiontreeregressor">
<h1>8.30.2. sklearn.tree.DecisionTreeRegressor<a class="headerlink" href="#sklearn-tree-decisiontreeregressor" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.tree.DecisionTreeRegressor">
<em class="property">class </em><tt class="descclassname">sklearn.tree.</tt><tt class="descname">DecisionTreeRegressor</tt><big>(</big><em>criterion='mse'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_density=0.1</em>, <em>max_features=None</em>, <em>compute_importances=False</em>, <em>random_state=None</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>A tree regressor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>criterion</strong> : string, optional (default=&#8221;mse&#8221;)</p>
<blockquote>
<div><p>The function to measure the quality of a split. The only supported
criterion is &#8220;mse&#8221; for the mean squared error.</p>
</div></blockquote>
<p><strong>max_features</strong> : int, string or None, optional (default=None)</p>
<blockquote>
<div><dl class="docutils">
<dt>The number of features to consider when looking for the best split:</dt>
<dd><ul class="first last simple">
<li>If &#8220;auto&#8221;, then <cite>max_features=sqrt(n_features)</cite> on
classification tasks and <cite>max_features=n_features</cite>
on regression problems.</li>
<li>If &#8220;sqrt&#8221;, then <cite>max_features=sqrt(n_features)</cite>.</li>
<li>If &#8220;log2&#8221;, then <cite>max_features=log2(n_features)</cite>.</li>
<li>If None, then <cite>max_features=n_features</cite>.</li>
</ul>
</dd>
</dl>
</div></blockquote>
<p><strong>max_depth</strong> : integer or None, optional (default=None)</p>
<blockquote>
<div><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</div></blockquote>
<p><strong>min_samples_split</strong> : integer, optional (default=2)</p>
<blockquote>
<div><p>The minimum number of samples required to split an internal node.</p>
</div></blockquote>
<p><strong>min_samples_leaf</strong> : integer, optional (default=1)</p>
<blockquote>
<div><p>The minimum number of samples required to be at a leaf node.</p>
</div></blockquote>
<p><strong>min_density</strong> : float, optional (default=0.1)</p>
<blockquote>
<div><p>This parameter controls a trade-off in an optimization heuristic. It
controls the minimum density of the <cite>sample_mask</cite> (i.e. the
fraction of samples in the mask). If the density falls below this
threshold the mask is recomputed and the input data is packed
which results in data copying.  If <cite>min_density</cite> equals to one,
the partitions are always represented as copies of the original
data. Otherwise, partitions are represented as bit masks (aka
sample masks).</p>
</div></blockquote>
<p><strong>compute_importances</strong> : boolean, optional (default=True)</p>
<blockquote>
<div><p>Whether feature importances are computed and stored into the
<tt class="docutils literal"><span class="pre">feature_importances_</span></tt> attribute when calling fit.</p>
</div></blockquote>
<p><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)</p>
<blockquote class="last">
<div><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition-see-also admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><tt class="xref py py-obj docutils literal"><span class="pre">DecisionTreeClassifier</span></tt></a></p>
</div>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r110" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[R110]</a></td><td><a class="reference external" href="http://en.wikipedia.org/wiki/Decision_tree_learning">http://en.wikipedia.org/wiki/Decision_tree_learning</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r111" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[R111]</a></td><td>L. Breiman, J. Friedman, R. Olshen, and C. Stone, &#8220;Classification
and Regression Trees&#8221;, Wadsworth, Belmont, CA, 1984.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r112" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[R112]</a></td><td>T. Hastie, R. Tibshirani and J. Friedman. &#8220;Elements of Statistical
Learning&#8221;, Springer, 2009.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r113" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R113]</td><td><em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id5">2</a>)</em> L. Breiman, and A. Cutler, &#8220;Random Forests&#8221;,
<a class="reference external" href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>R2 scores (a.k.a. coefficient of determination) over 10-folds CV:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span>                   
<span class="gp">...</span>
<span class="go">array([ 0.61..., 0.57..., -0.34..., 0.41..., 0.75...,</span>
<span class="go">        0.07..., 0.29..., 0.33..., -1.42..., -1.77...])</span>
</pre></div>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="27%" />
<col width="53%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><cite>tree_</cite></td>
<td>Tree object</td>
<td>The underlying Tree object.</td>
</tr>
<tr class="row-even"><td><cite>feature_importances_</cite></td>
<td>array of shape = [n_features]</td>
<td>The feature importances
(the higher, the more important the feature).
The importance of a feature is computed as the
(normalized) total reduction of error brought by that
feature.  It is also known as the Gini importance <a class="reference internal" href="#r113">[R113]</a>.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.fit" title="sklearn.tree.DecisionTreeRegressor.fit"><tt class="xref py py-obj docutils literal"><span class="pre">fit</span></tt></a>(X,&nbsp;y[,&nbsp;sample_mask,&nbsp;X_argsorted,&nbsp;...])</td>
<td>Build a decision tree from the training set (X, y).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.fit_transform" title="sklearn.tree.DecisionTreeRegressor.fit_transform"><tt class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></tt></a>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.get_params" title="sklearn.tree.DecisionTreeRegressor.get_params"><tt class="xref py py-obj docutils literal"><span class="pre">get_params</span></tt></a>([deep])</td>
<td>Get parameters for the estimator</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.predict" title="sklearn.tree.DecisionTreeRegressor.predict"><tt class="xref py py-obj docutils literal"><span class="pre">predict</span></tt></a>(X)</td>
<td>Predict class or regression value for X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.score" title="sklearn.tree.DecisionTreeRegressor.score"><tt class="xref py py-obj docutils literal"><span class="pre">score</span></tt></a>(X,&nbsp;y)</td>
<td>Returns the coefficient of determination R^2 of the prediction.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.set_params" title="sklearn.tree.DecisionTreeRegressor.set_params"><tt class="xref py py-obj docutils literal"><span class="pre">set_params</span></tt></a>(**params)</td>
<td>Set the parameters of the estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.transform" title="sklearn.tree.DecisionTreeRegressor.transform"><tt class="xref py py-obj docutils literal"><span class="pre">transform</span></tt></a>(X[,&nbsp;threshold])</td>
<td>Reduce X to its most important features.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.__init__">
<tt class="descname">__init__</tt><big>(</big><em>criterion='mse'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_density=0.1</em>, <em>max_features=None</em>, <em>compute_importances=False</em>, <em>random_state=None</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>y</em>, <em>sample_mask=None</em>, <em>X_argsorted=None</em>, <em>check_input=True</em>, <em>sample_weight=None</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a decision tree from the training set (X, y).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>The training input samples. Use <tt class="docutils literal"><span class="pre">dtype=np.float32</span></tt>
and <tt class="docutils literal"><span class="pre">order='F'</span></tt> for maximum efficiency.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = [n_samples] or [n_samples, n_outputs]</p>
<blockquote>
<div><p>The target values (integers that correspond to classes in
classification, real numbers in regression).
Use <tt class="docutils literal"><span class="pre">dtype=np.float64</span></tt> and <tt class="docutils literal"><span class="pre">order='C'</span></tt> for maximum
efficiency.</p>
</div></blockquote>
<p><strong>sample_mask</strong> : array-like, shape = [n_samples], dtype = bool or None</p>
<blockquote>
<div><p>A bit mask that encodes the rows of <tt class="docutils literal"><span class="pre">X</span></tt> that should be
used to build the decision tree. It can be used for bagging
without the need to create of copy of <tt class="docutils literal"><span class="pre">X</span></tt>.
If None a mask will be created that includes all samples.</p>
</div></blockquote>
<p><strong>X_argsorted</strong> : array-like, shape = [n_samples, n_features] or None</p>
<blockquote>
<div><p>Each column of <tt class="docutils literal"><span class="pre">X_argsorted</span></tt> holds the row indices of <tt class="docutils literal"><span class="pre">X</span></tt>
sorted according to the value of the corresponding feature
in ascending order.
I.e. <tt class="docutils literal"><span class="pre">X[X_argsorted[i,</span> <span class="pre">k],</span> <span class="pre">k]</span> <span class="pre">&lt;=</span> <span class="pre">X[X_argsorted[j,</span> <span class="pre">k],</span> <span class="pre">k]</span></tt>
for each j &gt; i.
If None, <tt class="docutils literal"><span class="pre">X_argsorted</span></tt> is computed internally.
The argument is supported to enable multiple decision trees
to share the data structure and to avoid re-computation in
tree ensembles. For maximum efficiency use dtype np.int32.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples] or None</p>
<blockquote>
<div><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
</div></blockquote>
<p><strong>check_input</strong> : boolean, (default=True)</p>
<blockquote>
<div><p>Allow to bypass several input checking.
Don&#8217;t use this parameter unless you know what you do.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first"><strong>self</strong> : object</p>
<blockquote class="last">
<div><p>Returns self.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.fit_transform">
<tt class="descname">fit_transform</tt><big>(</big><em>X</em>, <em>y=None</em>, <em>**fit_params</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : numpy array of shape [n_samples, n_features]</p>
<blockquote>
<div><p>Training set.</p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>
<blockquote class="last">
<div><p>Transformed array.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.get_params">
<tt class="descname">get_params</tt><big>(</big><em>deep=True</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for the estimator</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>deep: boolean, optional</strong> :</p>
<blockquote class="last">
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.predict">
<tt class="descname">predict</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class or regression value for X.</p>
<p>For a classification model, the predicted class for each sample in X is
returned. For a regression model, the predicted value based on X is
returned.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of shape = [n_samples, n_features]</p>
<blockquote>
<div><p>The input samples.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first"><strong>y</strong> : array of shape = [n_samples] or [n_samples, n_outputs]</p>
<blockquote class="last">
<div><p>The predicted classes, or the predict values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.score">
<tt class="descname">score</tt><big>(</big><em>X</em>, <em>y</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the regression
sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual
sum of squares ((y_true - y_true.mean()) ** 2).sum().
Best possible score is 1.0, lower values are worse.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Training set.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = [n_samples]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last"><strong>z</strong> : float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.set_params">
<tt class="descname">set_params</tt><big>(</big><em>**params</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of the estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<tt class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></tt> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns :</th><td class="field-body"><strong>self</strong> :</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.transform">
<tt class="descname">transform</tt><big>(</big><em>X</em>, <em>threshold=None</em><big>)</big><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce X to its most important features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : array or scipy sparse matrix of shape [n_samples, n_features]</p>
<blockquote>
<div><p>The input samples.</p>
</div></blockquote>
<p><strong>threshold</strong> : string, float or None, optional (default=None)</p>
<blockquote>
<div><p>The threshold value to use for feature selection. Features whose
importance is greater or equal are kept while the others are
discarded. If &#8220;median&#8221; (resp. &#8220;mean&#8221;), then the threshold value is
the median (resp. the mean) of the feature importances. A scaling
factor (e.g., &#8220;1.25*mean&#8221;) may also be used. If None and if
available, the object attribute <tt class="docutils literal"><span class="pre">threshold</span></tt> is used. Otherwise,
&#8220;mean&#8221; is used by default.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first"><strong>X_r</strong> : array of shape [n_samples, n_selected_features]</p>
<blockquote class="last">
<div><p>The input samples with only the selected features.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010–2013, scikit-learn developers (BSD License).
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="../../_sources/modules/generated/sklearn.tree.DecisionTreeRegressor.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="sklearn.tree.DecisionTreeClassifier.html">
        Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="sklearn.tree.ExtraTreeClassifier.html">
        Next
      </a>
    </div>
    <div class="buttonPrevious">
      <a href="../../np-modindex.html">
        Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="../../py-modindex.html">
        Next
      </a>
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
       var bodywrapper = $('.bodywrapper');
   	var sidebarbutton = $('#sidebarbutton');
        sidebarbutton.css({
	    'height': '900px'
       });
     </script>
  </body>
</html>