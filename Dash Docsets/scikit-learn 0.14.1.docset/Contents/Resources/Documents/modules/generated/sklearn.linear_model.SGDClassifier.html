<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<title>sklearn.linear_model.SGDClassifier — scikit-learn 0.14.1 documentation</title>
<!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<link href="../../_static/css/bootstrap.min.css" media="screen" rel="stylesheet"/>
<link href="../../_static/css/bootstrap-responsive.css" rel="stylesheet"/>
<link href="../../_static/nature.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.14.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
<script src="../../_static/jquery.js" type="text/javascript"></script>
<script src="../../_static/underscore.js" type="text/javascript"></script>
<script src="../../_static/doctools.js" type="text/javascript"></script>
<script src="../../_static/js/copybutton.js" type="text/javascript"></script>
<link href="../../_static/favicon.ico" rel="shortcut icon"/>
<link href="../../about.html" rel="author" title="About these documents"/>
<link href="../../index.html" rel="top" title="scikit-learn 0.14.1 documentation"/>
<link href="../classes.html" rel="up" title="Reference"/>
<link href="sklearn.linear_model.SGDRegressor.html" rel="next" title="sklearn.linear_model.SGDRegressor"/>
<link href="sklearn.linear_model.RidgeCV.html" rel="prev" title="3.2.3.1.1. sklearn.linear_model.RidgeCV"/>
<script src="../../_static/sidebar.js" type="text/javascript"></script>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<script src="../../_static/js/bootstrap.min.js" type="text/javascript"></script>
<link href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" rel="canonical"/>
<script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
    var bodywrapper = $('.bodywrapper');
    var sidebarbutton = $('#sidebarbutton');
    sidebarbutton.css({'height': '900px'});
  </script>
</head>
<body>
<div class="header-wrapper">
<div class="header">
<p class="logo"><a href="../../index.html">
<img alt="Logo" src="../../_static/scikit-learn-logo-small.png"/>
</a>
</p><div class="navbar">
<ul>
<li><a href="../../../stable/index.html">Home</a></li>
<li><a href="../../../stable/install.html">Installation</a></li>
<li class="btn-li"><div class="btn-group">
<a href="../../documentation.html">Documentation</a>
<a class="btn dropdown-toggle" data-toggle="dropdown">
<span class="caret"></span>
</a>
<ul class="dropdown-menu">
<li class="link-title">Scikit-learn 0.14 (stable)</li>
<li><a href="../../tutorial/index.html">Tutorials</a></li>
<li><a href="../../user_guide.html">User guide</a></li>
<li><a href="../classes.html">API</a></li>
<li class="divider"></li>
<li><a href="http://scikit-learn.org/dev/documentation.html">Development</a></li>
<li><a href="http://scikit-learn.org/0.13/">Scikit-learn 0.13</a></li>
<li><a href="http://scikit-learn.org/0.12/">Scikit-learn 0.12</a></li>
<li><a href="http://scikit-learn.org/0.11/">Scikit-learn 0.11</a></li>
<li><a href="../../documentation.html">More versions...</a></li>
</ul>
</div>
</li>
<li><a href="../../auto_examples/index.html">Examples</a></li>
</ul>
<div class="search_form">
<div id="cse" style="width: 100%;"></div>
</div>
</div> <!-- end navbar --></div>
</div>
<!-- Github "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
<img alt="Fork me on GitHub" class="fork-me" src="../../_static/img/forkme.png" style="position: absolute; top: 0; right: 0; border: 0;"/>
</a>
<div class="content-wrapper">
<div class="sphinxsidebar">
<div class="sphinxsidebarwrapper">
<div class="rel">
<!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
<div class="rellink">
<a accesskey="P" href="sklearn.linear_model.RidgeCV.html">Previous
        <br/>
<span class="smallrellink">
        3.2.3.1.1. sklea...
        </span>
<span class="hiddenrellink">
            3.2.3.1.1. sklearn.linear_model.RidgeCV
            </span>
</a>
</div>
<div class="spacer">
             
            </div>
<div class="rellink">
<a accesskey="N" href="sklearn.linear_model.SGDRegressor.html">Next
        <br/>
<span class="smallrellink">
        sklearn.linear_m...
        </span>
<span class="hiddenrellink">
            sklearn.linear_model.SGDRegressor
            </span>
</a>
</div>
<div class="spacer">
             
            </div>
<div class="rellink">
<a href="../../np-modindex.html">Modules
        <br/>
<span class="smallrellink">
        Python Module In...
        </span>
<span class="hiddenrellink">
            Python Module Index
            </span>
</a>
</div>
<div class="spacer">
             
            </div>
<div class="rellink">
<a href="../../py-modindex.html">Modules
        <br/>
<span class="smallrellink">
        Python Module In...
        </span>
<span class="hiddenrellink">
            Python Module Index
            </span>
</a>
</div>
<!-- Ad a link to the 'up' page -->
<div class="spacer">
         
        </div>
<div class="rellink">
<a href="../classes.html">
        Up
        <br/>
<span class="smallrellink">
        Reference
        </span>
<span class="hiddenrellink">
            Reference
            </span>
</a>
</div>
</div>
<p class="doc-version">This documentation is for scikit-learn <strong>version 0.14.1</strong> — <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
<p class="citing">If you use the software, please consider <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
<ul>
<li><a class="reference internal" href="#"><tt class="docutils literal"><span class="pre">sklearn.linear_model</span></tt>.SGDClassifier</a></li>
</ul>
</div>
</div>
<div class="content">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body">
<div class="section" id="sklearn-linear-model-sgdclassifier">
<h1><a class="reference internal" href="../classes.html#module-sklearn.linear_model" title="sklearn.linear_model"><tt class="xref py py-mod docutils literal"><span class="pre">sklearn.linear_model</span></tt></a>.SGDClassifier<a class="headerlink" href="#sklearn-linear-model-sgdclassifier" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.linear_model.SGDClassifier"><a name="//apple_ref/cpp/cl/sklearn.linear_model.SGDClassifier"></a>
<em class="property">class </em><tt class="descclassname">sklearn.linear_model.</tt><tt class="descname">SGDClassifier</tt><big>(</big><em>loss='hinge'</em>, <em>penalty='l2'</em>, <em>alpha=0.0001</em>, <em>l1_ratio=0.15</em>, <em>fit_intercept=True</em>, <em>n_iter=5</em>, <em>shuffle=False</em>, <em>verbose=0</em>, <em>epsilon=0.1</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>learning_rate='optimal'</em>, <em>eta0=0.0</em>, <em>power_t=0.5</em>, <em>class_weight=None</em>, <em>warm_start=False</em>, <em>rho=None</em>, <em>seed=None</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear classifiers (SVM, logistic regression, a.o.) with SGD training.</p>
<p>This estimator implements regularized linear models with stochastic
gradient descent (SGD) learning: the gradient of the loss is estimated
each sample at a time and the model is updated along the way with a
decreasing strength schedule (aka learning rate). SGD allows minibatch
(online/out-of-core) learning, see the partial_fit method.</p>
<p>This implementation works with data represented as dense or sparse arrays
of floating point values for the features. The model it fits can be
controlled with the loss parameter; by default, it fits a linear support
vector machine (SVM).</p>
<p>The regularizer is a penalty added to the loss function that shrinks model
parameters towards the zero vector using either the squared euclidean norm
L2 or the absolute norm L1 or a combination of both (Elastic Net). If the
parameter update crosses the 0.0 value because of the regularizer, the
update is truncated to 0.0 to allow for learning sparse models and achieve
online feature selection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>loss</strong> : str, ‘hinge’, ‘log’, ‘modified_huber’, ‘squared_hinge’,                ‘perceptron’, or a regression loss: ‘squared_loss’, ‘huber’,                ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’</p>
<blockquote>
<div><p>The loss function to be used. Defaults to ‘hinge’, which gives a
linear SVM.
The ‘log’ loss gives logistic regression, a probabilistic classifier.
‘modified_huber’ is another smooth loss that brings tolerance to
outliers as well as probability estimates.
‘squared_hinge’ is like hinge but is quadratically penalized.
‘perceptron’ is the linear loss used by the perceptron algorithm.
The other losses are designed for regression but can be useful in
classification as well; see SGDRegressor for a description.</p>
</div></blockquote>
<p><strong>penalty</strong> : str, ‘l2’ or ‘l1’ or ‘elasticnet’</p>
<blockquote>
<div><p>The penalty (aka regularization term) to be used. Defaults to ‘l2’
which is the standard regularizer for linear SVM models. ‘l1’ and
‘elasticnet’ migh bring sparsity to the model (feature selection)
not achievable with ‘l2’.</p>
</div></blockquote>
<p><strong>alpha</strong> : float</p>
<blockquote>
<div><p>Constant that multiplies the regularization term. Defaults to 0.0001</p>
</div></blockquote>
<p><strong>l1_ratio</strong> : float</p>
<blockquote>
<div><p>The Elastic Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.
Defaults to 0.15.</p>
</div></blockquote>
<p><strong>fit_intercept: bool</strong> :</p>
<blockquote>
<div><p>Whether the intercept should be estimated or not. If False, the
data is assumed to be already centered. Defaults to True.</p>
</div></blockquote>
<p><strong>n_iter: int, optional</strong> :</p>
<blockquote>
<div><p>The number of passes over the training data (aka epochs).
Defaults to 5.</p>
</div></blockquote>
<p><strong>shuffle: bool, optional</strong> :</p>
<blockquote>
<div><p>Whether or not the training data should be shuffled after each epoch.
Defaults to False.</p>
</div></blockquote>
<p><strong>random_state: int seed, RandomState instance, or None (default)</strong> :</p>
<blockquote>
<div><p>The seed of the pseudo random number generator to use when
shuffling the data.</p>
</div></blockquote>
<p><strong>verbose: integer, optional</strong> :</p>
<blockquote>
<div><p>The verbosity level</p>
</div></blockquote>
<p><strong>epsilon: float</strong> :</p>
<blockquote>
<div><p>Epsilon in the epsilon-insensitive loss functions; only if <cite>loss</cite> is
‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’.
For ‘huber’, determines the threshold at which it becomes less
important to get the prediction exactly right.
For epsilon-insensitive, any differences between the current prediction
and the correct label are ignored if they are less than this threshold.</p>
</div></blockquote>
<p><strong>n_jobs: integer, optional</strong> :</p>
<blockquote>
<div><p>The number of CPUs to use to do the OVA (One Versus All, for
multi-class problems) computation. -1 means ‘all CPUs’. Defaults
to 1.</p>
</div></blockquote>
<p><strong>learning_rate</strong> : string, optional</p>
<blockquote>
<div><p>The learning rate:
constant: eta = eta0
optimal: eta = 1.0/(t+t0) [default]
invscaling: eta = eta0 / pow(t, power_t)</p>
</div></blockquote>
<p><strong>eta0</strong> : double</p>
<blockquote>
<div><p>The initial learning rate [default 0.01].</p>
</div></blockquote>
<p><strong>power_t</strong> : double</p>
<blockquote>
<div><p>The exponent for inverse scaling learning rate [default 0.5].</p>
</div></blockquote>
<p><strong>class_weight</strong> : dict, {class_label</p>
<blockquote>
<div><p>Preset for the class_weight fit parameter.</p>
<p>Weights associated with classes. If not given, all classes
are supposed to have weight one.</p>
<p>The “auto” mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies.</p>
</div></blockquote>
<p><strong>warm_start</strong> : bool, optional</p>
<blockquote class="last">
<div><p>When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><tt class="xref py py-obj docutils literal"><span class="pre">LinearSVC</span></tt>, <a class="reference internal" href="sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><tt class="xref py py-obj docutils literal"><span class="pre">LogisticRegression</span></tt></a>, <a class="reference internal" href="sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron" title="sklearn.linear_model.Perceptron"><tt class="xref py py-obj docutils literal"><span class="pre">Perceptron</span></tt></a></p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">SGDClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="gp">... </span>
<span class="go">SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,</span>
<span class="go">        fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',</span>
<span class="go">        loss='hinge', n_iter=5, n_jobs=1, penalty='l2', power_t=0.5,</span>
<span class="go">        random_state=None, rho=None, shuffle=False,</span>
<span class="go">        verbose=0, warm_start=False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]))</span>
<span class="go">[1]</span>
</pre></div>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="11%"></col>
<col width="59%"></col>
<col width="30%"></col>
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><cite>coef_</cite></td>
<td>array, shape = [1, n_features] if n_classes == 2 else [n_classes,</td>
<td> </td>
</tr>
<tr class="row-even"><td>n_features]</td>
<td> </td>
<td>Weights assigned to the features.</td>
</tr>
<tr class="row-odd"><td><cite>intercept_</cite></td>
<td>array, shape = [1] if n_classes == 2 else [n_classes]</td>
<td>Constants in decision function.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%"></col>
<col width="90%"></col>
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.decision_function" title="sklearn.linear_model.SGDClassifier.decision_function"><tt class="xref py py-obj docutils literal"><span class="pre">decision_function</span></tt></a>(X)</td>
<td>Predict confidence scores for samples.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.densify" title="sklearn.linear_model.SGDClassifier.densify"><tt class="xref py py-obj docutils literal"><span class="pre">densify</span></tt></a>()</td>
<td>Convert coefficient matrix to dense array format.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.fit" title="sklearn.linear_model.SGDClassifier.fit"><tt class="xref py py-obj docutils literal"><span class="pre">fit</span></tt></a>(X, y[, coef_init, intercept_init, ...])</td>
<td>Fit linear model with Stochastic Gradient Descent.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.fit_transform" title="sklearn.linear_model.SGDClassifier.fit_transform"><tt class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></tt></a>(X[, y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.get_params" title="sklearn.linear_model.SGDClassifier.get_params"><tt class="xref py py-obj docutils literal"><span class="pre">get_params</span></tt></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.partial_fit" title="sklearn.linear_model.SGDClassifier.partial_fit"><tt class="xref py py-obj docutils literal"><span class="pre">partial_fit</span></tt></a>(X, y[, classes, sample_weight])</td>
<td>Fit linear model with Stochastic Gradient Descent.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.predict" title="sklearn.linear_model.SGDClassifier.predict"><tt class="xref py py-obj docutils literal"><span class="pre">predict</span></tt></a>(X)</td>
<td>Predict class labels for samples in X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.predict_log_proba" title="sklearn.linear_model.SGDClassifier.predict_log_proba"><tt class="xref py py-obj docutils literal"><span class="pre">predict_log_proba</span></tt></a>(X)</td>
<td>Log of probability estimates.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.predict_proba" title="sklearn.linear_model.SGDClassifier.predict_proba"><tt class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></tt></a>(X)</td>
<td>Probability estimates.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.score" title="sklearn.linear_model.SGDClassifier.score"><tt class="xref py py-obj docutils literal"><span class="pre">score</span></tt></a>(X, y)</td>
<td>Returns the mean accuracy on the given test data and labels.</td>
</tr>
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">set_params</span></tt>(*args, **kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.sparsify" title="sklearn.linear_model.SGDClassifier.sparsify"><tt class="xref py py-obj docutils literal"><span class="pre">sparsify</span></tt></a>()</td>
<td>Convert coefficient matrix to sparse format.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.linear_model.SGDClassifier.transform" title="sklearn.linear_model.SGDClassifier.transform"><tt class="xref py py-obj docutils literal"><span class="pre">transform</span></tt></a>(X[, threshold])</td>
<td>Reduce X to its most important features.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.__init__"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.__init__"></a>
<tt class="descname">__init__</tt><big>(</big><em>loss='hinge'</em>, <em>penalty='l2'</em>, <em>alpha=0.0001</em>, <em>l1_ratio=0.15</em>, <em>fit_intercept=True</em>, <em>n_iter=5</em>, <em>shuffle=False</em>, <em>verbose=0</em>, <em>epsilon=0.1</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>learning_rate='optimal'</em>, <em>eta0=0.0</em>, <em>power_t=0.5</em>, <em>class_weight=None</em>, <em>warm_start=False</em>, <em>rho=None</em>, <em>seed=None</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.decision_function"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.decision_function"></a>
<tt class="descname">decision_function</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = (n_samples, n_features)</p>
<blockquote>
<div><p>Samples.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)</strong> :</p>
<blockquote class="last">
<div><p>Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.densify"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.densify"></a>
<tt class="descname">densify</tt><big>(</big><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.densify" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <tt class="docutils literal"><span class="pre">coef_</span></tt> member (back) to a numpy.ndarray. This is the
default format of <tt class="docutils literal"><span class="pre">coef_</span></tt> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self: estimator</strong> :</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.fit"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.fit"></a>
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>y</em>, <em>coef_init=None</em>, <em>intercept_init=None</em>, <em>class_weight=None</em>, <em>sample_weight=None</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit linear model with Stochastic Gradient Descent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Training data</p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Target values</p>
</div></blockquote>
<p><strong>coef_init</strong> : array, shape = [n_classes,n_features]</p>
<blockquote>
<div><p>The initial coefficients to warm-start the optimization.</p>
</div></blockquote>
<p><strong>intercept_init</strong> : array, shape = [n_classes]</p>
<blockquote>
<div><p>The initial intercept to warm-start the optimization.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>
<blockquote>
<div><p>Weights applied to individual samples.
If not provided, uniform weights are assumed.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><strong>self</strong> : returns an instance of self.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.fit_transform"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.fit_transform"></a>
<tt class="descname">fit_transform</tt><big>(</big><em>X</em>, <em>y=None</em>, <em>**fit_params</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : numpy array of shape [n_samples, n_features]</p>
<blockquote>
<div><p>Training set.</p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>
<blockquote class="last">
<div><p>Transformed array.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.get_params"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.get_params"></a>
<tt class="descname">get_params</tt><big>(</big><em>deep=True</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep: boolean, optional</strong> :</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.partial_fit"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.partial_fit"></a>
<tt class="descname">partial_fit</tt><big>(</big><em>X</em>, <em>y</em>, <em>classes=None</em>, <em>sample_weight=None</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit linear model with Stochastic Gradient Descent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Subset of the training data</p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Subset of the target values</p>
</div></blockquote>
<p><strong>classes</strong> : array, shape = [n_classes]</p>
<blockquote>
<div><p>Classes across all calls to partial_fit.
Can be obtained by via <cite>np.unique(y_all)</cite>, where y_all is the
target vector of the entire dataset.
This argument is required for the first call to partial_fit
and can be omitted in the subsequent calls.
Note that y doesn’t need to contain all labels in <cite>classes</cite>.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>
<blockquote>
<div><p>Weights applied to individual samples.
If not provided, uniform weights are assumed.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><strong>self</strong> : returns an instance of self.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.predict"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.predict"></a>
<tt class="descname">predict</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for samples in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Samples.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>C</strong> : array, shape = [n_samples]</p>
<blockquote class="last">
<div><p>Predicted class label per sample.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.predict_log_proba"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.predict_log_proba"></a>
<tt class="descname">predict_log_proba</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Log of probability estimates.</p>
<p>When loss=”modified_huber”, probability estimates may be hard zeros
and ones, so taking the logarithm is not possible.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>T</strong> : array-like, shape = [n_samples, n_classes]</p>
<blockquote class="last">
<div><p>Returns the log-probability of the sample for each class in the
model, where classes are ordered as they are in
<cite>self.classes_</cite>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.predict_proba"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.predict_proba"></a>
<tt class="descname">predict_proba</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability estimates.</p>
<p>Multiclass probability estimates are derived from binary (one-vs.-rest)
estimates by simple normalization, as recommended by Zadrozny and
Elkan.</p>
<p>Binary probability estimates for loss=”modified_huber” are given by
(clip(decision_function(X), -1, 1) + 1) / 2.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>array, shape = [n_samples, n_classes]</strong> :</p>
<blockquote class="last">
<div><p>Returns the probability of the sample for each class in the model,
where classes are ordered as they are in <cite>self.classes_</cite>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>Zadrozny and Elkan, “Transforming classifier scores into multiclass
probability estimates”, SIGKDD‘02,
<a class="reference external" href="http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf">http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf</a></p>
<p>The justification for the formula in the loss=”modified_huber”
case is in the appendix B in:
<a class="reference external" href="http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf">http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf</a></p>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.score"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.score"></a>
<tt class="descname">score</tt><big>(</big><em>X</em>, <em>y</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mean accuracy on the given test data and labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Training set.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = [n_samples]</p>
<blockquote>
<div><p>Labels for X.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><strong>z</strong> : float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="attribute">
<dt id="sklearn.linear_model.SGDClassifier.seed"><a name="//apple_ref/cpp/Attribute/sklearn.linear_model.SGDClassifier.seed"></a>
<tt class="descname">seed</tt><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.seed" title="Permalink to this definition">¶</a></dt>
<dd><p>DEPRECATED: Parameter ‘seed’ was renamed to ‘random_state’ for consistency and will be removed in 0.15</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.sparsify"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.sparsify"></a>
<tt class="descname">sparsify</tt><big>(</big><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.sparsify" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <tt class="docutils literal"><span class="pre">coef_</span></tt> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <tt class="docutils literal"><span class="pre">intercept_</span></tt> member is not converted.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self: estimator</strong> :</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>For non-sparse models, i.e. when there are not many zeros in <tt class="docutils literal"><span class="pre">coef_</span></tt>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <tt class="docutils literal"><span class="pre">(coef_</span> <span class="pre">==</span> <span class="pre">0).sum()</span></tt>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.linear_model.SGDClassifier.transform"><a name="//apple_ref/cpp/clm/sklearn.linear_model.SGDClassifier.transform"></a>
<tt class="descname">transform</tt><big>(</big><em>X</em>, <em>threshold=None</em><big>)</big><a class="headerlink" href="#sklearn.linear_model.SGDClassifier.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce X to its most important features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array or scipy sparse matrix of shape [n_samples, n_features]</p>
<blockquote>
<div><p>The input samples.</p>
</div></blockquote>
<p><strong>threshold</strong> : string, float or None, optional (default=None)</p>
<blockquote>
<div><p>The threshold value to use for feature selection. Features whose
importance is greater or equal are kept while the others are
discarded. If “median” (resp. “mean”), then the threshold value is
the median (resp. the mean) of the feature importances. A scaling
factor (e.g., “1.25*mean”) may also be used. If None and if
available, the object attribute <tt class="docutils literal"><span class="pre">threshold</span></tt> is used. Otherwise,
“mean” is used by default.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_r</strong> : array of shape [n_samples, n_selected_features]</p>
<blockquote class="last">
<div><p>The input samples with only the selected features.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
</dd></dl>
</div>
</div>
</div>
</div>
<div class="clearer"></div>
</div>
</div>
<div class="footer">
        © 2010 - 2014, scikit-learn developers (BSD License).
      <a href="../../_sources/modules/generated/sklearn.linear_model.SGDClassifier.txt" rel="nofollow">Show this page source</a>
</div>
<div class="rel">
<div class="buttonPrevious">
<a href="sklearn.linear_model.RidgeCV.html">Previous
      </a>
</div>
<div class="buttonNext">
<a href="sklearn.linear_model.SGDRegressor.html">Next
      </a>
</div>
<div class="buttonPrevious">
<a href="../../np-modindex.html">Previous
      </a>
</div>
<div class="buttonNext">
<a href="../../py-modindex.html">Next
      </a>
</div>
</div>
<script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
</body>
</html>