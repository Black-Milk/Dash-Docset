<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>8.8.4.4. sklearn.feature_extraction.text.TfidfVectorizer — scikit-learn 0.13.1 documentation</title><link href="../../_static/nature.css" rel="stylesheet" type="text/css"/><link href="../../_static/pygments.css" rel="stylesheet" type="text/css"/><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.13.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script><script src="../../_static/jquery.js" type="text/javascript"></script><script src="../../_static/underscore.js" type="text/javascript"></script><script src="../../_static/doctools.js" type="text/javascript"></script><script src="../../_static/sidebar.js" type="text/javascript"></script><link href="../../_static/favicon.ico" rel="shortcut icon"/><link href="../../about.html" rel="author" title="About these documents"/><link href="../../index.html" rel="top" title="scikit-learn 0.13.1 documentation"/><link href="../classes.html" rel="up" title="8. Reference"/><link href="sklearn.feature_selection.SelectPercentile.html" rel="next" title="8.9.1. sklearn.feature_selection.SelectPercentile"/><link href="sklearn.feature_extraction.text.TfidfTransformer.html" rel="prev" title="8.8.4.3. sklearn.feature_extraction.text.TfidfTransformer"/><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script></head><body>
<div class="header-wrapper">
<div class="header">
<p class="logo"><a href="../../index.html">
<img alt="Logo" src="../../_static/scikit-learn-logo-small.png"/>
</a>
</p><div class="navbar">
<ul>
<li><a href="../../install.html">Download</a></li>
<li><a href="../../support.html">Support</a></li>
<li><a href="../../user_guide.html">User Guide</a></li>
<li><a href="../../auto_examples/index.html">Examples</a></li>
<li><a href="../classes.html">Reference</a></li>
</ul>
<div class="search_form">
<div id="cse" style="width: 100%;"></div>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
  google.load('search', '1', {language : 'en'});
  google.setOnLoadCallback(function() {
    var customSearchControl = new google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
    customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
    var options = new google.search.DrawOptions();
    options.setAutoComplete(true);
    customSearchControl.draw('cse', options);
  }, true);
</script>
</div>
</div> <!-- end navbar --></div>
</div>
<div class="content-wrapper">
<div class="sphinxsidebar">
<div class="sphinxsidebarwrapper">
<div class="rel">
<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  -->
<div class="rellink">
<a accesskey="P" href="sklearn.feature_extraction.text.TfidfTransformer.html" title="8.8.4.3. sklearn.feature_extraction.text.TfidfTransformer">Previous
	    <br/>
<span class="smallrellink">
	    8.8.4.3. sklearn...
	    </span>
<span class="hiddenrellink">
	    8.8.4.3. sklearn.feature_extraction.text.TfidfTransformer
	    </span>
</a>
</div>
<div class="spacer">
	     
	    </div>
<div class="rellink">
<a accesskey="N" href="sklearn.feature_selection.SelectPercentile.html" title="8.9.1. sklearn.feature_selection.SelectPercentile">Next
	    <br/>
<span class="smallrellink">
	    8.9.1. sklearn.f...
	    </span>
<span class="hiddenrellink">
	    8.9.1. sklearn.feature_selection.SelectPercentile
	    </span>
</a>
</div>
<div class="spacer">
	     
	    </div>
<div class="rellink">
<a href="../../np-modindex.html" title="Python Module Index">Modules
	    <br/>
<span class="smallrellink">
	    Python Module In...
	    </span>
<span class="hiddenrellink">
	    Python Module Index
	    </span>
</a>
</div>
<div class="spacer">
	     
	    </div>
<div class="rellink">
<a href="../../py-modindex.html" title="Python Module Index">Modules
	    <br/>
<span class="smallrellink">
	    Python Module In...
	    </span>
<span class="hiddenrellink">
	    Python Module Index
	    </span>
</a>
</div>
<!-- Ad a link to the 'up' page -->
<div class="spacer">
	 
	</div>
<div class="rellink">
<a href="../classes.html" title="8. Reference">
	Up
	<br/>
<span class="smallrellink">
	8. Reference
	</span>
<span class="hiddenrellink">
	8. Reference
	</span>
</a>
</div>
</div>
<p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.13.1</strong>
    — <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
<h3><a href="../../about.html#citing-scikit-learn">Citing</a></h3>
<p>If you use the software, please consider
    <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
<h3>This page</h3>
<ul>
<li><a class="reference internal" href="#">8.8.4.4. sklearn.feature_extraction.text.TfidfVectorizer</a></li>
</ul>
</div>
</div>
<div class="content">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body">
<div class="section" id="sklearn-feature-extraction-text-tfidfvectorizer">
<h1>8.8.4.4. sklearn.feature_extraction.text.TfidfVectorizer<a class="headerlink" href="#sklearn-feature-extraction-text-tfidfvectorizer" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer"><a name="//apple_ref/cpp/cl/sklearn.feature_extraction.text.TfidfVectorizer"></a>
<em class="property">class </em><tt class="descclassname">sklearn.feature_extraction.text.</tt><tt class="descname">TfidfVectorizer</tt><big>(</big><em>input='content'</em>, <em>charset='utf-8'</em>, <em>charset_error='strict'</em>, <em>strip_accents=None</em>, <em>lowercase=True</em>, <em>preprocessor=None</em>, <em>tokenizer=None</em>, <em>analyzer='word'</em>, <em>stop_words=None</em>, <em>token_pattern=u'(?u)\b\w\w+\b'</em>, <em>min_n=None</em>, <em>max_n=None</em>, <em>ngram_range=(1</em>, <em>1)</em>, <em>max_df=1.0</em>, <em>min_df=2</em>, <em>max_features=None</em>, <em>vocabulary=None</em>, <em>binary=False</em>, <em>dtype=&lt;type 'long'&gt;</em>, <em>norm='l2'</em>, <em>use_idf=True</em>, <em>smooth_idf=True</em>, <em>sublinear_tf=False</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a collection of raw documents to a matrix of TF-IDF features.</p>
<p>Equivalent to CountVectorizer followed by TfidfTransformer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>input</strong> : string {‘filename’, ‘file’, ‘content’}</p>
<blockquote>
<div><p>If filename, the sequence passed as an argument to fit is
expected to be a list of filenames that need reading to fetch
the raw content to analyze.</p>
<p>If ‘file’, the sequence items must have ‘read’ method (file-like
object) it is called to fetch the bytes in memory.</p>
<p>Otherwise the input is expected to be the sequence strings or
bytes items are expected to be analyzed directly.</p>
</div></blockquote>
<p><strong>charset</strong> : string, ‘utf-8’ by default.</p>
<blockquote>
<div><p>If bytes or files are given to analyze, this charset is used to
decode.</p>
</div></blockquote>
<p><strong>charset_error</strong> : {‘strict’, ‘ignore’, ‘replace’}</p>
<blockquote>
<div><p>Instruction on what to do if a byte sequence is given to analyze that
contains characters not of the given <cite>charset</cite>. By default, it is
‘strict’, meaning that a UnicodeDecodeError will be raised. Other
values are ‘ignore’ and ‘replace’.</p>
</div></blockquote>
<p><strong>strip_accents</strong> : {‘ascii’, ‘unicode’, None}</p>
<blockquote>
<div><p>Remove accents during the preprocessing step.
‘ascii’ is a fast method that only works on characters that have
an direct ASCII mapping.
‘unicode’ is a slightly slower method that works on any characters.
None (default) does nothing.</p>
</div></blockquote>
<p><strong>analyzer</strong> : string, {‘word’, ‘char’} or callable</p>
<blockquote>
<div><p>Whether the feature should be made of word or character n-grams.</p>
<p>If a callable is passed it is used to extract the sequence of features
out of the raw, unprocessed input.</p>
</div></blockquote>
<p><strong>preprocessor</strong> : callable or None (default)</p>
<blockquote>
<div><p>Override the preprocessing (string transformation) stage while
preserving the tokenizing and n-grams generation steps.</p>
</div></blockquote>
<p><strong>tokenizer</strong> : callable or None (default)</p>
<blockquote>
<div><p>Override the string tokenization step while preserving the
preprocessing and n-grams generation steps.</p>
</div></blockquote>
<p><strong>ngram_range</strong> : tuple (min_n, max_n)</p>
<blockquote>
<div><p>The lower and upper boundary of the range of n-values for different
n-grams to be extracted. All values of n such that min_n &lt;= n &lt;= max_n
will be used.</p>
</div></blockquote>
<p><strong>stop_words</strong> : string {‘english’}, list, or None (default)</p>
<blockquote>
<div><p>If a string, it is passed to _check_stop_list and the appropriate stop
list is returned. ‘english’ is currently the only supported string
value.</p>
<p>If a list, that list is assumed to contain stop words, all of which
will be removed from the resulting tokens.</p>
<p>If None, no stop words will be used. max_df can be set to a value
in the range [0.7, 1.0) to automatically detect and filter stop
words based on intra corpus document frequency of terms.</p>
</div></blockquote>
<p><strong>lowercase</strong> : boolean, default True</p>
<blockquote>
<div><p>Convert all characters to lowercase befor tokenizing.</p>
</div></blockquote>
<p><strong>token_pattern</strong> : string</p>
<blockquote>
<div><p>Regular expression denoting what constitutes a “token”, only used
if <cite>tokenize == ‘word’</cite>. The default regexp select tokens of 2
or more letters characters (punctuation is completely ignored
and always treated as a token separator).</p>
</div></blockquote>
<p><strong>max_df</strong> : float in range [0.0, 1.0] or int, optional, 1.0 by default</p>
<blockquote>
<div><p>When building the vocabulary ignore terms that have a term frequency
strictly higher than the given threshold (corpus specific stop words).
If float, the parameter represents a proportion of documents, integer
absolute counts.
This parameter is ignored if vocabulary is not None.</p>
</div></blockquote>
<p><strong>min_df</strong> : float in range [0.0, 1.0] or int, optional, 2 by default</p>
<blockquote>
<div><p>When building the vocabulary ignore terms that have a term frequency
strictly lower than the given threshold.
This value is also called cut-off in the literature.
If float, the parameter represents a proportion of documents, integer
absolute counts.
This parameter is ignored if vocabulary is not None.</p>
</div></blockquote>
<p><strong>max_features</strong> : optional, None by default</p>
<blockquote>
<div><p>If not None, build a vocabulary that only consider the top
max_features ordered by term frequency across the corpus.</p>
<p>This parameter is ignored if vocabulary is not None.</p>
</div></blockquote>
<p><strong>vocabulary</strong> : Mapping or iterable, optional</p>
<blockquote>
<div><p>Either a Mapping (e.g., a dict) where keys are terms and values are
indices in the feature matrix, or an iterable over terms. If not
given, a vocabulary is determined from the input documents.</p>
</div></blockquote>
<p><strong>binary</strong> : boolean, False by default.</p>
<blockquote>
<div><p>If True, all non zero counts are set to 1. This is useful for discrete
probabilistic models that model binary events rather than integer
counts.</p>
</div></blockquote>
<p><strong>dtype</strong> : type, optional</p>
<blockquote>
<div><p>Type of the matrix returned by fit_transform() or transform().</p>
</div></blockquote>
<p><strong>norm</strong> : ‘l1’, ‘l2’ or None, optional</p>
<blockquote>
<div><p>Norm used to normalize term vectors. None for no normalization.</p>
</div></blockquote>
<p><strong>use_idf</strong> : boolean, optional</p>
<blockquote>
<div><p>Enable inverse-document-frequency reweighting.</p>
</div></blockquote>
<p><strong>smooth_idf</strong> : boolean, optional</p>
<blockquote>
<div><p>Smooth idf weights by adding one to document frequencies, as if an
extra document was seen containing every term in the collection
exactly once. Prevents zero divisions.</p>
</div></blockquote>
<p><strong>sublinear_tf</strong> : boolean, optional</p>
<blockquote class="last">
<div><p>Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition-see-also admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference internal" href="sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="sklearn.feature_extraction.text.CountVectorizer"><tt class="xref py py-obj docutils literal"><span class="pre">CountVectorizer</span></tt></a></dt>
<dd>Tokenize the documents and count the occurrences of token and return them as a sparse matrix</dd>
<dt><a class="reference internal" href="sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer" title="sklearn.feature_extraction.text.TfidfTransformer"><tt class="xref py py-obj docutils literal"><span class="pre">TfidfTransformer</span></tt></a></dt>
<dd>Apply Term Frequency Inverse Document Frequency normalization to a sparse matrix of occurrence counts.</dd>
</dl>
</div>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%"></col>
<col width="90%"></col>
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer" title="sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer"><tt class="xref py py-obj docutils literal"><span class="pre">build_analyzer</span></tt></a>()</td>
<td>Return a callable that handles preprocessing and tokenization</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.build_preprocessor" title="sklearn.feature_extraction.text.TfidfVectorizer.build_preprocessor"><tt class="xref py py-obj docutils literal"><span class="pre">build_preprocessor</span></tt></a>()</td>
<td>Return a function to preprocess the text before tokenization</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.build_tokenizer" title="sklearn.feature_extraction.text.TfidfVectorizer.build_tokenizer"><tt class="xref py py-obj docutils literal"><span class="pre">build_tokenizer</span></tt></a>()</td>
<td>Return a function that split a string in sequence of tokens</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.decode" title="sklearn.feature_extraction.text.TfidfVectorizer.decode"><tt class="xref py py-obj docutils literal"><span class="pre">decode</span></tt></a>(doc)</td>
<td>Decode the input into a string of unicode symbols</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.fit" title="sklearn.feature_extraction.text.TfidfVectorizer.fit"><tt class="xref py py-obj docutils literal"><span class="pre">fit</span></tt></a>(raw_documents[, y])</td>
<td>Learn a conversion law from documents to array data</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.fit_transform" title="sklearn.feature_extraction.text.TfidfVectorizer.fit_transform"><tt class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></tt></a>(raw_documents[, y])</td>
<td>Learn the representation and return the vectors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names" title="sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names"><tt class="xref py py-obj docutils literal"><span class="pre">get_feature_names</span></tt></a>()</td>
<td>Array mapping from feature integer indices to feature name</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.get_params" title="sklearn.feature_extraction.text.TfidfVectorizer.get_params"><tt class="xref py py-obj docutils literal"><span class="pre">get_params</span></tt></a>([deep])</td>
<td>Get parameters for the estimator</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.get_stop_words" title="sklearn.feature_extraction.text.TfidfVectorizer.get_stop_words"><tt class="xref py py-obj docutils literal"><span class="pre">get_stop_words</span></tt></a>()</td>
<td>Build or fetch the effective stop words list</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.inverse_transform" title="sklearn.feature_extraction.text.TfidfVectorizer.inverse_transform"><tt class="xref py py-obj docutils literal"><span class="pre">inverse_transform</span></tt></a>(X)</td>
<td>Return terms per document with nonzero entries in X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.set_params" title="sklearn.feature_extraction.text.TfidfVectorizer.set_params"><tt class="xref py py-obj docutils literal"><span class="pre">set_params</span></tt></a>(**params)</td>
<td>Set the parameters of the estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.feature_extraction.text.TfidfVectorizer.transform" title="sklearn.feature_extraction.text.TfidfVectorizer.transform"><tt class="xref py py-obj docutils literal"><span class="pre">transform</span></tt></a>(raw_documents[, copy])</td>
<td>Transform raw text documents to tf–idf vectors</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.__init__"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.__init__"></a>
<tt class="descname">__init__</tt><big>(</big><em>input='content'</em>, <em>charset='utf-8'</em>, <em>charset_error='strict'</em>, <em>strip_accents=None</em>, <em>lowercase=True</em>, <em>preprocessor=None</em>, <em>tokenizer=None</em>, <em>analyzer='word'</em>, <em>stop_words=None</em>, <em>token_pattern=u'(?u)\b\w\w+\b'</em>, <em>min_n=None</em>, <em>max_n=None</em>, <em>ngram_range=(1</em>, <em>1)</em>, <em>max_df=1.0</em>, <em>min_df=2</em>, <em>max_features=None</em>, <em>vocabulary=None</em>, <em>binary=False</em>, <em>dtype=&lt;type 'long'&gt;</em>, <em>norm='l2'</em>, <em>use_idf=True</em>, <em>smooth_idf=True</em>, <em>sublinear_tf=False</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer"></a>
<tt class="descname">build_analyzer</tt><big>(</big><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a callable that handles preprocessing and tokenization</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.build_preprocessor"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.build_preprocessor"></a>
<tt class="descname">build_preprocessor</tt><big>(</big><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.build_preprocessor" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a function to preprocess the text before tokenization</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.build_tokenizer"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.build_tokenizer"></a>
<tt class="descname">build_tokenizer</tt><big>(</big><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.build_tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a function that split a string in sequence of tokens</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.decode"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.decode"></a>
<tt class="descname">decode</tt><big>(</big><em>doc</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Decode the input into a string of unicode symbols</p>
<p>The decoding strategy depends on the vectorizer parameters.</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.fit"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.fit"></a>
<tt class="descname">fit</tt><big>(</big><em>raw_documents</em>, <em>y=None</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn a conversion law from documents to array data</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.fit_transform"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.fit_transform"></a>
<tt class="descname">fit_transform</tt><big>(</big><em>raw_documents</em>, <em>y=None</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn the representation and return the vectors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>raw_documents</strong> : iterable</p>
<blockquote>
<div><p>an iterable which yields either str, unicode or file objects</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last"><strong>vectors</strong> : array, [n_samples, n_features]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names"></a>
<tt class="descname">get_feature_names</tt><big>(</big><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Array mapping from feature integer indices to feature name</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.get_params"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.get_params"></a>
<tt class="descname">get_params</tt><big>(</big><em>deep=True</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for the estimator</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>deep: boolean, optional</strong> :</p>
<blockquote class="last">
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.get_stop_words"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.get_stop_words"></a>
<tt class="descname">get_stop_words</tt><big>(</big><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.get_stop_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Build or fetch the effective stop words list</p>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.inverse_transform"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.inverse_transform"></a>
<tt class="descname">inverse_transform</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Return terms per document with nonzero entries in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>X</strong> : {array, sparse matrix}, shape = [n_samples, n_features]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first"><strong>X_inv</strong> : list of arrays, len = n_samples</p>
<blockquote class="last">
<div><p>List of arrays of terms.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.set_params"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.set_params"></a>
<tt class="descname">set_params</tt><big>(</big><em>**params</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of the estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<tt class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></tt> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns :</th><td class="field-body"><strong>self</strong> :</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="sklearn.feature_extraction.text.TfidfVectorizer.transform"><a name="//apple_ref/cpp/clm/sklearn.feature_extraction.text.TfidfVectorizer.transform"></a>
<tt class="descname">transform</tt><big>(</big><em>raw_documents</em>, <em>copy=True</em><big>)</big><a class="headerlink" href="#sklearn.feature_extraction.text.TfidfVectorizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform raw text documents to tf–idf vectors</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>raw_documents</strong> : iterable</p>
<blockquote>
<div><p>an iterable which yields either str, unicode or file objects</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last"><strong>vectors</strong> : sparse matrix, [n_samples, n_features]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
</dd></dl>
</div>
</div>
</div>
</div>
<div class="clearer"></div>
</div>
</div>
<div class="footer">
        © 2010–2013, scikit-learn developers (BSD License).
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
<a href="../../_sources/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.txt" rel="nofollow">Show this page source</a>
</span>
</div>
<div class="rel">
<div class="buttonPrevious">
<a href="sklearn.feature_extraction.text.TfidfTransformer.html">
        Previous
      </a>
</div>
<div class="buttonNext">
<a href="sklearn.feature_selection.SelectPercentile.html">
        Next
      </a>
</div>
<div class="buttonPrevious">
<a href="../../np-modindex.html">
        Previous
      </a>
</div>
<div class="buttonNext">
<a href="../../py-modindex.html">
        Next
      </a>
</div>
</div>
<script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
       var bodywrapper = $('.bodywrapper');
   	var sidebarbutton = $('#sidebarbutton');
        sidebarbutton.css({
	    'height': '900px'
       });
     </script>
</body></html>